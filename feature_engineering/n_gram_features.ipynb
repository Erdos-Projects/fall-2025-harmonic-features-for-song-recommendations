{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cb1374-3d5a-4f24-873c-86043343e4b2",
   "metadata": {},
   "source": [
    "This notebook is about determining which $n$-grams we should make into features. First, some explanation of terminology.\n",
    "\n",
    "A **raw chord** is a musical chord, represented either as a string (e.g. 'C' or 'Amin'), or as a binary vector of lenght 12 ('C' corresponds to $[1,0,0,0,1,0,0,1,0,0,0,0]$). The Chordonomicon dataset represents chords within songs as string labels, and provides the file \"chords_mapping.csv\" for converting from a string to vector.\n",
    "\n",
    "Mathematically, the space of raw chords is $X = \\{0,1\\}^{12}$. The cyclic group $G = \\mathbb{Z}/12 \\mathbb{Z}$ acts on this set by cyclically permuting vectors, which corresponds musically to transposition. Two chords are **harmonically equivalent** of they are in the same orbit of this group action, so the set of chords up to harmonic equivalence is the quotient space $X/G$. Musically speaking, two chords are harmonically equivalent if one of them is a transposition of the other. More generally, an $n$-gram is a finite sequence in $X$, and $G$ acts entry-wise on these sequences, and two $n$-grams are harmonically equivalent if they lie in the same $G$-orbit. The general space of $n$-grams up to equivalence is\n",
    "\n",
    "$$\\bigcup_{n \\ge 1} (X^n/G)$$\n",
    "\n",
    "The premise of this notebook is that the answer to \"Does song $S$ contain an $n$-gram equivalent to $x$?\" is useful for predicting the genre of $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc7f814-e343-410f-8102-8f0d1de5cf6e",
   "metadata": {},
   "source": [
    "This leaves the question of how to pick which $x \\in \\displaystyle \\bigcup_{n \\ge 1} (X^n/G)$ are most useful features for genre prediction. We have made this determination as follows:\n",
    "\n",
    "* A single musical \"phrase\" or \"idea\" is usually not longer than 5 chords, and often shorter, so we'll only consider $1 \\le n \\le 5$.\n",
    "* If a single model utilizes $n$-grams of multiple lengths, say $n=3$ and $n=4$, then there are dependency issues between features. For example, any song containing the $4$-gram 'C,F,G,C' also contains the $3$-grams 'C,F,G' and 'F,G,C'. While this isn't literally collinearity between features, it is a significant amount of redundant information.\n",
    "* Generalizing the previous idea, if shorter sequences do contain useful information about genre, then that information would also likely be captured by looking at longer sequences. More specifically, if there is useful information to be captured about genre with single chords or pairs of chords, then that information would also be captured by looking at $3$-grams or longer. So modeling with $1$-grams and $2$-grams seems not that useful.\n",
    "\n",
    "In summary, we will explore models using $3$-grams, $4$-grams, and $5$-grams up to harmonic equivalence, and in any given model, we will only utilize sequences of the same length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b7989-9fda-423e-a1b2-f162c992bdf6",
   "metadata": {},
   "source": [
    "Even after making this determination, there are far too many $3$-grams to enumerate all of them up to harmonic equivalence. It does not take very long to enumerate all of the raw $3$-grams, but running that raw list through the \"uniquify_n_grams\" method below takes way too long (estimated ~24 hours computation. \n",
    "\n",
    "Therefore, in order to pare down to a feasible set of $n$-grams, we will have to restrict. Our process for this is:\n",
    "* Enumerate all raw $n$-grams (for $n = 3, 4, 5$) with a counter object\n",
    "* Pick the top $k$ raw $n$-grams by frequency in the training data set\n",
    "* Take the quotient by harmonic equivalence to get a list of relatively common $n$-grams up to equivalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b94a2e-fd0e-4875-80b8-769a93d86091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit these to change which value of n or k to use\n",
    "n_range = [3,4,5]\n",
    "n_count = len(n_range)\n",
    "k = 200 # increasing k and re-running the file will not re-compute existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689e5947-47f7-4dd8-bf09-dafc5de346a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "\n",
    "data_folder_path = '../data/'\n",
    "train_data_filename = 'final_train.csv'\n",
    "test_data_filename = 'final_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0053b0-bb92-4605-b525-5d963dd18969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "df_train = pd.read_csv(data_folder_path + train_data_filename, low_memory=False)\n",
    "df_test = pd.read_csv(data_folder_path + test_data_filename, low_memory=False)\n",
    "chord_column_train = df_train['simplified_chords']\n",
    "chord_column_test = df_test['simplified_chords']\n",
    "num_songs_train = len(df_train.index)\n",
    "num_songs_test = len(df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd1ebe5f-4db0-4cea-a778-9afb62834d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the equivalence dictionary file\n",
    "# this is a dictionary of dictionaries\n",
    "#    the top-level keys are chord names (e.g. 'C','Amin')\n",
    "#    the top-level values are dictionaries, whose keys are equivalent chords, and whose values are the semitone distance between the top-level key and the low-level key\n",
    "with open(data_folder_path + 'harmonic_equivalence_dictionary.json') as file:\n",
    "    equiv_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86f1f02-ab15-4dae-9981-51b1bcb94c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method uses the harmonic equivalence dictinoary json file to compare chords input in string format\n",
    "def compare_chords(chord_1, chord_2):\n",
    "    # assumptions: chord_1 and chord_2 are type string\n",
    "    # return (True, distance) if they are equivalent\n",
    "    # for most purposes, you will not need to care about the distance, so then compare_chords(c1, c2)[0] gets the truth value\n",
    "    if chord_2 in equiv_dict[chord_1]:\n",
    "        return (True, equiv_dict[chord_1][chord_2])\n",
    "    else:\n",
    "        return (False, None)\n",
    "\n",
    "# this method uses compare_chords to compare two comma-separated n-gram strings for harmonic equivalence\n",
    "def compare_n_grams(n_gram_1, n_gram_2):\n",
    "    list_1 = n_gram_1.split(',')\n",
    "    list_2 = n_gram_2.split(',')\n",
    "\n",
    "    # if they aren't the same length, we don't have to check anything\n",
    "    if len(list_1) != len(list_2):\n",
    "        return (False, None)\n",
    "\n",
    "    # now we can assume they have the same length\n",
    "    comparison = [compare_chords(list_1[i], list_2[i]) for i in range(len(list_1))]\n",
    "\n",
    "    # if any pairs are not the same, return False\n",
    "    for c in comparison:\n",
    "        if not c[0]:\n",
    "            return (False, None)\n",
    "\n",
    "    # now we can assume every respective pair is equivalent, but we still need all of the distances to match\n",
    "    dist_0 = comparison[0][1]\n",
    "    for c in comparison:\n",
    "        if c[1] != dist_0:\n",
    "            return (False, None)\n",
    "\n",
    "    return (True, dist_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e961993d-2be6-46ab-a31e-89bdd29d46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method compiles all of the raw n-grams in a Counter object for whatever chord_column data is put in\n",
    "def get_raw_n_gram_counts(chord_column, n):\n",
    "    results = Counter()\n",
    "    for song in chord_column:\n",
    "        song_as_list = song.split(',')\n",
    "        song_n_grams = [','.join(song_as_list[i:i+n]) for i in range(len(song_as_list) - n + 1)]\n",
    "        for ng in song_n_grams:\n",
    "            results[ng] += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb33232a-3c94-4966-9bbe-3c800a3b4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a generic method for iterating through a counter of n-grams and aggregating equivalent n-grams\n",
    "# note: if you try to use this to find all the unique 3-grams, the computation takes a very long time (i.e around 24 hours)\n",
    "def uniquify_n_grams(n_gram_counter):\n",
    "    results = Counter()\n",
    "    processed = set()\n",
    "    for ng1 in n_gram_counter:\n",
    "        if ng1 in processed:\n",
    "            continue\n",
    "        total = n_gram_counter[ng1]\n",
    "        for ng2 in n_gram_counter:\n",
    "            if (ng2 not in processed) and ng1 != ng2:\n",
    "                if compare_n_grams(ng1, ng2)[0]:\n",
    "                    total += n_gram_counter[ng2]\n",
    "                    processed.add(ng2)\n",
    "        results[ng1] = total\n",
    "        processed.add(ng1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0fc1c00-ba25-4a7b-943e-e6c8323d7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return true/false depending on if a song contains a harmonically equivalent n_gram to the input n_gram\n",
    "def contains_n_gram(song, n_gram):\n",
    "    # assumption: input song is a comma-separated string of chord names\n",
    "    # assumption: input n_gram is a comma-separated string of chord names\n",
    "\n",
    "    # skip ahead and return true if the literal/raw version is the song\n",
    "    # This isn't necessary to have, but it was added because it seemed to speed things up\n",
    "    # Probably depends what kind of looping/checking is happening whether this will speed up or slow down\n",
    "    if n_gram in song:\n",
    "        return True\n",
    "\n",
    "    # split the song into a list of individual chord names\n",
    "    song_as_list = song.split(',')\n",
    "    n = len(n_gram.split(','))\n",
    "\n",
    "    # iterate through the possible starting points of n-grams within the song\n",
    "    for i in range(0,len(song_as_list) - n):\n",
    "        song_n_gram = ','.join(song_as_list[i:i+n])\n",
    "        if compare_n_grams(n_gram, song_n_gram)[0]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "assert(contains_n_gram('A,B,C,D,E,F,G','C,D'))\n",
    "assert(contains_n_gram('A,B,C,D,E,F','F,G'))\n",
    "assert(not(contains_n_gram('A,B,C,D,E,F','C,E')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6468e91-a597-4dbe-bf45-8630016cb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the chord column of our dataframe and a fixed n-gram, make a binary one-hot column for that n-gram\n",
    "def get_one_hot(chord_column, n_gram):\n",
    "    return chord_column.apply(lambda song : contains_n_gram(song, n_gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf2741fc-ac24-475d-a98d-a65783c29c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line compiles all of the raw n-grams from the training data, for a given list of n values\n",
    "raw_counters = [get_raw_n_gram_counts(chord_column_train, n) for n in n_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b2c879-0e67-4445-8120-099642f97c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut to top k most common raw n-grams\n",
    "top_k_counters = [Counter(dict(rc.most_common(k))) for rc in raw_counters]\n",
    "assert(len(top_k_counters[0]) == k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaa7d324-a77e-4cd7-9be8-0224669226bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniquify each of these\n",
    "unique_counters = [uniquify_n_grams(tkc) for tkc in top_k_counters]\n",
    "unique_counter_lengths = [len(uc) for uc in unique_counters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8f6388-a773-40c9-ac82-a532c53ae5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the training, data, there are:\n",
      "\n",
      "Raw 3-grams: 298213\n",
      "Unique 3-grams among top 200 raw 3-grams: 62\n",
      "Raw 4-grams: 888910\n",
      "Unique 4-grams among top 200 raw 4-grams: 72\n",
      "Raw 5-grams: 1752485\n",
      "Unique 5-grams among top 200 raw 5-grams: 71\n"
     ]
    }
   ],
   "source": [
    "print(\"In the training, data, there are:\\n\")\n",
    "for i in range(n_count):\n",
    "    n = n_range[i]\n",
    "    print(\"Raw \" + str(n) + \"-grams:\",len(raw_counters[i]))\n",
    "    print(\"Unique \" + str(n) + \"-grams among top \" + str(k) + \" raw \" + str(n) + \"-grams:\",len(unique_counters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8afd4b86-f905-4fb9-8727-4db751cd8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the feature selection from these\n",
    "selected_n_gram_features = [list(uc.keys()) for uc in unique_counters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1f4bcfa-e8ff-41ae-bedb-ed7082a3421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of new columns\n",
    "df_train_filenames = ['final_train_with_' + str(n) + '_grams.csv' for n in n_range]\n",
    "df_test_filenames = ['final_test_with_' + str(n) + '_grams.csv' for n in n_range]\n",
    "df_all_filenames = df_train_filenames + df_test_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e748413-e1a0-4381-b743-1411c417ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv files if they do not exist\n",
    "for i in range(3):\n",
    "    train_path = data_folder_path + df_train_filenames[i]\n",
    "    test_path = data_folder_path + df_test_filenames[i]\n",
    "    if not(os.path.exists(train_path)):\n",
    "        print(\"The following file does not yet exist, so it was created:\",train_path)\n",
    "        df_train.to_csv(train_path,index=False)\n",
    "    if not(os.path.exists(test_path)):\n",
    "        print(\"The following file does not yet exist, so it was created:\",test_path)\n",
    "        df_test.to_csv(test_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5036a4b-df86-4481-bf13-d3e13199fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the existing dataframes\n",
    "train_dataframes = [pd.read_csv(data_folder_path + df_train_filenames[i], index_col = False) for i in range(n_count)]\n",
    "test_dataframes = [pd.read_csv(data_folder_path + df_test_filenames[i], index_col = False) for i in range(n_count)]\n",
    "all_dataframes = train_dataframes + test_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbc44786-2500-40d0-b670-3db688f767da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>simplified_chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; G A Fsmin Bmin G A Fsmin Bmin &lt;verse...</td>\n",
       "      <td>G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>7vpGKEUPrA4UEsS4o4W1tP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C F G C F G F Dmin G C F Dmin G C F G C F G F ...</td>\n",
       "      <td>C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>7MTpNQUBKyyymbS3gPuqwQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  \\\n",
       "0  <intro_1> G A Fsmin Bmin G A Fsmin Bmin <verse...   \n",
       "1  C F G C F G F Dmin G C F Dmin G C F G C F G F ...   \n",
       "\n",
       "                                   simplified_chords  decade   main_genre  \\\n",
       "0  G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...  2010.0          pop   \n",
       "1  C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...  2000.0  alternative   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  7vpGKEUPrA4UEsS4o4W1tP  \n",
       "1  7MTpNQUBKyyymbS3gPuqwQ  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>simplified_chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; G A Fsmin Bmin G A Fsmin Bmin &lt;verse...</td>\n",
       "      <td>G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>7vpGKEUPrA4UEsS4o4W1tP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C F G C F G F Dmin G C F Dmin G C F G C F G F ...</td>\n",
       "      <td>C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>7MTpNQUBKyyymbS3gPuqwQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  \\\n",
       "0  <intro_1> G A Fsmin Bmin G A Fsmin Bmin <verse...   \n",
       "1  C F G C F G F Dmin G C F Dmin G C F G C F G F ...   \n",
       "\n",
       "                                   simplified_chords  decade   main_genre  \\\n",
       "0  G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...  2010.0          pop   \n",
       "1  C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...  2000.0  alternative   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  7vpGKEUPrA4UEsS4o4W1tP  \n",
       "1  7MTpNQUBKyyymbS3gPuqwQ  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>simplified_chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; G A Fsmin Bmin G A Fsmin Bmin &lt;verse...</td>\n",
       "      <td>G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>7vpGKEUPrA4UEsS4o4W1tP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C F G C F G F Dmin G C F Dmin G C F G C F G F ...</td>\n",
       "      <td>C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>7MTpNQUBKyyymbS3gPuqwQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  \\\n",
       "0  <intro_1> G A Fsmin Bmin G A Fsmin Bmin <verse...   \n",
       "1  C F G C F G F Dmin G C F Dmin G C F G C F G F ...   \n",
       "\n",
       "                                   simplified_chords  decade   main_genre  \\\n",
       "0  G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...  2010.0          pop   \n",
       "1  C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...  2000.0  alternative   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  7vpGKEUPrA4UEsS4o4W1tP  \n",
       "1  7MTpNQUBKyyymbS3gPuqwQ  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>simplified_chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; C D E &lt;verse_1&gt; C D G B E C D G B &lt;c...</td>\n",
       "      <td>C,D,E,C,D,G,B,E,C,D,G,B,E,B,E,B,E,C,D,G,B,C,E,...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>206APP3O8maeXJ5dHndAwk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;verse_1&gt; G Fsmin Bmin D/A G D/Fs G Emin A D G...</td>\n",
       "      <td>G,Fsmin,Bmin,D,G,D,G,Emin,A,D,G,D,G,D,G,Fsmin,...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>country</td>\n",
       "      <td>4d7FN4kiCq8Mh78nCBj1xf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  \\\n",
       "0  <intro_1> C D E <verse_1> C D G B E C D G B <c...   \n",
       "1  <verse_1> G Fsmin Bmin D/A G D/Fs G Emin A D G...   \n",
       "\n",
       "                                   simplified_chords  decade main_genre  \\\n",
       "0  C,D,E,C,D,G,B,E,C,D,G,B,E,B,E,B,E,C,D,G,B,C,E,...  2020.0        pop   \n",
       "1  G,Fsmin,Bmin,D,G,D,G,Emin,A,D,G,D,G,D,G,Fsmin,...  2010.0    country   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  206APP3O8maeXJ5dHndAwk  \n",
       "1  4d7FN4kiCq8Mh78nCBj1xf  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>simplified_chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; C D E &lt;verse_1&gt; C D G B E C D G B &lt;c...</td>\n",
       "      <td>C,D,E,C,D,G,B,E,C,D,G,B,E,B,E,B,E,C,D,G,B,C,E,...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>206APP3O8maeXJ5dHndAwk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;verse_1&gt; G Fsmin Bmin D/A G D/Fs G Emin A D G...</td>\n",
       "      <td>G,Fsmin,Bmin,D,G,D,G,Emin,A,D,G,D,G,D,G,Fsmin,...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>country</td>\n",
       "      <td>4d7FN4kiCq8Mh78nCBj1xf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  \\\n",
       "0  <intro_1> C D E <verse_1> C D G B E C D G B <c...   \n",
       "1  <verse_1> G Fsmin Bmin D/A G D/Fs G Emin A D G...   \n",
       "\n",
       "                                   simplified_chords  decade main_genre  \\\n",
       "0  C,D,E,C,D,G,B,E,C,D,G,B,E,B,E,B,E,C,D,G,B,C,E,...  2020.0        pop   \n",
       "1  G,Fsmin,Bmin,D,G,D,G,Emin,A,D,G,D,G,D,G,Fsmin,...  2010.0    country   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  206APP3O8maeXJ5dHndAwk  \n",
       "1  4d7FN4kiCq8Mh78nCBj1xf  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>simplified_chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; C D E &lt;verse_1&gt; C D G B E C D G B &lt;c...</td>\n",
       "      <td>C,D,E,C,D,G,B,E,C,D,G,B,E,B,E,B,E,C,D,G,B,C,E,...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>206APP3O8maeXJ5dHndAwk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;verse_1&gt; G Fsmin Bmin D/A G D/Fs G Emin A D G...</td>\n",
       "      <td>G,Fsmin,Bmin,D,G,D,G,Emin,A,D,G,D,G,D,G,Fsmin,...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>country</td>\n",
       "      <td>4d7FN4kiCq8Mh78nCBj1xf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  \\\n",
       "0  <intro_1> C D E <verse_1> C D G B E C D G B <c...   \n",
       "1  <verse_1> G Fsmin Bmin D/A G D/Fs G Emin A D G...   \n",
       "\n",
       "                                   simplified_chords  decade main_genre  \\\n",
       "0  C,D,E,C,D,G,B,E,C,D,G,B,E,B,E,B,E,C,D,G,B,C,E,...  2020.0        pop   \n",
       "1  G,Fsmin,Bmin,D,G,D,G,Emin,A,D,G,D,G,D,G,Fsmin,...  2010.0    country   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  206APP3O8maeXJ5dHndAwk  \n",
       "1  4d7FN4kiCq8Mh78nCBj1xf  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in all_dataframes:\n",
    "    display(df[['chords','simplified_chords','decade','main_genre','spotify_song_id']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1be5c21c-07a2-4f81-a385-e5479ced5ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new one-hot columns for n-grams for n in [3, 4, 5]\n",
      "Number of new n-grams per class: [30, 33, 33]\n",
      "Total new n-grams: 96\n",
      "\n",
      "Creating 30 one-hot columns for n = 3\n",
      "Completed 1 columns in 68 seconds\n",
      "\tAverage time per column so far: 68.5 seconds\n",
      "\tRemaining columns: 95\n",
      "\tEstimated remaining time: 6507 seconds\n",
      "Completed 2 columns in 130 seconds\n",
      "\tAverage time per column so far: 65.4 seconds\n",
      "\tRemaining columns: 94\n",
      "\tEstimated remaining time: 6147 seconds\n",
      "Completed 3 columns in 200 seconds\n",
      "\tAverage time per column so far: 66.8 seconds\n",
      "\tRemaining columns: 93\n",
      "\tEstimated remaining time: 6212 seconds\n",
      "Completed 4 columns in 275 seconds\n",
      "\tAverage time per column so far: 69.0 seconds\n",
      "\tRemaining columns: 92\n",
      "\tEstimated remaining time: 6348 seconds\n",
      "Completed 5 columns in 328 seconds\n",
      "\tAverage time per column so far: 65.7 seconds\n",
      "\tRemaining columns: 91\n",
      "\tEstimated remaining time: 5978 seconds\n",
      "Completed 6 columns in 382 seconds\n",
      "\tAverage time per column so far: 63.7 seconds\n",
      "\tRemaining columns: 90\n",
      "\tEstimated remaining time: 5733 seconds\n",
      "Completed 7 columns in 439 seconds\n",
      "\tAverage time per column so far: 62.8 seconds\n",
      "\tRemaining columns: 89\n",
      "\tEstimated remaining time: 5589 seconds\n",
      "Completed 8 columns in 494 seconds\n",
      "\tAverage time per column so far: 61.8 seconds\n",
      "\tRemaining columns: 88\n",
      "\tEstimated remaining time: 5438 seconds\n",
      "Completed 9 columns in 548 seconds\n",
      "\tAverage time per column so far: 60.9 seconds\n",
      "\tRemaining columns: 87\n",
      "\tEstimated remaining time: 5298 seconds\n",
      "Completed 10 columns in 602 seconds\n",
      "\tAverage time per column so far: 60.3 seconds\n",
      "\tRemaining columns: 86\n",
      "\tEstimated remaining time: 5185 seconds\n",
      "Completed 11 columns in 657 seconds\n",
      "\tAverage time per column so far: 59.8 seconds\n",
      "\tRemaining columns: 85\n",
      "\tEstimated remaining time: 5083 seconds\n",
      "Completed 12 columns in 711 seconds\n",
      "\tAverage time per column so far: 59.3 seconds\n",
      "\tRemaining columns: 84\n",
      "\tEstimated remaining time: 4981 seconds\n",
      "Completed 13 columns in 765 seconds\n",
      "\tAverage time per column so far: 58.9 seconds\n",
      "\tRemaining columns: 83\n",
      "\tEstimated remaining time: 4888 seconds\n",
      "Completed 14 columns in 816 seconds\n",
      "\tAverage time per column so far: 58.3 seconds\n",
      "\tRemaining columns: 82\n",
      "\tEstimated remaining time: 4780 seconds\n",
      "Completed 15 columns in 868 seconds\n",
      "\tAverage time per column so far: 57.9 seconds\n",
      "\tRemaining columns: 81\n",
      "\tEstimated remaining time: 4689 seconds\n",
      "Completed 16 columns in 922 seconds\n",
      "\tAverage time per column so far: 57.6 seconds\n",
      "\tRemaining columns: 80\n",
      "\tEstimated remaining time: 4608 seconds\n",
      "Completed 17 columns in 977 seconds\n",
      "\tAverage time per column so far: 57.5 seconds\n",
      "\tRemaining columns: 79\n",
      "\tEstimated remaining time: 4542 seconds\n",
      "Completed 18 columns in 1030 seconds\n",
      "\tAverage time per column so far: 57.3 seconds\n",
      "\tRemaining columns: 78\n",
      "\tEstimated remaining time: 4469 seconds\n",
      "Completed 19 columns in 1084 seconds\n",
      "\tAverage time per column so far: 57.1 seconds\n",
      "\tRemaining columns: 77\n",
      "\tEstimated remaining time: 4396 seconds\n",
      "Completed 20 columns in 1137 seconds\n",
      "\tAverage time per column so far: 56.9 seconds\n",
      "\tRemaining columns: 76\n",
      "\tEstimated remaining time: 4324 seconds\n",
      "Completed 21 columns in 1190 seconds\n",
      "\tAverage time per column so far: 56.7 seconds\n",
      "\tRemaining columns: 75\n",
      "\tEstimated remaining time: 4252 seconds\n",
      "Completed 22 columns in 1244 seconds\n",
      "\tAverage time per column so far: 56.6 seconds\n",
      "\tRemaining columns: 74\n",
      "\tEstimated remaining time: 4188 seconds\n",
      "Completed 23 columns in 1298 seconds\n",
      "\tAverage time per column so far: 56.5 seconds\n",
      "\tRemaining columns: 73\n",
      "\tEstimated remaining time: 4124 seconds\n",
      "Completed 24 columns in 1352 seconds\n",
      "\tAverage time per column so far: 56.4 seconds\n",
      "\tRemaining columns: 72\n",
      "\tEstimated remaining time: 4060 seconds\n",
      "Completed 25 columns in 1407 seconds\n",
      "\tAverage time per column so far: 56.3 seconds\n",
      "\tRemaining columns: 71\n",
      "\tEstimated remaining time: 3997 seconds\n",
      "Completed 26 columns in 1461 seconds\n",
      "\tAverage time per column so far: 56.2 seconds\n",
      "\tRemaining columns: 70\n",
      "\tEstimated remaining time: 3934 seconds\n",
      "Completed 27 columns in 1516 seconds\n",
      "\tAverage time per column so far: 56.2 seconds\n",
      "\tRemaining columns: 69\n",
      "\tEstimated remaining time: 3877 seconds\n",
      "Completed 28 columns in 1572 seconds\n",
      "\tAverage time per column so far: 56.1 seconds\n",
      "\tRemaining columns: 68\n",
      "\tEstimated remaining time: 3814 seconds\n",
      "Completed 29 columns in 1625 seconds\n",
      "\tAverage time per column so far: 56.1 seconds\n",
      "\tRemaining columns: 67\n",
      "\tEstimated remaining time: 3758 seconds\n",
      "Completed 30 columns in 1680 seconds\n",
      "\tAverage time per column so far: 56.0 seconds\n",
      "\tRemaining columns: 66\n",
      "\tEstimated remaining time: 3696 seconds\n",
      "Completed all columns for n = 3\n",
      "Saving dataframe to file.\n",
      "\n",
      "\n",
      "Creating 33 one-hot columns for n = 4\n",
      "Completed 31 columns in 1746 seconds\n",
      "\tAverage time per column so far: 56.3 seconds\n",
      "\tRemaining columns: 65\n",
      "\tEstimated remaining time: 3659 seconds\n",
      "Completed 32 columns in 1808 seconds\n",
      "\tAverage time per column so far: 56.5 seconds\n",
      "\tRemaining columns: 64\n",
      "\tEstimated remaining time: 3616 seconds\n",
      "Completed 33 columns in 1869 seconds\n",
      "\tAverage time per column so far: 56.7 seconds\n",
      "\tRemaining columns: 63\n",
      "\tEstimated remaining time: 3572 seconds\n",
      "Completed 34 columns in 1931 seconds\n",
      "\tAverage time per column so far: 56.8 seconds\n",
      "\tRemaining columns: 62\n",
      "\tEstimated remaining time: 3521 seconds\n",
      "Completed 35 columns in 1992 seconds\n",
      "\tAverage time per column so far: 56.9 seconds\n",
      "\tRemaining columns: 61\n",
      "\tEstimated remaining time: 3470 seconds\n",
      "Completed 36 columns in 2053 seconds\n",
      "\tAverage time per column so far: 57.0 seconds\n",
      "\tRemaining columns: 60\n",
      "\tEstimated remaining time: 3420 seconds\n",
      "Completed 37 columns in 2114 seconds\n",
      "\tAverage time per column so far: 57.1 seconds\n",
      "\tRemaining columns: 59\n",
      "\tEstimated remaining time: 3368 seconds\n",
      "Completed 38 columns in 2174 seconds\n",
      "\tAverage time per column so far: 57.2 seconds\n",
      "\tRemaining columns: 58\n",
      "\tEstimated remaining time: 3317 seconds\n",
      "Completed 39 columns in 2235 seconds\n",
      "\tAverage time per column so far: 57.3 seconds\n",
      "\tRemaining columns: 57\n",
      "\tEstimated remaining time: 3266 seconds\n",
      "Completed 40 columns in 2294 seconds\n",
      "\tAverage time per column so far: 57.4 seconds\n",
      "\tRemaining columns: 56\n",
      "\tEstimated remaining time: 3214 seconds\n",
      "Completed 41 columns in 2356 seconds\n",
      "\tAverage time per column so far: 57.5 seconds\n",
      "\tRemaining columns: 55\n",
      "\tEstimated remaining time: 3162 seconds\n",
      "Completed 42 columns in 2416 seconds\n",
      "\tAverage time per column so far: 57.5 seconds\n",
      "\tRemaining columns: 54\n",
      "\tEstimated remaining time: 3105 seconds\n",
      "Completed 43 columns in 2477 seconds\n",
      "\tAverage time per column so far: 57.6 seconds\n",
      "\tRemaining columns: 53\n",
      "\tEstimated remaining time: 3052 seconds\n",
      "Completed 44 columns in 2539 seconds\n",
      "\tAverage time per column so far: 57.7 seconds\n",
      "\tRemaining columns: 52\n",
      "\tEstimated remaining time: 3000 seconds\n",
      "Completed 45 columns in 2602 seconds\n",
      "\tAverage time per column so far: 57.8 seconds\n",
      "\tRemaining columns: 51\n",
      "\tEstimated remaining time: 2947 seconds\n",
      "Completed 46 columns in 2664 seconds\n",
      "\tAverage time per column so far: 57.9 seconds\n",
      "\tRemaining columns: 50\n",
      "\tEstimated remaining time: 2895 seconds\n",
      "Completed 47 columns in 2725 seconds\n",
      "\tAverage time per column so far: 58.0 seconds\n",
      "\tRemaining columns: 49\n",
      "\tEstimated remaining time: 2842 seconds\n",
      "Completed 48 columns in 2786 seconds\n",
      "\tAverage time per column so far: 58.1 seconds\n",
      "\tRemaining columns: 48\n",
      "\tEstimated remaining time: 2788 seconds\n",
      "Completed 49 columns in 2848 seconds\n",
      "\tAverage time per column so far: 58.1 seconds\n",
      "\tRemaining columns: 47\n",
      "\tEstimated remaining time: 2730 seconds\n",
      "Completed 50 columns in 2911 seconds\n",
      "\tAverage time per column so far: 58.2 seconds\n",
      "\tRemaining columns: 46\n",
      "\tEstimated remaining time: 2677 seconds\n",
      "Completed 51 columns in 2978 seconds\n",
      "\tAverage time per column so far: 58.4 seconds\n",
      "\tRemaining columns: 45\n",
      "\tEstimated remaining time: 2628 seconds\n",
      "Completed 52 columns in 3049 seconds\n",
      "\tAverage time per column so far: 58.7 seconds\n",
      "\tRemaining columns: 44\n",
      "\tEstimated remaining time: 2582 seconds\n",
      "Completed 53 columns in 3118 seconds\n",
      "\tAverage time per column so far: 58.8 seconds\n",
      "\tRemaining columns: 43\n",
      "\tEstimated remaining time: 2528 seconds\n",
      "Completed 54 columns in 3182 seconds\n",
      "\tAverage time per column so far: 58.9 seconds\n",
      "\tRemaining columns: 42\n",
      "\tEstimated remaining time: 2473 seconds\n",
      "Completed 55 columns in 3246 seconds\n",
      "\tAverage time per column so far: 59.0 seconds\n",
      "\tRemaining columns: 41\n",
      "\tEstimated remaining time: 2419 seconds\n",
      "Completed 56 columns in 3311 seconds\n",
      "\tAverage time per column so far: 59.1 seconds\n",
      "\tRemaining columns: 40\n",
      "\tEstimated remaining time: 2364 seconds\n",
      "Completed 57 columns in 3381 seconds\n",
      "\tAverage time per column so far: 59.3 seconds\n",
      "\tRemaining columns: 39\n",
      "\tEstimated remaining time: 2312 seconds\n",
      "Completed 58 columns in 3447 seconds\n",
      "\tAverage time per column so far: 59.4 seconds\n",
      "\tRemaining columns: 38\n",
      "\tEstimated remaining time: 2257 seconds\n",
      "Completed 59 columns in 3513 seconds\n",
      "\tAverage time per column so far: 59.6 seconds\n",
      "\tRemaining columns: 37\n",
      "\tEstimated remaining time: 2205 seconds\n",
      "Completed 60 columns in 3584 seconds\n",
      "\tAverage time per column so far: 59.7 seconds\n",
      "\tRemaining columns: 36\n",
      "\tEstimated remaining time: 2149 seconds\n",
      "Completed 61 columns in 3688 seconds\n",
      "\tAverage time per column so far: 60.5 seconds\n",
      "\tRemaining columns: 35\n",
      "\tEstimated remaining time: 2117 seconds\n",
      "Completed 62 columns in 3800 seconds\n",
      "\tAverage time per column so far: 61.3 seconds\n",
      "\tRemaining columns: 34\n",
      "\tEstimated remaining time: 2084 seconds\n",
      "Completed 63 columns in 3915 seconds\n",
      "\tAverage time per column so far: 62.2 seconds\n",
      "\tRemaining columns: 33\n",
      "\tEstimated remaining time: 2052 seconds\n",
      "Completed all columns for n = 4\n",
      "Saving dataframe to file.\n",
      "\n",
      "\n",
      "Creating 33 one-hot columns for n = 5\n",
      "Completed 64 columns in 4064 seconds\n",
      "\tAverage time per column so far: 63.5 seconds\n",
      "\tRemaining columns: 32\n",
      "\tEstimated remaining time: 2032 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ng \u001b[38;5;129;01min\u001b[39;00m new_n_grams:\n\u001b[0;32m     25\u001b[0m     new_column_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m ng\n\u001b[1;32m---> 26\u001b[0m     df_train_n[new_column_label] \u001b[38;5;241m=\u001b[39m chord_column_train\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m song : contains_n_gram(song, ng)) \u001b[38;5;66;03m# this is where all the work gets done\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     df_test_n[new_column_label] \u001b[38;5;241m=\u001b[39m chord_column_test\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m song : contains_n_gram(song, ng)) \u001b[38;5;66;03m# this is where all the work gets done\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     completed_columns \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[22], line 26\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(song)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ng \u001b[38;5;129;01min\u001b[39;00m new_n_grams:\n\u001b[0;32m     25\u001b[0m     new_column_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m ng\n\u001b[1;32m---> 26\u001b[0m     df_train_n[new_column_label] \u001b[38;5;241m=\u001b[39m chord_column_train\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m song : contains_n_gram(song, ng)) \u001b[38;5;66;03m# this is where all the work gets done\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     df_test_n[new_column_label] \u001b[38;5;241m=\u001b[39m chord_column_test\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m song : contains_n_gram(song, ng)) \u001b[38;5;66;03m# this is where all the work gets done\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     completed_columns \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m, in \u001b[0;36mcontains_n_gram\u001b[1;34m(song, n_gram)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(song_as_list) \u001b[38;5;241m-\u001b[39m n):\n\u001b[0;32m     18\u001b[0m     song_n_gram \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(song_as_list[i:i\u001b[38;5;241m+\u001b[39mn])\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compare_n_grams(n_gram, song_n_gram)[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m, in \u001b[0;36mcompare_n_grams\u001b[1;34m(n_gram_1, n_gram_2)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# now we can assume they have the same length\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m comparison \u001b[38;5;241m=\u001b[39m [compare_chords(list_1[i], list_2[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(list_1))]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# if any pairs are not the same, return False\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m comparison:\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36mcompare_chords\u001b[1;34m(chord_1, chord_2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# this method uses the harmonic equivalence dictinoary json file to compare chords input in string format\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_chords\u001b[39m(chord_1, chord_2):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# assumptions: chord_1 and chord_2 are type string\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# return (True, distance) if they are equivalent\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# for most purposes, you will not need to care about the distance, so then compare_chords(c1, c2)[0] gets the truth value\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chord_2 \u001b[38;5;129;01min\u001b[39;00m equiv_dict[chord_1]:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, equiv_dict[chord_1][chord_2])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make a list of new one-hot columns to add (to avoid duplication)\n",
    "new_n_gram_lists = [None]*n_count\n",
    "for i in range(n_count):\n",
    "    new_n_gram_lists[i] = [ng for ng in selected_n_gram_features[i] if ('contains_' + ng) not in list(train_dataframes[i].columns)]\n",
    "new_n_gram_counts = [len(x) for x in new_n_gram_lists]\n",
    "total_new_n_grams = np.sum(new_n_gram_counts)\n",
    "\n",
    "# add one-hot columns for the new n-grams\n",
    "print(\"Creating new one-hot columns for n-grams for n in\",n_range)\n",
    "print(\"Number of new n-grams per class:\",new_n_gram_counts)\n",
    "print(\"Total new n-grams:\",total_new_n_grams)\n",
    "\n",
    "t0 = time.time()\n",
    "completed_columns = 0\n",
    "remaining_columns = total_new_n_grams\n",
    "\n",
    "for i in range(n_count):\n",
    "    n = n_range[i]\n",
    "    df_train_n = train_dataframes[i]\n",
    "    df_test_n = test_dataframes[i]\n",
    "    new_n_grams = new_n_gram_lists[i]\n",
    "    \n",
    "    print(\"\\nCreating\",new_n_gram_counts[i],\"one-hot columns for n =\",n)\n",
    "    for ng in new_n_grams:\n",
    "        new_column_label = 'contains_' + ng\n",
    "        df_train_n[new_column_label] = chord_column_train.apply(lambda song : contains_n_gram(song, ng)) # this is where all the work gets done\n",
    "        df_test_n[new_column_label] = chord_column_test.apply(lambda song : contains_n_gram(song, ng)) # this is where all the work gets done\n",
    "        \n",
    "        completed_columns += 1\n",
    "        remaining_columns -= 1\n",
    "        time_so_far = time.time() - t0\n",
    "        avg_time_per_column = np.round(time_so_far/completed_columns, decimals = 1)\n",
    "        print(\"Completed\",completed_columns,\"columns in\",int(time_so_far),\"seconds\")\n",
    "        print(\"\\tAverage time per column so far:\",avg_time_per_column,\"seconds\")\n",
    "        print(\"\\tRemaining columns:\",remaining_columns)\n",
    "        print(\"\\tEstimated remaining time:\",int(remaining_columns*avg_time_per_column),\"seconds\")\n",
    "\n",
    "    # save the n-grams dataframe to csv\n",
    "    print(\"Completed all columns for n =\",n)\n",
    "    print(\"Saving dataframe to file.\\n\")\n",
    "    df_train_n.to_csv(data_folder_path + df_train_filenames[i], index = False)\n",
    "    df_test_n.to_csv(data_folder_path + df_test_filenames[i], index = False)\n",
    "\n",
    "print(\"Completed all new one-hot columns.\")\n",
    "print(\"Total time taken:\",time.time()-t0,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef0e87-54c3-48a6-af4a-779416153ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in all_dataframes:\n",
    "    print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa097f2-8747-41cf-ba9d-90a27c034584",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframes[0].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
