{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-04T23:57:33.780616Z",
     "start_time": "2025-11-04T23:57:33.531444Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:57:37.680823Z",
     "start_time": "2025-11-04T23:57:37.677095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_duplicates(data, id_column='spotify_song_id'):\n",
    "    \"\"\"Check for duplicate rows and duplicate IDs in a DataFrame.\"\"\"\n",
    "    print(f\"Number of duplicate rows: {data.duplicated().sum()}\")\n",
    "    print(f\"Total rows: {len(data)}\")\n",
    "\n",
    "    # View the duplicate rows if any exist\n",
    "    if data.duplicated().sum() > 0:\n",
    "        print(\"\\nDuplicate rows:\")\n",
    "        print(data[data.duplicated(keep=False)])\n",
    "\n",
    "    # Check for duplicate ID values\n",
    "    print(f\"\\nNumber of duplicate {id_column}: {data[id_column].duplicated().sum()}\")\n",
    "    print(f\"Total rows: {len(data)}\")\n",
    "\n",
    "    # View rows with duplicate ID if any exist\n",
    "    if data[id_column].duplicated().sum() > 0:\n",
    "        duplicates = data[data[id_column].duplicated(keep=False)]\n",
    "        print(f\"\\nRows with duplicate {id_column}: {len(duplicates)}\")\n",
    "        print(duplicates.sort_values(id_column))"
   ],
   "id": "738395a7418825a6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:57:42.412010Z",
     "start_time": "2025-11-04T23:57:42.409674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_folder_path = Path('../../../data/')\n",
    "# print(os.listdir(data_folder_path))"
   ],
   "id": "1c5fe94e0297c98a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:57:46.968964Z",
     "start_time": "2025-11-04T23:57:44.856665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_train_3_grams = pd.read_csv(data_folder_path / 'clean_train_with_3_grams.csv')\n",
    "print(data_train_3_grams.columns)\n",
    "check_duplicates(data_train_3_grams)"
   ],
   "id": "bd3d3016970d848c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['chords', 'simplified_chords', 'decade', 'main_genre',\n",
      "       'spotify_song_id', 'contains_G,C,G', 'contains_C,G,C', 'contains_C,G,D',\n",
      "       'contains_C,G,Amin', 'contains_C,D,G', 'contains_D,G,C',\n",
      "       'contains_Emin,C,G', 'contains_D,C,G', 'contains_G,Amin,F',\n",
      "       'contains_G,D,C', 'contains_Amin,G,F', 'contains_G,C,D',\n",
      "       'contains_Amin,F,G', 'contains_F,G,Amin', 'contains_G,F,G',\n",
      "       'contains_Amin,C,G', 'contains_G,Amin,G', 'contains_G,C,Amin',\n",
      "       'contains_Amin,G,C', 'contains_C,G,Emin', 'contains_G,Amin,C',\n",
      "       'contains_G,Emin,C', 'contains_F,Amin,G', 'contains_C,D,C',\n",
      "       'contains_C,Amin,G', 'contains_G,C,Emin', 'contains_Amin,G,Amin',\n",
      "       'contains_C,Amin,C', 'contains_Emin,G,C', 'contains_G,F,Amin',\n",
      "       'contains_Amin,D,G', 'contains_G,D,Amin'],\n",
      "      dtype='object')\n",
      "Number of duplicate rows: 0\n",
      "Total rows: 255606\n",
      "\n",
      "Number of duplicate spotify_song_id: 0\n",
      "Total rows: 255606\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:57:52.320513Z",
     "start_time": "2025-11-04T23:57:50.080960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_train_4_grams = pd.read_csv(data_folder_path / 'clean_train_with_4_grams.csv')\n",
    "print(data_train_4_grams.columns)\n",
    "check_duplicates(data_train_4_grams)"
   ],
   "id": "df086b34599b90d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['chords', 'simplified_chords', 'decade', 'main_genre',\n",
      "       'spotify_song_id', 'contains_C,G,C,G', 'contains_G,C,G,C',\n",
      "       'contains_F,C,G,Amin', 'contains_C,G,Amin,F', 'contains_Amin,F,C,G',\n",
      "       'contains_G,D,C,G', 'contains_C,G,D,C', 'contains_G,Amin,F,C',\n",
      "       'contains_D,C,G,D', 'contains_D,G,C,G', 'contains_C,D,G,C',\n",
      "       'contains_G,C,D,G', 'contains_G,C,G,D', 'contains_C,G,D,G',\n",
      "       'contains_D,G,C,D', 'contains_G,D,G,C', 'contains_G,Amin,F,G',\n",
      "       'contains_Amin,F,G,C', 'contains_F,G,Amin,F', 'contains_F,G,F,G',\n",
      "       'contains_Amin,G,F,C', 'contains_Amin,G,Amin,G',\n",
      "       'contains_Amin,F,G,Amin', 'contains_G,Amin,G,Amin',\n",
      "       'contains_G,Emin,C,G', 'contains_C,G,Amin,C', 'contains_G,Amin,C,G',\n",
      "       'contains_G,C,G,Amin', 'contains_C,D,G,D', 'contains_D,C,D,C',\n",
      "       'contains_F,Amin,G,F', 'contains_C,G,Emin,C', 'contains_Amin,C,G,Amin',\n",
      "       'contains_F,G,C,Amin', 'contains_C,Amin,F,G', 'contains_G,F,G,C',\n",
      "       'contains_G,Amin,G,F', 'contains_C,Amin,C,Amin', 'contains_G,F,Amin,G'],\n",
      "      dtype='object')\n",
      "Number of duplicate rows: 0\n",
      "Total rows: 255606\n",
      "\n",
      "Number of duplicate spotify_song_id: 0\n",
      "Total rows: 255606\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:57:57.924517Z",
     "start_time": "2025-11-04T23:57:55.713250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_train_5_grams = pd.read_csv(data_folder_path / 'clean_train_with_5_grams.csv')\n",
    "print(data_train_5_grams.columns)\n",
    "check_duplicates(data_train_5_grams)"
   ],
   "id": "8774afe06dc6e55a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['chords', 'simplified_chords', 'decade', 'main_genre',\n",
      "       'spotify_song_id', 'contains_G,C,G,C,G', 'contains_C,G,C,G,C',\n",
      "       'contains_C,G,Amin,F,C', 'contains_F,C,G,Amin,F',\n",
      "       'contains_G,Amin,F,C,G', 'contains_Amin,F,C,G,Amin',\n",
      "       'contains_C,G,D,C,G', 'contains_G,D,C,G,D', 'contains_D,C,G,D,C',\n",
      "       'contains_D,G,C,D,G', 'contains_G,C,D,G,C', 'contains_C,D,G,C,D',\n",
      "       'contains_G,C,G,D,G', 'contains_G,D,G,C,G', 'contains_C,G,D,G,C',\n",
      "       'contains_D,G,C,G,D', 'contains_F,G,Amin,F,G',\n",
      "       'contains_G,Amin,F,G,Amin', 'contains_G,Amin,G,Amin,G',\n",
      "       'contains_Amin,G,Amin,G,Amin', 'contains_C,G,Emin,C,G',\n",
      "       'contains_Amin,F,G,Amin,F', 'contains_C,G,Amin,C,G',\n",
      "       'contains_G,F,G,F,G', 'contains_Amin,G,F,Amin,G',\n",
      "       'contains_C,Amin,F,G,C', 'contains_Emin,C,G,Emin,C',\n",
      "       'contains_G,Amin,C,G,Amin', 'contains_G,F,Amin,G,F',\n",
      "       'contains_F,G,F,G,F', 'contains_G,C,Amin,F,G', 'contains_F,G,C,Amin,F',\n",
      "       'contains_Amin,C,G,Amin,C', 'contains_D,G,C,G,C', 'contains_C,G,C,G,D',\n",
      "       'contains_G,Emin,C,G,Emin', 'contains_C,Amin,C,Amin,C',\n",
      "       'contains_F,Amin,G,F,Amin'],\n",
      "      dtype='object')\n",
      "Number of duplicate rows: 0\n",
      "Total rows: 255606\n",
      "\n",
      "Number of duplicate spotify_song_id: 0\n",
      "Total rows: 255606\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:58:02.091181Z",
     "start_time": "2025-11-04T23:58:01.433421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "common_cols = ['spotify_song_id', 'chords', 'simplified_chords', 'decade', 'main_genre']\n",
    "\n",
    "merged_data = (\n",
    "    data_train_3_grams\n",
    "    .merge(data_train_4_grams, on=common_cols, how='inner')\n",
    "    .merge(data_train_5_grams, on=common_cols, how='inner')\n",
    ")\n",
    "\n",
    "print(f\"Merged data shape: {merged_data.shape}\")"
   ],
   "id": "1c3998d2575a22e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data shape: (255606, 114)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:58:06.328053Z",
     "start_time": "2025-11-04T23:58:06.152546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get boolean columns (all columns except common_cols)\n",
    "bool_cols = [col for col in merged_data.columns if col not in common_cols]\n",
    "\n",
    "# Convert boolean columns to int (False -> 0, True -> 1)\n",
    "merged_data[bool_cols] = merged_data[bool_cols].astype(int)\n",
    "\n",
    "print(f\"Converted {len(bool_cols)} boolean columns to 0/1\")"
   ],
   "id": "b94fbf26c58d4ad0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 109 boolean columns to 0/1\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:58:12.068582Z",
     "start_time": "2025-11-04T23:58:08.981795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save merged data to CSV\n",
    "output_path = data_folder_path / 'data_train_n_grams.csv'\n",
    "merged_data.to_csv(output_path, index=False)\n",
    "print(f\"Saved merged data to {output_path}\")"
   ],
   "id": "ac3ca9e521628e5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged data to ../../../data/data_train_n_grams.csv\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
