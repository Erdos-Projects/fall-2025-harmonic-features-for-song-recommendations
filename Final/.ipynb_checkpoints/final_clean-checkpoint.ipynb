{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d95f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0376ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import raw data\n",
    "path_to_raw_data='../data/chordonomicon_raw.csv'\n",
    "raw_df=pd.read_csv(path_to_raw_data, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ba10e",
   "metadata": {},
   "source": [
    "Since our target variables are decade, genre and popularity, remove all entries that have NA for any of the decade, main_genre and spotify_song_id (can be linked to Spotify data to get popularity metric) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecdea62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize NA's\n",
    "raw_df = raw_df.replace({np.nan: pd.NA})\n",
    "#filter raw_df\n",
    "clean_df=raw_df[raw_df['release_date'].notna() & raw_df['spotify_song_id'].notna() & \n",
    "                raw_df['main_genre'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bead54e",
   "metadata": {},
   "source": [
    "We will build all our predictive features from the chords feature, so filter the cleaned dataset to have four columns: chords, decade, main_genre and spotify_song_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c668a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=clean_df[['chords','decade','main_genre','spotify_song_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ce46c",
   "metadata": {},
   "source": [
    "The original dataset covers all decades from 1890-2020, but there is extreme class inbalance due to few entries from the 1890s-1940s. Remove these decades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b31061ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=clean_df[clean_df['decade']>1940]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b59d8e",
   "metadata": {},
   "source": [
    "If we are using n-grams of up to length 5 as features, then we need to remove all data entries having 5 or fewer total chords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dad8a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions to find the total number of chords listed in each song\n",
    "\n",
    "import re\n",
    "\n",
    "# regex to capture tags like <verse_1>, <chorus_2>, <bridge>, etc.\n",
    "TAG = re.compile(r\"<\\s*([^>]+?)\\s*>\", flags=re.IGNORECASE)\n",
    "\n",
    "# Given string of chords partitioned into sections, returns dictionary of sections:chords in section.\n",
    "def song_split(chord_str: str):\n",
    "    s = (chord_str or \"\").strip()\n",
    "\n",
    "    # find all tags and their spans\n",
    "    spans = [(m.group(1).strip(), m.start(), m.end()) for m in TAG.finditer(s)]\n",
    "    if not spans:\n",
    "        return {\"whole\": s}  # no tags â†’ treat the whole thing as one section\n",
    "\n",
    "    # sentinel for the end of the string\n",
    "    spans.append((\"__END__\", len(s), len(s)))\n",
    "\n",
    "    chord_dict = {}\n",
    "    for (name, tag_start, tag_end), (_, next_start, _) in zip(spans, spans[1:]):\n",
    "        if name == \"__END__\":\n",
    "            break\n",
    "        # Get the segment between the end of the current tag and the start of the next tag\n",
    "        segment = s[tag_end:next_start].strip()\n",
    "        if segment:  # only keep non-empty segments\n",
    "            # If the section already exists, concatenate the new segment to the existing string\n",
    "            if name in chord_dict:\n",
    "                chord_dict[name] += \" \" + segment\n",
    "            else:\n",
    "                chord_dict[name] = segment\n",
    "\n",
    "    return chord_dict\n",
    "\n",
    "#Given a sections:chords dictionary, return the total number of chords\n",
    "def total_chord_count(dict):\n",
    "    #split each sequence into a list\n",
    "    nest_list=[dict[i].split() for i in dict.keys()]\n",
    "    #concatenate lists\n",
    "    unnest_list=[j for i in nest_list for j in i]\n",
    "    return len(unnest_list)\n",
    "\n",
    "# make new temporary 'chord_dict' and total_chords' features\n",
    "clean_df.insert(loc=4,column='chord_dict',\n",
    "                value=clean_df['chords'].apply(song_split))\n",
    "clean_df.insert(loc=5,column='total_chords',\n",
    "                value=clean_df['chord_dict'].apply(total_chord_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c07e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove entries with 5 or fewer total chords\n",
    "clean_df=clean_df[clean_df['total_chords']>5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229d83e",
   "metadata": {},
   "source": [
    "There is a single song in the dataset which contains an unrecognized chord 'sC', drop this entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "524ecd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=clean_df[clean_df['spotify_song_id']!='0cUssfb9LDMpEXy812iWCO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56d685d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update row indices to account for removed data points\n",
    "final_df=final_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bd8b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove temporary rows\n",
    "final_df=final_df.drop(columns=['chord_dict','total_chords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b17e824b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; E D A/Cs E D A/Cs &lt;verse_1&gt; E D A/Cs...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>metal</td>\n",
       "      <td>2ffJZ2r8HxI5DHcmf3BO6c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;intro_1&gt; Csmin &lt;verse_1&gt; A Csmin A Csmin A Cs...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>metal</td>\n",
       "      <td>5KiY8SZEnvCPyIEkFGRR3y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;intro_1&gt; C &lt;verse_1&gt; G C G C &lt;chorus_1&gt; F Dmi...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>3zUecdrWC3IqrNSjhnoF3G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;intro_1&gt; G Bmin Amin D G Bmin &lt;verse_1&gt; Amin ...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>1gh9q0HsS3tVXQypDXp4gf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;intro_1&gt; Fsmin Fsno3d Bno3d E/B Fsno3d Bno3d ...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>4y3uAOMHISJ3OOdjPC1FFN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;chorus_1&gt; C Amin Dmin G C G Amin Dmin G C &lt;ve...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>7FPREUUChbE5dPuDXAzjFz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;chorus_1&gt; Amin G F G Amin Fmaj7 Amin G Amin G...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>electronic</td>\n",
       "      <td>6IgzeUSIN04yVLvZdxZ6iI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;intro_1&gt; Cmaj7 C Cmaj7 C &lt;verse_1&gt; G D Emin D...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>6DneB3VYsHvIYdsfFoI1e6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;intro_1&gt; D G D G D G D G D G D Bb C D G D Bb ...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>rock</td>\n",
       "      <td>3ouHmB2wtv5CzbsWlAGZzq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amin7 Emin Gmaj7 Amin Cmaj7 Emin7 Cmaj7 Amin7 ...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>soul</td>\n",
       "      <td>3a3Zhb4QJx7r3yxw4j9VVP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  decade  main_genre  \\\n",
       "0  <intro_1> E D A/Cs E D A/Cs <verse_1> E D A/Cs...  2000.0       metal   \n",
       "1  <intro_1> Csmin <verse_1> A Csmin A Csmin A Cs...  2000.0       metal   \n",
       "2  <intro_1> C <verse_1> G C G C <chorus_1> F Dmi...  2020.0         pop   \n",
       "3  <intro_1> G Bmin Amin D G Bmin <verse_1> Amin ...  2020.0         pop   \n",
       "4  <intro_1> Fsmin Fsno3d Bno3d E/B Fsno3d Bno3d ...  2020.0         pop   \n",
       "5  <chorus_1> C Amin Dmin G C G Amin Dmin G C <ve...  2020.0         pop   \n",
       "6  <chorus_1> Amin G F G Amin Fmaj7 Amin G Amin G...  2020.0  electronic   \n",
       "7  <intro_1> Cmaj7 C Cmaj7 C <verse_1> G D Emin D...  2020.0         pop   \n",
       "8  <intro_1> D G D G D G D G D G D Bb C D G D Bb ...  2000.0        rock   \n",
       "9  Amin7 Emin Gmaj7 Amin Cmaj7 Emin7 Cmaj7 Amin7 ...  2000.0        soul   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  2ffJZ2r8HxI5DHcmf3BO6c  \n",
       "1  5KiY8SZEnvCPyIEkFGRR3y  \n",
       "2  3zUecdrWC3IqrNSjhnoF3G  \n",
       "3  1gh9q0HsS3tVXQypDXp4gf  \n",
       "4  4y3uAOMHISJ3OOdjPC1FFN  \n",
       "5  7FPREUUChbE5dPuDXAzjFz  \n",
       "6  6IgzeUSIN04yVLvZdxZ6iI  \n",
       "7  6DneB3VYsHvIYdsfFoI1e6  \n",
       "8  3ouHmB2wtv5CzbsWlAGZzq  \n",
       "9  3a3Zhb4QJx7r3yxw4j9VVP  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect final dataset\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62956130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300713, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8382b",
   "metadata": {},
   "source": [
    "Create final train and set split. An 85-15 split will produce a train set of size 255,606 and a test set of size 45,107."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce672b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "475256ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train, final_test = train_test_split(final_df,test_size=.15,random_state=000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68dd04a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\..\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m path_to_train_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/clean_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m path_to_test_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/clean_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m final_train\u001b[38;5;241m.\u001b[39mto_csv(path_to_final_data)\n\u001b[0;32m      6\u001b[0m final_test\u001b[38;5;241m.\u001b[39mto_csv(path_to_final_data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '..\\..\\data'"
     ]
    }
   ],
   "source": [
    "#write these files to csv\n",
    "path_to_final_data='../../data/clean.csv'\n",
    "path_to_train_data='../../data/clean_test.csv'\n",
    "path_to_test_data='../../data/clean_train.csv'\n",
    "final_train.to_csv(path_to_final_data)\n",
    "final_test.to_csv(path_to_final_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
