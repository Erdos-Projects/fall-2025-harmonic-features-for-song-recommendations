{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cb1374-3d5a-4f24-873c-86043343e4b2",
   "metadata": {},
   "source": [
    "This notebook is about determining which $n$-grams we should make into features. First, some explanation of terminology.\n",
    "\n",
    "A **raw chord** is a musical chord, represented either as a string (e.g. 'C' or 'Amin'), or as a binary vector of lenght 12 ('C' corresponds to $[1,0,0,0,1,0,0,1,0,0,0,0]$). The Chordonomicon dataset represents chords within songs as string labels, and provides the file \"chords_mapping.csv\" for converting from a string to vector.\n",
    "\n",
    "Mathematically, the space of raw chords is $X = \\{0,1\\}^{12}$. The cyclic group $G = \\mathbb{Z}/12 \\mathbb{Z}$ acts on this set by cyclically permuting vectors, which corresponds musically to transposition. Two chords are **harmonically equivalent** of they are in the same orbit of this group action, so the set of chords up to harmonic equivalence is the quotient space $X/G$. Musically speaking, two chords are harmonically equivalent if one of them is a transposition of the other. More generally, an $n$-gram is a finite sequence in $X$, and $G$ acts entry-wise on these sequences, and two $n$-grams are harmonically equivalent if they lie in the same $G$-orbit. The general space of $n$-grams up to equivalence is\n",
    "\n",
    "$$\\bigcup_{n \\ge 1} (X^n/G)$$\n",
    "\n",
    "The premise of this notebook is that the answer to \"Does song $S$ contain an $n$-gram equivalent to $x$?\" is useful for predicting the genre of $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc7f814-e343-410f-8102-8f0d1de5cf6e",
   "metadata": {},
   "source": [
    "This leaves the question of how to pick which $x \\in \\displaystyle \\bigcup_{n \\ge 1} (X^n/G)$ are most useful features for genre prediction. We have made this determination as follows:\n",
    "\n",
    "* A single musical \"phrase\" or \"idea\" is usually not longer than 5 chords, and often shorter, so we'll only consider $1 \\le n \\le 5$.\n",
    "* If a single model utilizes $n$-grams of multiple lengths, say $n=3$ and $n=4$, then there are dependency issues between features. For example, any song containing the $4$-gram 'C,F,G,C' also contains the $3$-grams 'C,F,G' and 'F,G,C'. While this isn't literally collinearity between features, it is a significant amount of redundant information.\n",
    "* Generalizing the previous idea, if shorter sequences do contain useful information about genre, then that information would also likely be captured by looking at longer sequences. More specifically, if there is useful information to be captured about genre with single chords or pairs of chords, then that information would also be captured by looking at $3$-grams or longer. So modeling with $1$-grams and $2$-grams seems not that useful.\n",
    "\n",
    "In summary, we will explore models using $3$-grams, $4$-grams, and $5$-grams up to harmonic equivalence, and in any given model, we will only utilize sequences of the same length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b7989-9fda-423e-a1b2-f162c992bdf6",
   "metadata": {},
   "source": [
    "Even after making this determination, there are far too many $3$-grams to enumerate all of them up to harmonic equivalence. It does not take very long to enumerate all of the raw $3$-grams, but running that raw list through the \"uniquify_n_grams\" method below takes way too long (estimated ~24 hours computation. \n",
    "\n",
    "Therefore, in order to pare down to a feasible set of $n$-grams, we will have to restrict. Our process for this is:\n",
    "* Enumerate all raw $n$-grams (for $n = 3, 4, 5$) with a counter object\n",
    "* Pick the top $k$ raw $n$-grams by frequency in the training data set\n",
    "* Take the quotient by harmonic equivalence to get a list of relatively common $n$-grams up to equivalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b94a2e-fd0e-4875-80b8-769a93d86091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit these to change which value of n or k to use\n",
    "n_range = [3,4,5]\n",
    "n_count = len(n_range)\n",
    "k = 100 # increasing k and re-running the file will not re-compute existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689e5947-47f7-4dd8-bf09-dafc5de346a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "\n",
    "data_folder_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0053b0-bb92-4605-b525-5d963dd18969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the test data\n",
    "df = pd.read_csv(data_folder_path + 'clean_test.csv', low_memory=False)\n",
    "chord_column = df['simplified_chords']\n",
    "num_songs = len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd1ebe5f-4db0-4cea-a778-9afb62834d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the equivalence dictionary file\n",
    "# this is a dictionary of dictionaries\n",
    "#    the top-level keys are chord names (e.g. 'C','Amin')\n",
    "#    the top-level values are dictionaries, whose keys are equivalent chords, and whose values are the semitone distance between the top-level key and the low-level key\n",
    "with open(data_folder_path + 'harmonic_equivalence_dictionary.json') as file:\n",
    "    equiv_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86f1f02-ab15-4dae-9981-51b1bcb94c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method uses the harmonic equivalence dictinoary json file to compare chords input in string format\n",
    "def compare_chords(chord_1, chord_2):\n",
    "    # assumptions: chord_1 and chord_2 are type string\n",
    "    # return (True, distance) if they are equivalent\n",
    "    # for most purposes, you will not need to care about the distance, so then compare_chords(c1, c2)[0] gets the truth value\n",
    "    if chord_2 in equiv_dict[chord_1]:\n",
    "        return (True, equiv_dict[chord_1][chord_2])\n",
    "    else:\n",
    "        return (False, None)\n",
    "\n",
    "# this method uses compare_chords to compare two comma-separated n-gram strings for harmonic equivalence\n",
    "def compare_n_grams(n_gram_1, n_gram_2):\n",
    "    list_1 = n_gram_1.split(',')\n",
    "    list_2 = n_gram_2.split(',')\n",
    "\n",
    "    # if they aren't the same length, we don't have to check anything\n",
    "    if len(list_1) != len(list_2):\n",
    "        return (False, None)\n",
    "\n",
    "    # now we can assume they have the same length\n",
    "    comparison = [compare_chords(list_1[i], list_2[i]) for i in range(len(list_1))]\n",
    "\n",
    "    # if any pairs are not the same, return False\n",
    "    for c in comparison:\n",
    "        if not c[0]:\n",
    "            return (False, None)\n",
    "\n",
    "    # now we can assume every respective pair is equivalent, but we still need all of the distances to match\n",
    "    dist_0 = comparison[0][1]\n",
    "    for c in comparison:\n",
    "        if c[1] != dist_0:\n",
    "            return (False, None)\n",
    "\n",
    "    return (True, dist_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e961993d-2be6-46ab-a31e-89bdd29d46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method compiles all of the raw n-grams in a Counter object for whatever chord_column data is put in\n",
    "def get_raw_n_gram_counts(chord_column, n):\n",
    "    results = Counter()\n",
    "    for song in chord_column:\n",
    "        song_as_list = song.split(',')\n",
    "        song_n_grams = [','.join(song_as_list[i:i+n]) for i in range(len(song_as_list) - n + 1)]\n",
    "        for ng in song_n_grams:\n",
    "            results[ng] += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb33232a-3c94-4966-9bbe-3c800a3b4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a generic method for iterating through a counter of n-grams and aggregating equivalent n-grams\n",
    "# note: if you try to use this to find all the unique 3-grams, the computation takes a very long time (i.e around 24 hours)\n",
    "def uniquify_n_grams(n_gram_counter):\n",
    "    results = Counter()\n",
    "    processed = set()\n",
    "    for ng1 in n_gram_counter:\n",
    "        if ng1 in processed:\n",
    "            continue\n",
    "        total = n_gram_counter[ng1]\n",
    "        for ng2 in n_gram_counter:\n",
    "            if (ng2 not in processed) and ng1 != ng2:\n",
    "                if compare_n_grams(ng1, ng2)[0]:\n",
    "                    total += n_gram_counter[ng2]\n",
    "                    processed.add(ng2)\n",
    "        results[ng1] = total\n",
    "        processed.add(ng1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0fc1c00-ba25-4a7b-943e-e6c8323d7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return true/false depending on if a song contains a harmonically equivalent n_gram to the input n_gram\n",
    "def contains_n_gram(song, n_gram):\n",
    "    # assumption: input song is a comma-separated string of chord names\n",
    "    # assumption: input n_gram is a comma-separated string of chord names\n",
    "\n",
    "    # skip ahead and return true if the literal/raw version is the song\n",
    "    # This isn't necessary to have, but it was added because it seemed to speed things up\n",
    "    # Probably depends what kind of looping/checking is happening whether this will speed up or slow down\n",
    "    if n_gram in song:\n",
    "        return True\n",
    "\n",
    "    # split the song into a list of individual chord names\n",
    "    song_as_list = song.split(',')\n",
    "    n = len(n_gram.split(','))\n",
    "\n",
    "    # iterate through the possible starting points of n-grams within the song\n",
    "    for i in range(0,len(song_as_list) - n):\n",
    "        song_n_gram = ','.join(song_as_list[i:i+n])\n",
    "        if compare_n_grams(n_gram, song_n_gram)[0]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "assert(contains_n_gram('A,B,C,D,E,F,G','C,D'))\n",
    "assert(contains_n_gram('A,B,C,D,E,F','F,G'))\n",
    "assert(not(contains_n_gram('A,B,C,D,E,F','C,E')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6468e91-a597-4dbe-bf45-8630016cb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the chord column of our dataframe and a fixed n-gram, make a binary one-hot column for that n-gram\n",
    "def get_one_hot(chord_column, n_gram):\n",
    "    return chord_column.apply(lambda song : contains_n_gram(song, n_gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf2741fc-ac24-475d-a98d-a65783c29c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line compiles all of the raw n-grams for a given list of n values\n",
    "raw_counters = [get_raw_n_gram_counts(chord_column, n) for n in n_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b2c879-0e67-4445-8120-099642f97c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut to top k most common raw n-grams\n",
    "top_k_counters = [Counter(dict(rc.most_common(k))) for rc in raw_counters]\n",
    "assert(len(top_k_counters[0]) == k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaa7d324-a77e-4cd7-9be8-0224669226bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniquify each of these\n",
    "unique_counters = [uniquify_n_grams(tkc) for tkc in top_k_counters]\n",
    "unique_counter_lengths = [len(uc) for uc in unique_counters]\n",
    "#total_unique_n_grams = np.sum(unique_counter_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8f6388-a773-40c9-ac82-a532c53ae5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw 3-grams: 298213\n",
      "Unique 3-grams among top 100 raw 3-grams: 32\n",
      "Raw 4-grams: 888910\n",
      "Unique 4-grams among top 100 raw 4-grams: 39\n",
      "Raw 5-grams: 1752485\n",
      "Unique 5-grams among top 100 raw 5-grams: 38\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_count):\n",
    "    n = n_range[i]\n",
    "    print(\"Raw \" + str(n) + \"-grams:\",len(raw_counters[i]))\n",
    "    print(\"Unique \" + str(n) + \"-grams among top \" + str(k) + \" raw \" + str(n) + \"-grams:\",len(unique_counters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8afd4b86-f905-4fb9-8727-4db751cd8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the feature selection from these\n",
    "selected_n_gram_features = [list(uc.keys()) for uc in unique_counters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1f4bcfa-e8ff-41ae-bedb-ed7082a3421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of new columns\n",
    "df_filenames = ['clean_test_with_' + str(n) + '_grams' for n in n_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5036a4b-df86-4481-bf13-d3e13199fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the existing dataframes\n",
    "dataframes = [pd.read_csv(data_folder_path + df_filenames[i], index_col = False) for i in range(len(n_range))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbc44786-2500-40d0-b670-3db688f767da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>simplified_chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; G A Fsmin Bmin G A Fsmin Bmin &lt;verse...</td>\n",
       "      <td>G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>7vpGKEUPrA4UEsS4o4W1tP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C F G C F G F Dmin G C F Dmin G C F G C F G F ...</td>\n",
       "      <td>C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>7MTpNQUBKyyymbS3gPuqwQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C F C G Amin G F C F C G Amin G F C G C F C G ...</td>\n",
       "      <td>C,F,C,G,Amin,G,F,C,F,C,G,Amin,G,F,C,G,C,F,C,G,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>6jIIMhcBPRTrkTWh3PXIc7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amin G Gmin B Amin G Gmin B Amin G Gmin B Amin...</td>\n",
       "      <td>Amin,G,Gmin,B,Amin,G,Gmin,B,Amin,G,Gmin,B,Amin...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>2zAfQdoOeYujy7QIgDUq9p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;verse_1&gt; D Dmaj7 G/D A/D D Dmaj7 G/D A/D &lt;cho...</td>\n",
       "      <td>D,Dmaj7,G,A,D,Dmaj7,G,A,G,D,Emin,D,A,G,D,Emin,...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>metal</td>\n",
       "      <td>40rChMoUd1VXb4TKgTuTSP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  \\\n",
       "0  <intro_1> G A Fsmin Bmin G A Fsmin Bmin <verse...   \n",
       "1  C F G C F G F Dmin G C F Dmin G C F G C F G F ...   \n",
       "2  C F C G Amin G F C F C G Amin G F C G C F C G ...   \n",
       "3  Amin G Gmin B Amin G Gmin B Amin G Gmin B Amin...   \n",
       "4  <verse_1> D Dmaj7 G/D A/D D Dmaj7 G/D A/D <cho...   \n",
       "\n",
       "                                   simplified_chords  decade   main_genre  \\\n",
       "0  G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...  2010.0          pop   \n",
       "1  C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...  2000.0  alternative   \n",
       "2  C,F,C,G,Amin,G,F,C,F,C,G,Amin,G,F,C,G,C,F,C,G,...  2000.0  alternative   \n",
       "3  Amin,G,Gmin,B,Amin,G,Gmin,B,Amin,G,Gmin,B,Amin...  2010.0          pop   \n",
       "4  D,Dmaj7,G,A,D,Dmaj7,G,A,G,D,Emin,D,A,G,D,Emin,...  2010.0        metal   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  7vpGKEUPrA4UEsS4o4W1tP  \n",
       "1  7MTpNQUBKyyymbS3gPuqwQ  \n",
       "2  6jIIMhcBPRTrkTWh3PXIc7  \n",
       "3  2zAfQdoOeYujy7QIgDUq9p  \n",
       "4  40rChMoUd1VXb4TKgTuTSP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>simplified_chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; G A Fsmin Bmin G A Fsmin Bmin &lt;verse...</td>\n",
       "      <td>G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>7vpGKEUPrA4UEsS4o4W1tP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C F G C F G F Dmin G C F Dmin G C F G C F G F ...</td>\n",
       "      <td>C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>7MTpNQUBKyyymbS3gPuqwQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C F C G Amin G F C F C G Amin G F C G C F C G ...</td>\n",
       "      <td>C,F,C,G,Amin,G,F,C,F,C,G,Amin,G,F,C,G,C,F,C,G,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>6jIIMhcBPRTrkTWh3PXIc7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amin G Gmin B Amin G Gmin B Amin G Gmin B Amin...</td>\n",
       "      <td>Amin,G,Gmin,B,Amin,G,Gmin,B,Amin,G,Gmin,B,Amin...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>2zAfQdoOeYujy7QIgDUq9p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;verse_1&gt; D Dmaj7 G/D A/D D Dmaj7 G/D A/D &lt;cho...</td>\n",
       "      <td>D,Dmaj7,G,A,D,Dmaj7,G,A,G,D,Emin,D,A,G,D,Emin,...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>metal</td>\n",
       "      <td>40rChMoUd1VXb4TKgTuTSP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  \\\n",
       "0  <intro_1> G A Fsmin Bmin G A Fsmin Bmin <verse...   \n",
       "1  C F G C F G F Dmin G C F Dmin G C F G C F G F ...   \n",
       "2  C F C G Amin G F C F C G Amin G F C G C F C G ...   \n",
       "3  Amin G Gmin B Amin G Gmin B Amin G Gmin B Amin...   \n",
       "4  <verse_1> D Dmaj7 G/D A/D D Dmaj7 G/D A/D <cho...   \n",
       "\n",
       "                                   simplified_chords  decade   main_genre  \\\n",
       "0  G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...  2010.0          pop   \n",
       "1  C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...  2000.0  alternative   \n",
       "2  C,F,C,G,Amin,G,F,C,F,C,G,Amin,G,F,C,G,C,F,C,G,...  2000.0  alternative   \n",
       "3  Amin,G,Gmin,B,Amin,G,Gmin,B,Amin,G,Gmin,B,Amin...  2010.0          pop   \n",
       "4  D,Dmaj7,G,A,D,Dmaj7,G,A,G,D,Emin,D,A,G,D,Emin,...  2010.0        metal   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  7vpGKEUPrA4UEsS4o4W1tP  \n",
       "1  7MTpNQUBKyyymbS3gPuqwQ  \n",
       "2  6jIIMhcBPRTrkTWh3PXIc7  \n",
       "3  2zAfQdoOeYujy7QIgDUq9p  \n",
       "4  40rChMoUd1VXb4TKgTuTSP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>simplified_chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; G A Fsmin Bmin G A Fsmin Bmin &lt;verse...</td>\n",
       "      <td>G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>7vpGKEUPrA4UEsS4o4W1tP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C F G C F G F Dmin G C F Dmin G C F G C F G F ...</td>\n",
       "      <td>C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>7MTpNQUBKyyymbS3gPuqwQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C F C G Amin G F C F C G Amin G F C G C F C G ...</td>\n",
       "      <td>C,F,C,G,Amin,G,F,C,F,C,G,Amin,G,F,C,G,C,F,C,G,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>6jIIMhcBPRTrkTWh3PXIc7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amin G Gmin B Amin G Gmin B Amin G Gmin B Amin...</td>\n",
       "      <td>Amin,G,Gmin,B,Amin,G,Gmin,B,Amin,G,Gmin,B,Amin...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>2zAfQdoOeYujy7QIgDUq9p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;verse_1&gt; D Dmaj7 G/D A/D D Dmaj7 G/D A/D &lt;cho...</td>\n",
       "      <td>D,Dmaj7,G,A,D,Dmaj7,G,A,G,D,Emin,D,A,G,D,Emin,...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>metal</td>\n",
       "      <td>40rChMoUd1VXb4TKgTuTSP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  \\\n",
       "0  <intro_1> G A Fsmin Bmin G A Fsmin Bmin <verse...   \n",
       "1  C F G C F G F Dmin G C F Dmin G C F G C F G F ...   \n",
       "2  C F C G Amin G F C F C G Amin G F C G C F C G ...   \n",
       "3  Amin G Gmin B Amin G Gmin B Amin G Gmin B Amin...   \n",
       "4  <verse_1> D Dmaj7 G/D A/D D Dmaj7 G/D A/D <cho...   \n",
       "\n",
       "                                   simplified_chords  decade   main_genre  \\\n",
       "0  G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...  2010.0          pop   \n",
       "1  C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...  2000.0  alternative   \n",
       "2  C,F,C,G,Amin,G,F,C,F,C,G,Amin,G,F,C,G,C,F,C,G,...  2000.0  alternative   \n",
       "3  Amin,G,Gmin,B,Amin,G,Gmin,B,Amin,G,Gmin,B,Amin...  2010.0          pop   \n",
       "4  D,Dmaj7,G,A,D,Dmaj7,G,A,G,D,Emin,D,A,G,D,Emin,...  2010.0        metal   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  7vpGKEUPrA4UEsS4o4W1tP  \n",
       "1  7MTpNQUBKyyymbS3gPuqwQ  \n",
       "2  6jIIMhcBPRTrkTWh3PXIc7  \n",
       "3  2zAfQdoOeYujy7QIgDUq9p  \n",
       "4  40rChMoUd1VXb4TKgTuTSP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in dataframes:\n",
    "    display(df[['chords','simplified_chords','decade','main_genre','spotify_song_id']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1be5c21c-07a2-4f81-a385-e5479ced5ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new one-hot columns for n-grams for n in [3, 4, 5]\n",
      "Number of new n-grams per class: [13, 24, 24]\n",
      "Total new n-grams: 61\n",
      "\n",
      "Creating 13 one-hot columns for n = 3\n",
      "Completed 1 columns in 43 seconds\n",
      "\tAverage time per column so far: 43.2 seconds\n",
      "\tRemaining columns: 60\n",
      "\tEstimated remaining time: 2592 seconds\n",
      "Completed 2 columns in 86 seconds\n",
      "\tAverage time per column so far: 43.4 seconds\n",
      "\tRemaining columns: 59\n",
      "\tEstimated remaining time: 2560 seconds\n",
      "Completed 3 columns in 130 seconds\n",
      "\tAverage time per column so far: 43.6 seconds\n",
      "\tRemaining columns: 58\n",
      "\tEstimated remaining time: 2528 seconds\n",
      "Completed 4 columns in 174 seconds\n",
      "\tAverage time per column so far: 43.7 seconds\n",
      "\tRemaining columns: 57\n",
      "\tEstimated remaining time: 2490 seconds\n",
      "Completed 5 columns in 216 seconds\n",
      "\tAverage time per column so far: 43.3 seconds\n",
      "\tRemaining columns: 56\n",
      "\tEstimated remaining time: 2424 seconds\n",
      "Completed 6 columns in 259 seconds\n",
      "\tAverage time per column so far: 43.3 seconds\n",
      "\tRemaining columns: 55\n",
      "\tEstimated remaining time: 2381 seconds\n",
      "Completed 7 columns in 303 seconds\n",
      "\tAverage time per column so far: 43.4 seconds\n",
      "\tRemaining columns: 54\n",
      "\tEstimated remaining time: 2343 seconds\n",
      "Completed 8 columns in 347 seconds\n",
      "\tAverage time per column so far: 43.4 seconds\n",
      "\tRemaining columns: 53\n",
      "\tEstimated remaining time: 2300 seconds\n",
      "Completed 9 columns in 392 seconds\n",
      "\tAverage time per column so far: 43.6 seconds\n",
      "\tRemaining columns: 52\n",
      "\tEstimated remaining time: 2267 seconds\n",
      "Completed 10 columns in 436 seconds\n",
      "\tAverage time per column so far: 43.6 seconds\n",
      "\tRemaining columns: 51\n",
      "\tEstimated remaining time: 2223 seconds\n",
      "Completed 11 columns in 482 seconds\n",
      "\tAverage time per column so far: 43.9 seconds\n",
      "\tRemaining columns: 50\n",
      "\tEstimated remaining time: 2195 seconds\n",
      "Completed 12 columns in 527 seconds\n",
      "\tAverage time per column so far: 43.9 seconds\n",
      "\tRemaining columns: 49\n",
      "\tEstimated remaining time: 2151 seconds\n",
      "Completed 13 columns in 573 seconds\n",
      "\tAverage time per column so far: 44.1 seconds\n",
      "\tRemaining columns: 48\n",
      "\tEstimated remaining time: 2116 seconds\n",
      "Completed all columns for n = 3\n",
      "Saving dataframe to file.\n",
      "\n",
      "\n",
      "Creating 24 one-hot columns for n = 4\n",
      "Completed 14 columns in 628 seconds\n",
      "\tAverage time per column so far: 44.9 seconds\n",
      "\tRemaining columns: 47\n",
      "\tEstimated remaining time: 2110 seconds\n",
      "Completed 15 columns in 680 seconds\n",
      "\tAverage time per column so far: 45.4 seconds\n",
      "\tRemaining columns: 46\n",
      "\tEstimated remaining time: 2088 seconds\n",
      "Completed 16 columns in 731 seconds\n",
      "\tAverage time per column so far: 45.7 seconds\n",
      "\tRemaining columns: 45\n",
      "\tEstimated remaining time: 2056 seconds\n",
      "Completed 17 columns in 784 seconds\n",
      "\tAverage time per column so far: 46.1 seconds\n",
      "\tRemaining columns: 44\n",
      "\tEstimated remaining time: 2028 seconds\n",
      "Completed 18 columns in 835 seconds\n",
      "\tAverage time per column so far: 46.4 seconds\n",
      "\tRemaining columns: 43\n",
      "\tEstimated remaining time: 1995 seconds\n",
      "Completed 19 columns in 886 seconds\n",
      "\tAverage time per column so far: 46.7 seconds\n",
      "\tRemaining columns: 42\n",
      "\tEstimated remaining time: 1961 seconds\n",
      "Completed 20 columns in 939 seconds\n",
      "\tAverage time per column so far: 47.0 seconds\n",
      "\tRemaining columns: 41\n",
      "\tEstimated remaining time: 1927 seconds\n",
      "Completed 21 columns in 991 seconds\n",
      "\tAverage time per column so far: 47.2 seconds\n",
      "\tRemaining columns: 40\n",
      "\tEstimated remaining time: 1888 seconds\n",
      "Completed 22 columns in 1045 seconds\n",
      "\tAverage time per column so far: 47.5 seconds\n",
      "\tRemaining columns: 39\n",
      "\tEstimated remaining time: 1852 seconds\n",
      "Completed 23 columns in 1098 seconds\n",
      "\tAverage time per column so far: 47.8 seconds\n",
      "\tRemaining columns: 38\n",
      "\tEstimated remaining time: 1816 seconds\n",
      "Completed 24 columns in 1149 seconds\n",
      "\tAverage time per column so far: 47.9 seconds\n",
      "\tRemaining columns: 37\n",
      "\tEstimated remaining time: 1772 seconds\n",
      "Completed 25 columns in 1204 seconds\n",
      "\tAverage time per column so far: 48.2 seconds\n",
      "\tRemaining columns: 36\n",
      "\tEstimated remaining time: 1735 seconds\n",
      "Completed 26 columns in 1255 seconds\n",
      "\tAverage time per column so far: 48.3 seconds\n",
      "\tRemaining columns: 35\n",
      "\tEstimated remaining time: 1690 seconds\n",
      "Completed 27 columns in 1307 seconds\n",
      "\tAverage time per column so far: 48.4 seconds\n",
      "\tRemaining columns: 34\n",
      "\tEstimated remaining time: 1645 seconds\n",
      "Completed 28 columns in 1360 seconds\n",
      "\tAverage time per column so far: 48.6 seconds\n",
      "\tRemaining columns: 33\n",
      "\tEstimated remaining time: 1603 seconds\n",
      "Completed 29 columns in 1413 seconds\n",
      "\tAverage time per column so far: 48.7 seconds\n",
      "\tRemaining columns: 32\n",
      "\tEstimated remaining time: 1558 seconds\n",
      "Completed 30 columns in 1467 seconds\n",
      "\tAverage time per column so far: 48.9 seconds\n",
      "\tRemaining columns: 31\n",
      "\tEstimated remaining time: 1515 seconds\n",
      "Completed 31 columns in 1521 seconds\n",
      "\tAverage time per column so far: 49.1 seconds\n",
      "\tRemaining columns: 30\n",
      "\tEstimated remaining time: 1473 seconds\n",
      "Completed 32 columns in 1574 seconds\n",
      "\tAverage time per column so far: 49.2 seconds\n",
      "\tRemaining columns: 29\n",
      "\tEstimated remaining time: 1426 seconds\n",
      "Completed 33 columns in 1627 seconds\n",
      "\tAverage time per column so far: 49.3 seconds\n",
      "\tRemaining columns: 28\n",
      "\tEstimated remaining time: 1380 seconds\n",
      "Completed 34 columns in 1679 seconds\n",
      "\tAverage time per column so far: 49.4 seconds\n",
      "\tRemaining columns: 27\n",
      "\tEstimated remaining time: 1333 seconds\n",
      "Completed 35 columns in 1731 seconds\n",
      "\tAverage time per column so far: 49.5 seconds\n",
      "\tRemaining columns: 26\n",
      "\tEstimated remaining time: 1287 seconds\n",
      "Completed 36 columns in 1785 seconds\n",
      "\tAverage time per column so far: 49.6 seconds\n",
      "\tRemaining columns: 25\n",
      "\tEstimated remaining time: 1240 seconds\n",
      "Completed 37 columns in 1838 seconds\n",
      "\tAverage time per column so far: 49.7 seconds\n",
      "\tRemaining columns: 24\n",
      "\tEstimated remaining time: 1192 seconds\n",
      "Completed all columns for n = 4\n",
      "Saving dataframe to file.\n",
      "\n",
      "\n",
      "Creating 24 one-hot columns for n = 5\n",
      "Completed 38 columns in 1901 seconds\n",
      "\tAverage time per column so far: 50.0 seconds\n",
      "\tRemaining columns: 23\n",
      "\tEstimated remaining time: 1150 seconds\n",
      "Completed 39 columns in 1964 seconds\n",
      "\tAverage time per column so far: 50.4 seconds\n",
      "\tRemaining columns: 22\n",
      "\tEstimated remaining time: 1108 seconds\n",
      "Completed 40 columns in 2024 seconds\n",
      "\tAverage time per column so far: 50.6 seconds\n",
      "\tRemaining columns: 21\n",
      "\tEstimated remaining time: 1062 seconds\n",
      "Completed 41 columns in 2094 seconds\n",
      "\tAverage time per column so far: 51.1 seconds\n",
      "\tRemaining columns: 20\n",
      "\tEstimated remaining time: 1022 seconds\n",
      "Completed 42 columns in 2172 seconds\n",
      "\tAverage time per column so far: 51.7 seconds\n",
      "\tRemaining columns: 19\n",
      "\tEstimated remaining time: 982 seconds\n",
      "Completed 43 columns in 2234 seconds\n",
      "\tAverage time per column so far: 52.0 seconds\n",
      "\tRemaining columns: 18\n",
      "\tEstimated remaining time: 936 seconds\n",
      "Completed 44 columns in 2290 seconds\n",
      "\tAverage time per column so far: 52.1 seconds\n",
      "\tRemaining columns: 17\n",
      "\tEstimated remaining time: 885 seconds\n",
      "Completed 45 columns in 2344 seconds\n",
      "\tAverage time per column so far: 52.1 seconds\n",
      "\tRemaining columns: 16\n",
      "\tEstimated remaining time: 833 seconds\n",
      "Completed 46 columns in 2399 seconds\n",
      "\tAverage time per column so far: 52.2 seconds\n",
      "\tRemaining columns: 15\n",
      "\tEstimated remaining time: 783 seconds\n",
      "Completed 47 columns in 2453 seconds\n",
      "\tAverage time per column so far: 52.2 seconds\n",
      "\tRemaining columns: 14\n",
      "\tEstimated remaining time: 730 seconds\n",
      "Completed 48 columns in 2508 seconds\n",
      "\tAverage time per column so far: 52.3 seconds\n",
      "\tRemaining columns: 13\n",
      "\tEstimated remaining time: 679 seconds\n",
      "Completed 49 columns in 2563 seconds\n",
      "\tAverage time per column so far: 52.3 seconds\n",
      "\tRemaining columns: 12\n",
      "\tEstimated remaining time: 627 seconds\n",
      "Completed 50 columns in 2620 seconds\n",
      "\tAverage time per column so far: 52.4 seconds\n",
      "\tRemaining columns: 11\n",
      "\tEstimated remaining time: 576 seconds\n",
      "Completed 51 columns in 2676 seconds\n",
      "\tAverage time per column so far: 52.5 seconds\n",
      "\tRemaining columns: 10\n",
      "\tEstimated remaining time: 525 seconds\n",
      "Completed 52 columns in 2732 seconds\n",
      "\tAverage time per column so far: 52.5 seconds\n",
      "\tRemaining columns: 9\n",
      "\tEstimated remaining time: 472 seconds\n",
      "Completed 53 columns in 2787 seconds\n",
      "\tAverage time per column so far: 52.6 seconds\n",
      "\tRemaining columns: 8\n",
      "\tEstimated remaining time: 420 seconds\n",
      "Completed 54 columns in 2843 seconds\n",
      "\tAverage time per column so far: 52.7 seconds\n",
      "\tRemaining columns: 7\n",
      "\tEstimated remaining time: 368 seconds\n",
      "Completed 55 columns in 2900 seconds\n",
      "\tAverage time per column so far: 52.7 seconds\n",
      "\tRemaining columns: 6\n",
      "\tEstimated remaining time: 316 seconds\n",
      "Completed 56 columns in 2955 seconds\n",
      "\tAverage time per column so far: 52.8 seconds\n",
      "\tRemaining columns: 5\n",
      "\tEstimated remaining time: 264 seconds\n",
      "Completed 57 columns in 3009 seconds\n",
      "\tAverage time per column so far: 52.8 seconds\n",
      "\tRemaining columns: 4\n",
      "\tEstimated remaining time: 211 seconds\n",
      "Completed 58 columns in 3063 seconds\n",
      "\tAverage time per column so far: 52.8 seconds\n",
      "\tRemaining columns: 3\n",
      "\tEstimated remaining time: 158 seconds\n",
      "Completed 59 columns in 3120 seconds\n",
      "\tAverage time per column so far: 52.9 seconds\n",
      "\tRemaining columns: 2\n",
      "\tEstimated remaining time: 105 seconds\n",
      "Completed 60 columns in 3175 seconds\n",
      "\tAverage time per column so far: 52.9 seconds\n",
      "\tRemaining columns: 1\n",
      "\tEstimated remaining time: 52 seconds\n",
      "Completed 61 columns in 3231 seconds\n",
      "\tAverage time per column so far: 53.0 seconds\n",
      "\tRemaining columns: 0\n",
      "\tEstimated remaining time: 0 seconds\n",
      "Completed all columns for n = 5\n",
      "Saving dataframe to file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make a list of new one-hot columns to add (to avoid duplication)\n",
    "new_n_gram_lists = [None]*n_count\n",
    "for i in range(n_count):\n",
    "    new_n_gram_lists[i] = [ng for ng in selected_n_gram_features[i] if ('contains_' + ng) not in list(dataframes[i].columns)]\n",
    "new_n_gram_counts = [len(x) for x in new_n_gram_lists]\n",
    "total_new_n_grams = np.sum(new_n_gram_counts)\n",
    "\n",
    "# add one-hot columns for the new n-grams\n",
    "print(\"Creating new one-hot columns for n-grams for n in\",n_range)\n",
    "print(\"Number of new n-grams per class:\",new_n_gram_counts)\n",
    "print(\"Total new n-grams:\",total_new_n_grams)\n",
    "\n",
    "t0 = time.time()\n",
    "completed_columns = 0\n",
    "remaining_columns = total_new_n_grams\n",
    "\n",
    "for i in range(n_count):\n",
    "    n = n_range[i]\n",
    "    df_n = dataframes[i]\n",
    "    new_n_grams = new_n_gram_lists[i]\n",
    "    \n",
    "    print(\"\\nCreating\",new_n_gram_counts[i],\"one-hot columns for n =\",n)\n",
    "    for ng in new_n_grams:\n",
    "        new_column_label = 'contains_' + ng\n",
    "        df_n[new_column_label] = chord_column.apply(lambda song : contains_n_gram(song, ng)) # this is where all the work gets done\n",
    "        \n",
    "        completed_columns += 1\n",
    "        remaining_columns -= 1\n",
    "        time_so_far = time.time() - t0\n",
    "        avg_time_per_column = np.round(time_so_far/completed_columns, decimals = 1)\n",
    "        print(\"Completed\",completed_columns,\"columns in\",int(time_so_far),\"seconds\")\n",
    "        print(\"\\tAverage time per column so far:\",avg_time_per_column,\"seconds\")\n",
    "        print(\"\\tRemaining columns:\",remaining_columns)\n",
    "        print(\"\\tEstimated remaining time:\",int(remaining_columns*avg_time_per_column),\"seconds\")\n",
    "\n",
    "    # save the n-grams dataframe to csv\n",
    "    print(\"Completed all columns for n =\",n)\n",
    "    print(\"Saving dataframe to file.\\n\")\n",
    "    df_n.to_csv(data_folder_path + df_filenames[i], index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
