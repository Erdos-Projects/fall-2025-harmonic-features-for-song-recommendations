{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:08.717421Z",
     "start_time": "2025-11-02T01:07:07.708589Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functions import *\n",
    "from functions_plots import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6030ff23331d5a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:15.718086Z",
     "start_time": "2025-11-02T01:07:08.719760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 255606\n",
      "Number of predictor columns: 119\n",
      "Target columns: ['spotify_popularity', 'on_hot100', 'decade', 'main_genre']\n",
      "All columns in the raw data: ['id', 'chords', 'release_date', 'genres', 'decade', 'rock_genre', 'artist_id', 'main_genre', 'spotify_song_id', 'spotify_artist_id'] \n",
      "\n",
      "All columns in the training data: ['chords_x', 'simplified_chords_x', 'spotify_song_id', 'chords_y', 'missing_notes', 'simplified_chords_y', 'drone_ratio', 'average_overlap', 'average_2overlap', 'average_3overlap', 'average_4overlap', 'average_5overlap', 'maj_triad_ratio', 'min_triad_ratio', 'chords', 'unique_5gram_density', 'unique_chord_density', 'simplified_chords', 'decade', 'main_genre', 'spotify_track_id', 'spotify_artist_id', 'spotify_success', 'spotify_track_name', 'spotify_artists', 'spotify_album_name', 'spotify_release_date', 'spotify_popularity', 'spotify_duration_ms', 'spotify_artist_name', 'spotify_genres', 'spotify_artist_popularity', 'spotify_followers', 'contains_G,C,G', 'contains_C,G,C', 'contains_C,G,D', 'contains_C,G,Amin', 'contains_C,D,G', 'contains_D,G,C', 'contains_Emin,C,G', 'contains_D,C,G', 'contains_G,Amin,F', 'contains_G,D,C', 'contains_Amin,G,F', 'contains_G,C,D', 'contains_Amin,F,G', 'contains_F,G,Amin', 'contains_G,F,G', 'contains_Amin,C,G', 'contains_G,Amin,G', 'contains_G,C,Amin', 'contains_Amin,G,C', 'contains_C,G,Emin', 'contains_G,Amin,C', 'contains_G,Emin,C', 'contains_F,Amin,G', 'contains_C,D,C', 'contains_C,Amin,G', 'contains_G,C,Emin', 'contains_Amin,G,Amin', 'contains_C,Amin,C', 'contains_Emin,G,C', 'contains_G,F,Amin', 'contains_Amin,D,G', 'contains_G,D,Amin', 'contains_C,G,C,G', 'contains_G,C,G,C', 'contains_F,C,G,Amin', 'contains_C,G,Amin,F', 'contains_Amin,F,C,G', 'contains_G,D,C,G', 'contains_C,G,D,C', 'contains_G,Amin,F,C', 'contains_D,C,G,D', 'contains_D,G,C,G', 'contains_C,D,G,C', 'contains_G,C,D,G', 'contains_G,C,G,D', 'contains_C,G,D,G', 'contains_D,G,C,D', 'contains_G,D,G,C', 'contains_G,Amin,F,G', 'contains_Amin,F,G,C', 'contains_F,G,Amin,F', 'contains_F,G,F,G', 'contains_Amin,G,F,C', 'contains_Amin,G,Amin,G', 'contains_Amin,F,G,Amin', 'contains_G,Amin,G,Amin', 'contains_G,Emin,C,G', 'contains_C,G,Amin,C', 'contains_G,Amin,C,G', 'contains_G,C,G,Amin', 'contains_C,D,G,D', 'contains_D,C,D,C', 'contains_F,Amin,G,F', 'contains_C,G,Emin,C', 'contains_Amin,C,G,Amin', 'contains_F,G,C,Amin', 'contains_C,Amin,F,G', 'contains_G,F,G,C', 'contains_G,Amin,G,F', 'contains_C,Amin,C,Amin', 'contains_G,F,Amin,G', 'contains_G,C,G,C,G', 'contains_C,G,C,G,C', 'contains_C,G,Amin,F,C', 'contains_F,C,G,Amin,F', 'contains_G,Amin,F,C,G', 'contains_Amin,F,C,G,Amin', 'contains_C,G,D,C,G', 'contains_G,D,C,G,D', 'contains_D,C,G,D,C', 'contains_D,G,C,D,G', 'contains_G,C,D,G,C', 'contains_C,D,G,C,D', 'contains_G,C,G,D,G', 'contains_G,D,G,C,G', 'contains_C,G,D,G,C', 'contains_D,G,C,G,D', 'contains_F,G,Amin,F,G', 'contains_G,Amin,F,G,Amin', 'contains_G,Amin,G,Amin,G', 'contains_Amin,G,Amin,G,Amin', 'contains_C,G,Emin,C,G', 'contains_Amin,F,G,Amin,F', 'contains_C,G,Amin,C,G', 'contains_G,F,G,F,G', 'contains_Amin,G,F,Amin,G', 'contains_C,Amin,F,G,C', 'contains_Emin,C,G,Emin,C', 'contains_G,Amin,C,G,Amin', 'contains_G,F,Amin,G,F', 'contains_F,G,F,G,F', 'contains_G,C,Amin,F,G', 'contains_F,G,C,Amin,F', 'contains_Amin,C,G,Amin,C', 'contains_D,G,C,G,C', 'contains_C,G,C,G,D', 'contains_G,Emin,C,G,Emin', 'contains_C,Amin,C,Amin,C', 'contains_F,Amin,G,F,Amin', 'track_id', 'on_hot100']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_folder_path = Path('../data/')\n",
    "data = pd.read_csv(data_folder_path / 'data_train_all.csv')\n",
    "data_columns = pd.read_csv(data_folder_path / 'data_train_all_columns.csv')\n",
    "\n",
    "print(\"Training data length:\", len(data))\n",
    "\n",
    "predictor_columns = data_columns[data_columns['column_type'].isin(['predictor_n_grams', 'predictor_continuous'])]['column_name'].tolist()\n",
    "print(f\"Number of predictor columns: {len(predictor_columns)}\")\n",
    "\n",
    "target_columns = data_columns[data_columns['column_type'] == 'target']['column_name'].tolist()\n",
    "print(f\"Target columns: {target_columns}\")\n",
    "\n",
    "# Merge back with the raw data so that we can use the extra column to filter later\n",
    "data_raw = pd.read_csv(data_folder_path / 'chordonomicon_raw.csv', low_memory=False)\n",
    "\n",
    "print(\"All columns in the raw data:\",list(data_raw.columns),'\\n')\n",
    "print(\"All columns in the training data:\",list(data.columns))\n",
    "\n",
    "keys = ['spotify_song_id', 'decade', 'main_genre']\n",
    "data = data.merge(data_raw, on=keys, how='left', suffixes=('', '_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9bbba8348e8802d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:15.779041Z",
     "start_time": "2025-11-02T01:07:15.776358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rows dropped, no missing values\n"
     ]
    }
   ],
   "source": [
    "# Select target variable and type\n",
    "\n",
    "# target_variable = 'decade'\n",
    "# target_type = 'multiclass'\n",
    "\n",
    "target_variable = 'main_genre'\n",
    "target_type = 'multiclass'\n",
    "\n",
    "# target_variable = 'spotify_popularity'\n",
    "# target_type = 'regression'\n",
    "\n",
    "# target_variable = 'on_hot100'\n",
    "# target_type = 'binary'\n",
    "\n",
    "# Drop NaN values in target variable from entire dataset\n",
    "if data[target_variable].isna().any():\n",
    "    data = data[data[target_variable].notna()].reset_index(drop=True)\n",
    "    print(f\"Rows after dropping NaN in {target_variable}: {len(data)}\")\n",
    "else:\n",
    "    print(f\"No rows dropped, no missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ee1b406c856c3e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:15.917178Z",
     "start_time": "2025-11-02T01:07:15.781063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-gram features: ['contains_G,C,G', 'contains_C,G,C', 'contains_C,G,D', 'contains_C,G,Amin', 'contains_C,D,G', 'contains_D,G,C', 'contains_Emin,C,G', 'contains_D,C,G', 'contains_G,Amin,F', 'contains_G,D,C', 'contains_Amin,G,F', 'contains_G,C,D', 'contains_Amin,F,G', 'contains_F,G,Amin', 'contains_G,F,G', 'contains_Amin,C,G', 'contains_G,Amin,G', 'contains_G,C,Amin', 'contains_Amin,G,C', 'contains_C,G,Emin', 'contains_G,Amin,C', 'contains_G,Emin,C', 'contains_F,Amin,G', 'contains_C,D,C', 'contains_C,Amin,G', 'contains_G,C,Emin', 'contains_Amin,G,Amin', 'contains_C,Amin,C', 'contains_Emin,G,C', 'contains_G,F,Amin', 'contains_Amin,D,G', 'contains_G,D,Amin'] \n",
      "\n",
      "4-gram features: ['contains_C,G,C,G', 'contains_G,C,G,C', 'contains_F,C,G,Amin', 'contains_C,G,Amin,F', 'contains_Amin,F,C,G', 'contains_G,D,C,G', 'contains_C,G,D,C', 'contains_G,Amin,F,C', 'contains_D,C,G,D', 'contains_D,G,C,G', 'contains_C,D,G,C', 'contains_G,C,D,G', 'contains_G,C,G,D', 'contains_C,G,D,G', 'contains_D,G,C,D', 'contains_G,D,G,C', 'contains_G,Amin,F,G', 'contains_Amin,F,G,C', 'contains_F,G,Amin,F', 'contains_F,G,F,G', 'contains_Amin,G,F,C', 'contains_Amin,G,Amin,G', 'contains_Amin,F,G,Amin', 'contains_G,Amin,G,Amin', 'contains_G,Emin,C,G', 'contains_C,G,Amin,C', 'contains_G,Amin,C,G', 'contains_G,C,G,Amin', 'contains_C,D,G,D', 'contains_D,C,D,C', 'contains_F,Amin,G,F', 'contains_C,G,Emin,C', 'contains_Amin,C,G,Amin', 'contains_F,G,C,Amin', 'contains_C,Amin,F,G', 'contains_G,F,G,C', 'contains_G,Amin,G,F', 'contains_C,Amin,C,Amin', 'contains_G,F,Amin,G'] \n",
      "\n",
      "5-gram features: ['contains_G,C,G,C,G', 'contains_C,G,C,G,C', 'contains_C,G,Amin,F,C', 'contains_F,C,G,Amin,F', 'contains_G,Amin,F,C,G', 'contains_Amin,F,C,G,Amin', 'contains_C,G,D,C,G', 'contains_G,D,C,G,D', 'contains_D,C,G,D,C', 'contains_D,G,C,D,G', 'contains_G,C,D,G,C', 'contains_C,D,G,C,D', 'contains_G,C,G,D,G', 'contains_G,D,G,C,G', 'contains_C,G,D,G,C', 'contains_D,G,C,G,D', 'contains_F,G,Amin,F,G', 'contains_G,Amin,F,G,Amin', 'contains_G,Amin,G,Amin,G', 'contains_Amin,G,Amin,G,Amin', 'contains_C,G,Emin,C,G', 'contains_Amin,F,G,Amin,F', 'contains_C,G,Amin,C,G', 'contains_G,F,G,F,G', 'contains_Amin,G,F,Amin,G', 'contains_C,Amin,F,G,C', 'contains_Emin,C,G,Emin,C', 'contains_G,Amin,C,G,Amin', 'contains_G,F,Amin,G,F', 'contains_F,G,F,G,F', 'contains_G,C,Amin,F,G', 'contains_F,G,C,Amin,F', 'contains_Amin,C,G,Amin,C', 'contains_D,G,C,G,C', 'contains_C,G,C,G,D', 'contains_G,Emin,C,G,Emin', 'contains_C,Amin,C,Amin,C', 'contains_F,Amin,G,F,Amin'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select features here\n",
    "\n",
    "#path_feature_selection = Path('../feature_selection_csv/feature_selection_csv')\n",
    "#feature_selection_csv = pd.read_csv(path_feature_selection / f'lasso_feature_importance_{target_variable}.csv')\n",
    "#print(feature_selection_csv.columns)\n",
    "\n",
    "# # Plot feature importance for all features\n",
    "# ax = plot_feature_importance(feature_selection_csv)\n",
    "\n",
    "# Plot feature importance for top N features\n",
    "#ax = plot_feature_importance_df(feature_selection_csv, top_n=30)\n",
    "\n",
    "# Select top N features or comment out to use all features\n",
    "#predictor_columns = feature_selection_csv.head(20)['feature'].astype(str).tolist()\n",
    "\n",
    "# extract n-gram features\n",
    "feature_3_grams = [x for x in data.columns if 'contains' in x and x.count(',') == 2]\n",
    "feature_4_grams = [x for x in data.columns if 'contains' in x and x.count(',') == 3]\n",
    "feature_5_grams = [x for x in data.columns if 'contains' in x and x.count(',') == 4]\n",
    "\n",
    "print(\"3-gram features:\",feature_3_grams,'\\n')\n",
    "print(\"4-gram features:\",feature_4_grams,'\\n')\n",
    "print(\"5-gram features:\",feature_5_grams,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae63d07a7c1345a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:16.617524Z",
     "start_time": "2025-11-02T01:07:15.921911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique decades after filter: [1990, 2000, 2010, 2020]\n"
     ]
    }
   ],
   "source": [
    "# Filter data here\n",
    "data_filtered = data[pd.to_numeric(data['decade'], errors='coerce') >= 1990].reset_index(drop=True)\n",
    "\n",
    "unique_decades = pd.to_numeric(data_filtered['decade'], errors='coerce').dropna().astype(int).unique()\n",
    "unique_decades = sorted(unique_decades)\n",
    "print(\"Unique decades after filter:\", unique_decades)\n",
    "\n",
    "# Make a dataframe with predictor features\n",
    "data_X = data_filtered[predictor_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e3f78f1878255cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:16.630989Z",
     "start_time": "2025-11-02T01:07:16.628497Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5-fold cross validation (stratified for classification to keep class ratios per fold)\n",
    "if target_variable == 'spotify_popularity':\n",
    "    # Use regular KFold for regression\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "else:\n",
    "    # Use StratifiedKFold for classification tasks\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=145)\n",
    "\n",
    "# When modeling genre, we need to encode the labels (all other target variables are numeric already)\n",
    "if target_variable == 'main_genre':\n",
    "    le = LabelEncoder()\n",
    "    data_y = le.fit_transform(data_filtered[target_variable])\n",
    "else:\n",
    "    data_y = data_filtered[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b73fb7-b9bb-40fc-b391-dd9ce82ad8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pop': 0.2414301698708168,\n",
       "         'rock': 0.19097752008951277,\n",
       "         'country': 0.1486467453815638,\n",
       "         'alternative': 0.14038794081516084,\n",
       "         'pop rock': 0.11276730593178563,\n",
       "         'punk': 0.04784316487093417,\n",
       "         'metal': 0.03363379576379271,\n",
       "         'rap': 0.028770842624977505,\n",
       "         'soul': 0.02039075765044639,\n",
       "         'jazz': 0.017570010093659775,\n",
       "         'reggae': 0.010887850832922544,\n",
       "         'electronic': 0.006693896074427048})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counter = Counter(data.main_genre)\n",
    "genre_counter_total = sum(genre_counter.values())\n",
    "genre_counter_relative = Counter({k : v/genre_counter_total for k, v in genre_counter.items()})\n",
    "genre_counter_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ecb13ec9f83da5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:16.736014Z",
     "start_time": "2025-11-02T01:07:16.642198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: main_genre\n",
      "Predictors: ['unique_chord_density', 'unique_5gram_density', 'min_triad_ratio', 'maj_triad_ratio', 'average_5overlap', 'average_4overlap', 'average_3overlap', 'average_2overlap', 'average_overlap', 'drone_ratio', 'contains_G,C,G,C,G', 'contains_C,G,C,G,C', 'contains_C,G,Amin,F,C', 'contains_F,C,G,Amin,F', 'contains_D,C,G,D,C', 'contains_Amin,F,C,G,Amin', 'contains_C,G,D,C,G', 'contains_G,D,C,G,D', 'contains_G,Amin,F,C,G', 'contains_G,F,Amin,G', 'contains_Amin,C,G,Amin', 'contains_G,Amin,G,F', 'contains_G,F,G,C', 'contains_C,Amin,F,G', 'contains_F,G,C,Amin', 'contains_D,G,C,D,G', 'contains_C,G,Emin,C', 'contains_F,Amin,G,F', 'contains_D,C,D,C', 'contains_C,D,G,D', 'contains_G,C,G,Amin', 'contains_G,Amin,C,G', 'contains_C,Amin,C,Amin', 'contains_G,C,D,G,C', 'contains_D,G,C,G,D', 'contains_G,C,G,D,G', 'contains_F,Amin,G,F,Amin', 'contains_C,Amin,C,Amin,C', 'contains_G,Emin,C,G,Emin', 'contains_C,G,C,G,D', 'contains_D,G,C,G,C', 'contains_Amin,C,G,Amin,C', 'contains_F,G,C,Amin,F', 'contains_G,C,Amin,F,G', 'contains_F,G,F,G,F', 'contains_G,F,Amin,G,F', 'contains_G,Amin,C,G,Amin', 'contains_Emin,C,G,Emin,C', 'contains_C,Amin,F,G,C', 'contains_Amin,G,F,Amin,G', 'contains_G,F,G,F,G', 'contains_C,G,Amin,C,G', 'contains_Amin,F,G,Amin,F', 'contains_C,G,Emin,C,G', 'contains_Amin,G,Amin,G,Amin', 'contains_G,Amin,G,Amin,G', 'contains_G,Amin,F,G,Amin', 'contains_F,G,Amin,F,G', 'contains_C,G,Amin,C', 'contains_C,G,D,G,C', 'contains_G,D,G,C,G', 'contains_C,D,G,C,D', 'contains_G,Emin,C,G', 'contains_F,G,Amin,F', 'contains_Amin,F,G,Amin', 'contains_C,D,C', 'contains_F,Amin,G', 'contains_G,Emin,C', 'contains_G,Amin,C', 'contains_C,G,Emin', 'contains_Amin,G,C', 'contains_G,C,Amin', 'contains_G,Amin,G', 'contains_Amin,C,G', 'contains_G,F,G', 'contains_F,G,Amin', 'contains_C,Amin,G', 'contains_Amin,F,G', 'contains_Amin,G,F', 'contains_G,D,C', 'contains_G,Amin,F', 'contains_D,C,G', 'contains_Emin,C,G', 'contains_D,G,C', 'contains_C,D,G', 'contains_C,G,Amin', 'contains_C,G,D', 'contains_C,G,C', 'contains_G,C,G', 'contains_G,C,D', 'contains_G,Amin,G,Amin', 'contains_G,C,Emin', 'contains_C,Amin,C', 'contains_Amin,G,Amin,G', 'contains_Amin,G,F,C', 'contains_F,G,F,G', 'contains_Amin,F,G,C', 'contains_G,Amin,F,G', 'contains_G,D,G,C', 'contains_D,G,C,D', 'contains_C,G,D,G', 'contains_G,C,G,D', 'contains_G,C,D,G', 'contains_C,D,G,C', 'contains_Amin,G,Amin', 'contains_D,G,C,G', 'contains_G,Amin,F,C', 'contains_G,D,C,G', 'contains_Amin,F,C,G', 'contains_C,G,Amin,F', 'contains_F,C,G,Amin', 'contains_G,C,G,C', 'contains_C,G,C,G', 'contains_G,D,Amin', 'contains_Amin,D,G', 'contains_G,F,Amin', 'contains_Emin,G,C', 'contains_D,C,G,D', 'contains_C,G,D,C'] \n",
      "\n",
      "\n",
      "Evaluating Dummy Baseline...\n",
      "Cross-validation folds: 5\n",
      "\n",
      "============================================================\n",
      "Dummy Baseline - Multiclass Target\n",
      "Parameters: strategy=most_frequent\n",
      "============================================================\n",
      "\n",
      "Test Performance (Out-of-Sample):\n",
      "------------------------------------------------------------\n",
      "Accuracy                      :  0.2552 (+/- 0.0000)\n",
      "Precision Micro               :  0.2552 (+/- 0.0000)\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Target variable:\",target_variable)\n",
    "print(\"Predictors:\",predictor_columns,'\\n')\n",
    "results_dummy = evaluate_dummy_baseline(data_X, data_y, cv=cv, target_type=target_type, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a193f5976fc655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:20.418289Z",
     "start_time": "2025-11-02T01:07:16.748062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: main_genre\n",
      "Predictors: ['unique_chord_density', 'unique_5gram_density', 'min_triad_ratio', 'maj_triad_ratio', 'average_5overlap', 'average_4overlap', 'average_3overlap', 'average_2overlap', 'average_overlap', 'drone_ratio', 'contains_G,C,G,C,G', 'contains_C,G,C,G,C', 'contains_C,G,Amin,F,C', 'contains_F,C,G,Amin,F', 'contains_D,C,G,D,C', 'contains_Amin,F,C,G,Amin', 'contains_C,G,D,C,G', 'contains_G,D,C,G,D', 'contains_G,Amin,F,C,G', 'contains_G,F,Amin,G', 'contains_Amin,C,G,Amin', 'contains_G,Amin,G,F', 'contains_G,F,G,C', 'contains_C,Amin,F,G', 'contains_F,G,C,Amin', 'contains_D,G,C,D,G', 'contains_C,G,Emin,C', 'contains_F,Amin,G,F', 'contains_D,C,D,C', 'contains_C,D,G,D', 'contains_G,C,G,Amin', 'contains_G,Amin,C,G', 'contains_C,Amin,C,Amin', 'contains_G,C,D,G,C', 'contains_D,G,C,G,D', 'contains_G,C,G,D,G', 'contains_F,Amin,G,F,Amin', 'contains_C,Amin,C,Amin,C', 'contains_G,Emin,C,G,Emin', 'contains_C,G,C,G,D', 'contains_D,G,C,G,C', 'contains_Amin,C,G,Amin,C', 'contains_F,G,C,Amin,F', 'contains_G,C,Amin,F,G', 'contains_F,G,F,G,F', 'contains_G,F,Amin,G,F', 'contains_G,Amin,C,G,Amin', 'contains_Emin,C,G,Emin,C', 'contains_C,Amin,F,G,C', 'contains_Amin,G,F,Amin,G', 'contains_G,F,G,F,G', 'contains_C,G,Amin,C,G', 'contains_Amin,F,G,Amin,F', 'contains_C,G,Emin,C,G', 'contains_Amin,G,Amin,G,Amin', 'contains_G,Amin,G,Amin,G', 'contains_G,Amin,F,G,Amin', 'contains_F,G,Amin,F,G', 'contains_C,G,Amin,C', 'contains_C,G,D,G,C', 'contains_G,D,G,C,G', 'contains_C,D,G,C,D', 'contains_G,Emin,C,G', 'contains_F,G,Amin,F', 'contains_Amin,F,G,Amin', 'contains_C,D,C', 'contains_F,Amin,G', 'contains_G,Emin,C', 'contains_G,Amin,C', 'contains_C,G,Emin', 'contains_Amin,G,C', 'contains_G,C,Amin', 'contains_G,Amin,G', 'contains_Amin,C,G', 'contains_G,F,G', 'contains_F,G,Amin', 'contains_C,Amin,G', 'contains_Amin,F,G', 'contains_Amin,G,F', 'contains_G,D,C', 'contains_G,Amin,F', 'contains_D,C,G', 'contains_Emin,C,G', 'contains_D,G,C', 'contains_C,D,G', 'contains_C,G,Amin', 'contains_C,G,D', 'contains_C,G,C', 'contains_G,C,G', 'contains_G,C,D', 'contains_G,Amin,G,Amin', 'contains_G,C,Emin', 'contains_C,Amin,C', 'contains_Amin,G,Amin,G', 'contains_Amin,G,F,C', 'contains_F,G,F,G', 'contains_Amin,F,G,C', 'contains_G,Amin,F,G', 'contains_G,D,G,C', 'contains_D,G,C,D', 'contains_C,G,D,G', 'contains_G,C,G,D', 'contains_G,C,D,G', 'contains_C,D,G,C', 'contains_Amin,G,Amin', 'contains_D,G,C,G', 'contains_G,Amin,F,C', 'contains_G,D,C,G', 'contains_Amin,F,C,G', 'contains_C,G,Amin,F', 'contains_F,C,G,Amin', 'contains_G,C,G,C', 'contains_C,G,C,G', 'contains_G,D,Amin', 'contains_Amin,D,G', 'contains_G,F,Amin', 'contains_Emin,G,C', 'contains_D,C,G,D', 'contains_C,G,D,C']\n",
      "\n",
      "Training Logistic Regression/Ridge...\n",
      "Cross-validation folds: 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget variable:\u001B[39m\u001B[38;5;124m\"\u001B[39m,target_variable)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPredictors:\u001B[39m\u001B[38;5;124m\"\u001B[39m,predictor_columns)\n\u001B[1;32m----> 4\u001B[0m results_lr \u001B[38;5;241m=\u001B[39m train_logistic_regression(\n\u001B[0;32m      5\u001B[0m     data_X,\n\u001B[0;32m      6\u001B[0m     data_y,\n\u001B[0;32m      7\u001B[0m     cv\u001B[38;5;241m=\u001B[39mcv,\n\u001B[0;32m      8\u001B[0m     target_type\u001B[38;5;241m=\u001B[39mtarget_type,\n\u001B[0;32m      9\u001B[0m     C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m,\n\u001B[0;32m     10\u001B[0m     penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     11\u001B[0m     solver\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlbfgs\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     12\u001B[0m     random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m\n\u001B[0;32m     13\u001B[0m )\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\fall-2025-harmonic-features-for-song-recommendations\\modeling\\functions.py:199\u001B[0m, in \u001B[0;36mtrain_logistic_regression\u001B[1;34m(X, y, cv, target_type, C, penalty, solver, max_iter, random_state)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCross-validation folds: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcv\u001B[38;5;241m.\u001B[39mget_n_splits()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# Perform cross-validation\u001B[39;00m\n\u001B[1;32m--> 199\u001B[0m scores \u001B[38;5;241m=\u001B[39m cross_validate(\n\u001B[0;32m    200\u001B[0m     model, X, y,\n\u001B[0;32m    201\u001B[0m     cv\u001B[38;5;241m=\u001B[39mcv,\n\u001B[0;32m    202\u001B[0m     scoring\u001B[38;5;241m=\u001B[39mscoring,\n\u001B[0;32m    203\u001B[0m     return_train_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    204\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    205\u001B[0m )\n\u001B[0;32m    207\u001B[0m \u001B[38;5;66;03m# Print results\u001B[39;00m\n\u001B[0;32m    208\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRidge Regression\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m target_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLogistic Regression\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:430\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n\u001B[0;32m    427\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[0;32m    429\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m--> 430\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[0;32m    431\u001B[0m     delayed(_fit_and_score)(\n\u001B[0;32m    432\u001B[0m         clone(estimator),\n\u001B[0;32m    433\u001B[0m         X,\n\u001B[0;32m    434\u001B[0m         y,\n\u001B[0;32m    435\u001B[0m         scorer\u001B[38;5;241m=\u001B[39mscorers,\n\u001B[0;32m    436\u001B[0m         train\u001B[38;5;241m=\u001B[39mtrain,\n\u001B[0;32m    437\u001B[0m         test\u001B[38;5;241m=\u001B[39mtest,\n\u001B[0;32m    438\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m    439\u001B[0m         parameters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    440\u001B[0m         fit_params\u001B[38;5;241m=\u001B[39mrouted_params\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mfit,\n\u001B[0;32m    441\u001B[0m         score_params\u001B[38;5;241m=\u001B[39mrouted_params\u001B[38;5;241m.\u001B[39mscorer\u001B[38;5;241m.\u001B[39mscore,\n\u001B[0;32m    442\u001B[0m         return_train_score\u001B[38;5;241m=\u001B[39mreturn_train_score,\n\u001B[0;32m    443\u001B[0m         return_times\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    444\u001B[0m         return_estimator\u001B[38;5;241m=\u001B[39mreturn_estimator,\n\u001B[0;32m    445\u001B[0m         error_score\u001B[38;5;241m=\u001B[39merror_score,\n\u001B[0;32m    446\u001B[0m     )\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m indices\n\u001B[0;32m    448\u001B[0m )\n\u001B[0;32m    450\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[0;32m    452\u001B[0m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1762\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train and fit logistic regression model here (uses ridge regression for regression variables)\n",
    "print(\"Target variable:\",target_variable)\n",
    "print(\"Predictors:\",predictor_columns)\n",
    "results_lr = train_logistic_regression(\n",
    "    data_X,\n",
    "    data_y,\n",
    "    cv=cv,\n",
    "    target_type=target_type,\n",
    "    C=1.0,\n",
    "    penalty='l2',\n",
    "    solver='lbfgs',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d147c7d098022c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:26.805948Z",
     "start_time": "2025-11-02T01:07:20.547209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Lasso model here\n",
    "print(\"Target variable:\",target_variable)\n",
    "print(\"Predictors:\",predictor_columns,'\\n')\n",
    "results_lasso = train_lasso(\n",
    "    data_X,\n",
    "    data_y,\n",
    "    cv=cv,\n",
    "    target_type=target_type,\n",
    "    alpha=0.1,\n",
    "    max_iter=5000,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110fbb4e9794f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:08:08.349295Z",
     "start_time": "2025-11-02T01:07:26.832276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Random Forests model here\n",
    "print(\"Target variable:\",target_variable)\n",
    "print(\"Predictors:\",predictor_columns,'\\n')\n",
    "results_rf = train_random_forest(\n",
    "    data_X,\n",
    "    data_y,\n",
    "    cv=cv,\n",
    "    target_type=target_type,\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
