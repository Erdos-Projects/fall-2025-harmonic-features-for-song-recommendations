{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:08.717421Z",
     "start_time": "2025-11-02T01:07:07.708589Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functions import *\n",
    "from functions_plots import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6030ff23331d5a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:15.718086Z",
     "start_time": "2025-11-02T01:07:08.719760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 255606\n",
      "Number of predictor columns: 119\n",
      "Target columns: ['spotify_popularity', 'on_hot100', 'decade', 'main_genre']\n",
      "All columns in the raw data: ['id', 'chords', 'release_date', 'genres', 'decade', 'rock_genre', 'artist_id', 'main_genre', 'spotify_song_id', 'spotify_artist_id'] \n",
      "\n",
      "All columns in the training data: ['chords_x', 'simplified_chords_x', 'spotify_song_id', 'chords_y', 'missing_notes', 'simplified_chords_y', 'drone_ratio', 'average_overlap', 'average_2overlap', 'average_3overlap', 'average_4overlap', 'average_5overlap', 'maj_triad_ratio', 'min_triad_ratio', 'chords', 'unique_5gram_density', 'unique_chord_density', 'simplified_chords', 'decade', 'main_genre', 'spotify_track_id', 'spotify_artist_id', 'spotify_success', 'spotify_track_name', 'spotify_artists', 'spotify_album_name', 'spotify_release_date', 'spotify_popularity', 'spotify_duration_ms', 'spotify_artist_name', 'spotify_genres', 'spotify_artist_popularity', 'spotify_followers', 'contains_G,C,G', 'contains_C,G,C', 'contains_C,G,D', 'contains_C,G,Amin', 'contains_C,D,G', 'contains_D,G,C', 'contains_Emin,C,G', 'contains_D,C,G', 'contains_G,Amin,F', 'contains_G,D,C', 'contains_Amin,G,F', 'contains_G,C,D', 'contains_Amin,F,G', 'contains_F,G,Amin', 'contains_G,F,G', 'contains_Amin,C,G', 'contains_G,Amin,G', 'contains_G,C,Amin', 'contains_Amin,G,C', 'contains_C,G,Emin', 'contains_G,Amin,C', 'contains_G,Emin,C', 'contains_F,Amin,G', 'contains_C,D,C', 'contains_C,Amin,G', 'contains_G,C,Emin', 'contains_Amin,G,Amin', 'contains_C,Amin,C', 'contains_Emin,G,C', 'contains_G,F,Amin', 'contains_Amin,D,G', 'contains_G,D,Amin', 'contains_C,G,C,G', 'contains_G,C,G,C', 'contains_F,C,G,Amin', 'contains_C,G,Amin,F', 'contains_Amin,F,C,G', 'contains_G,D,C,G', 'contains_C,G,D,C', 'contains_G,Amin,F,C', 'contains_D,C,G,D', 'contains_D,G,C,G', 'contains_C,D,G,C', 'contains_G,C,D,G', 'contains_G,C,G,D', 'contains_C,G,D,G', 'contains_D,G,C,D', 'contains_G,D,G,C', 'contains_G,Amin,F,G', 'contains_Amin,F,G,C', 'contains_F,G,Amin,F', 'contains_F,G,F,G', 'contains_Amin,G,F,C', 'contains_Amin,G,Amin,G', 'contains_Amin,F,G,Amin', 'contains_G,Amin,G,Amin', 'contains_G,Emin,C,G', 'contains_C,G,Amin,C', 'contains_G,Amin,C,G', 'contains_G,C,G,Amin', 'contains_C,D,G,D', 'contains_D,C,D,C', 'contains_F,Amin,G,F', 'contains_C,G,Emin,C', 'contains_Amin,C,G,Amin', 'contains_F,G,C,Amin', 'contains_C,Amin,F,G', 'contains_G,F,G,C', 'contains_G,Amin,G,F', 'contains_C,Amin,C,Amin', 'contains_G,F,Amin,G', 'contains_G,C,G,C,G', 'contains_C,G,C,G,C', 'contains_C,G,Amin,F,C', 'contains_F,C,G,Amin,F', 'contains_G,Amin,F,C,G', 'contains_Amin,F,C,G,Amin', 'contains_C,G,D,C,G', 'contains_G,D,C,G,D', 'contains_D,C,G,D,C', 'contains_D,G,C,D,G', 'contains_G,C,D,G,C', 'contains_C,D,G,C,D', 'contains_G,C,G,D,G', 'contains_G,D,G,C,G', 'contains_C,G,D,G,C', 'contains_D,G,C,G,D', 'contains_F,G,Amin,F,G', 'contains_G,Amin,F,G,Amin', 'contains_G,Amin,G,Amin,G', 'contains_Amin,G,Amin,G,Amin', 'contains_C,G,Emin,C,G', 'contains_Amin,F,G,Amin,F', 'contains_C,G,Amin,C,G', 'contains_G,F,G,F,G', 'contains_Amin,G,F,Amin,G', 'contains_C,Amin,F,G,C', 'contains_Emin,C,G,Emin,C', 'contains_G,Amin,C,G,Amin', 'contains_G,F,Amin,G,F', 'contains_F,G,F,G,F', 'contains_G,C,Amin,F,G', 'contains_F,G,C,Amin,F', 'contains_Amin,C,G,Amin,C', 'contains_D,G,C,G,C', 'contains_C,G,C,G,D', 'contains_G,Emin,C,G,Emin', 'contains_C,Amin,C,Amin,C', 'contains_F,Amin,G,F,Amin', 'track_id', 'on_hot100']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_folder_path = Path('../data/')\n",
    "data = pd.read_csv(data_folder_path / 'data_train_all.csv')\n",
    "data_columns = pd.read_csv(data_folder_path / 'data_train_all_columns.csv')\n",
    "\n",
    "print(\"Training data length:\", len(data))\n",
    "\n",
    "predictor_columns = data_columns[data_columns['column_type'].isin(['predictor_n_grams', 'predictor_continuous'])]['column_name'].tolist()\n",
    "print(f\"Number of predictor columns: {len(predictor_columns)}\")\n",
    "\n",
    "target_columns = data_columns[data_columns['column_type'] == 'target']['column_name'].tolist()\n",
    "print(f\"Target columns: {target_columns}\")\n",
    "\n",
    "# Merge back with the raw data so that we can use the extra column to filter later\n",
    "data_raw = pd.read_csv(data_folder_path / 'chordonomicon_raw.csv', low_memory=False)\n",
    "\n",
    "print(\"All columns in the raw data:\",list(data_raw.columns),'\\n')\n",
    "print(\"All columns in the training data:\",list(data.columns))\n",
    "\n",
    "keys = ['spotify_song_id', 'decade', 'main_genre']\n",
    "data = data.merge(data_raw, on=keys, how='left', suffixes=('', '_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9bbba8348e8802d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:15.779041Z",
     "start_time": "2025-11-02T01:07:15.776358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rows dropped, no missing values\n"
     ]
    }
   ],
   "source": [
    "# Select target variable and type\n",
    "\n",
    "# target_variable = 'decade'\n",
    "# target_type = 'multiclass'\n",
    "\n",
    "target_variable = 'main_genre'\n",
    "target_type = 'multiclass'\n",
    "\n",
    "# target_variable = 'spotify_popularity'\n",
    "# target_type = 'regression'\n",
    "\n",
    "# target_variable = 'on_hot100'\n",
    "# target_type = 'binary'\n",
    "\n",
    "# Drop NaN values in target variable from entire dataset\n",
    "if data[target_variable].isna().any():\n",
    "    data = data[data[target_variable].notna()].reset_index(drop=True)\n",
    "    print(f\"Rows after dropping NaN in {target_variable}: {len(data)}\")\n",
    "else:\n",
    "    print(f\"No rows dropped, no missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ee1b406c856c3e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:15.917178Z",
     "start_time": "2025-11-02T01:07:15.781063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-gram features: ['contains_G,C,G', 'contains_C,G,C', 'contains_C,G,D', 'contains_C,G,Amin', 'contains_C,D,G', 'contains_D,G,C', 'contains_Emin,C,G', 'contains_D,C,G', 'contains_G,Amin,F', 'contains_G,D,C', 'contains_Amin,G,F', 'contains_G,C,D', 'contains_Amin,F,G', 'contains_F,G,Amin', 'contains_G,F,G', 'contains_Amin,C,G', 'contains_G,Amin,G', 'contains_G,C,Amin', 'contains_Amin,G,C', 'contains_C,G,Emin', 'contains_G,Amin,C', 'contains_G,Emin,C', 'contains_F,Amin,G', 'contains_C,D,C', 'contains_C,Amin,G', 'contains_G,C,Emin', 'contains_Amin,G,Amin', 'contains_C,Amin,C', 'contains_Emin,G,C', 'contains_G,F,Amin', 'contains_Amin,D,G', 'contains_G,D,Amin'] \n",
      "\n",
      "4-gram features: ['contains_C,G,C,G', 'contains_G,C,G,C', 'contains_F,C,G,Amin', 'contains_C,G,Amin,F', 'contains_Amin,F,C,G', 'contains_G,D,C,G', 'contains_C,G,D,C', 'contains_G,Amin,F,C', 'contains_D,C,G,D', 'contains_D,G,C,G', 'contains_C,D,G,C', 'contains_G,C,D,G', 'contains_G,C,G,D', 'contains_C,G,D,G', 'contains_D,G,C,D', 'contains_G,D,G,C', 'contains_G,Amin,F,G', 'contains_Amin,F,G,C', 'contains_F,G,Amin,F', 'contains_F,G,F,G', 'contains_Amin,G,F,C', 'contains_Amin,G,Amin,G', 'contains_Amin,F,G,Amin', 'contains_G,Amin,G,Amin', 'contains_G,Emin,C,G', 'contains_C,G,Amin,C', 'contains_G,Amin,C,G', 'contains_G,C,G,Amin', 'contains_C,D,G,D', 'contains_D,C,D,C', 'contains_F,Amin,G,F', 'contains_C,G,Emin,C', 'contains_Amin,C,G,Amin', 'contains_F,G,C,Amin', 'contains_C,Amin,F,G', 'contains_G,F,G,C', 'contains_G,Amin,G,F', 'contains_C,Amin,C,Amin', 'contains_G,F,Amin,G'] \n",
      "\n",
      "5-gram features: ['contains_G,C,G,C,G', 'contains_C,G,C,G,C', 'contains_C,G,Amin,F,C', 'contains_F,C,G,Amin,F', 'contains_G,Amin,F,C,G', 'contains_Amin,F,C,G,Amin', 'contains_C,G,D,C,G', 'contains_G,D,C,G,D', 'contains_D,C,G,D,C', 'contains_D,G,C,D,G', 'contains_G,C,D,G,C', 'contains_C,D,G,C,D', 'contains_G,C,G,D,G', 'contains_G,D,G,C,G', 'contains_C,G,D,G,C', 'contains_D,G,C,G,D', 'contains_F,G,Amin,F,G', 'contains_G,Amin,F,G,Amin', 'contains_G,Amin,G,Amin,G', 'contains_Amin,G,Amin,G,Amin', 'contains_C,G,Emin,C,G', 'contains_Amin,F,G,Amin,F', 'contains_C,G,Amin,C,G', 'contains_G,F,G,F,G', 'contains_Amin,G,F,Amin,G', 'contains_C,Amin,F,G,C', 'contains_Emin,C,G,Emin,C', 'contains_G,Amin,C,G,Amin', 'contains_G,F,Amin,G,F', 'contains_F,G,F,G,F', 'contains_G,C,Amin,F,G', 'contains_F,G,C,Amin,F', 'contains_Amin,C,G,Amin,C', 'contains_D,G,C,G,C', 'contains_C,G,C,G,D', 'contains_G,Emin,C,G,Emin', 'contains_C,Amin,C,Amin,C', 'contains_F,Amin,G,F,Amin'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select features here\n",
    "\n",
    "#path_feature_selection = Path('../feature_selection/feature_selection')\n",
    "#feature_selection = pd.read_csv(path_feature_selection / f'lasso_feature_importance_{target_variable}.csv')\n",
    "#print(feature_selection.columns)\n",
    "\n",
    "# # Plot feature importance for all features\n",
    "# ax = plot_feature_importance(feature_selection)\n",
    "\n",
    "# Plot feature importance for top N features\n",
    "#ax = plot_feature_importance_df(feature_selection, top_n=30)\n",
    "\n",
    "# Select top N features or comment out to use all features\n",
    "#predictor_columns = feature_selection.head(20)['feature'].astype(str).tolist()\n",
    "\n",
    "# extract n-gram features\n",
    "feature_3_grams = [x for x in data.columns if 'contains' in x and x.count(',') == 2]\n",
    "feature_4_grams = [x for x in data.columns if 'contains' in x and x.count(',') == 3]\n",
    "feature_5_grams = [x for x in data.columns if 'contains' in x and x.count(',') == 4]\n",
    "\n",
    "print(\"3-gram features:\",feature_3_grams,'\\n')\n",
    "print(\"4-gram features:\",feature_4_grams,'\\n')\n",
    "print(\"5-gram features:\",feature_5_grams,'\\n')\n",
    "\n",
    "predictor_columns = feature_3_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae63d07a7c1345a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:16.617524Z",
     "start_time": "2025-11-02T01:07:15.921911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique decades after filter: [1990, 2000, 2010, 2020]\n"
     ]
    }
   ],
   "source": [
    "# Filter data here\n",
    "data_filtered = data[pd.to_numeric(data['decade'], errors='coerce') >= 1990].reset_index(drop=True)\n",
    "\n",
    "unique_decades = pd.to_numeric(data_filtered['decade'], errors='coerce').dropna().astype(int).unique()\n",
    "unique_decades = sorted(unique_decades)\n",
    "print(\"Unique decades after filter:\", unique_decades)\n",
    "\n",
    "# Make a dataframe with predictor features\n",
    "data_X = data_filtered[predictor_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e3f78f1878255cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:16.630989Z",
     "start_time": "2025-11-02T01:07:16.628497Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5-fold cross validation (stratified for classification to keep class ratios per fold)\n",
    "if target_variable == 'spotify_popularity':\n",
    "    # Use regular KFold for regression\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "else:\n",
    "    # Use StratifiedKFold for classification tasks\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=145)\n",
    "\n",
    "# When modeling genre, we need to encode the labels (all other target variables are numeric already)\n",
    "if target_variable == 'main_genre':\n",
    "    le = LabelEncoder()\n",
    "    data_y = le.fit_transform(data_filtered[target_variable])\n",
    "else:\n",
    "    data_y = data_filtered[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04b73fb7-b9bb-40fc-b391-dd9ce82ad8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pop': 0.2414301698708168,\n",
       "         'rock': 0.19097752008951277,\n",
       "         'country': 0.1486467453815638,\n",
       "         'alternative': 0.14038794081516084,\n",
       "         'pop rock': 0.11276730593178563,\n",
       "         'punk': 0.04784316487093417,\n",
       "         'metal': 0.03363379576379271,\n",
       "         'rap': 0.028770842624977505,\n",
       "         'soul': 0.02039075765044639,\n",
       "         'jazz': 0.017570010093659775,\n",
       "         'reggae': 0.010887850832922544,\n",
       "         'electronic': 0.006693896074427048})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counter = Counter(data.main_genre)\n",
    "genre_counter_total = sum(genre_counter.values())\n",
    "genre_counter_relative = Counter({k : v/genre_counter_total for k, v in genre_counter.items()})\n",
    "genre_counter_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81ecb13ec9f83da5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:16.736014Z",
     "start_time": "2025-11-02T01:07:16.642198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: main_genre\n",
      "Predictors: ['contains_G,C,G', 'contains_C,G,C', 'contains_C,G,D', 'contains_C,G,Amin', 'contains_C,D,G', 'contains_D,G,C', 'contains_Emin,C,G', 'contains_D,C,G', 'contains_G,Amin,F', 'contains_G,D,C', 'contains_Amin,G,F', 'contains_G,C,D', 'contains_Amin,F,G', 'contains_F,G,Amin', 'contains_G,F,G', 'contains_Amin,C,G', 'contains_G,Amin,G', 'contains_G,C,Amin', 'contains_Amin,G,C', 'contains_C,G,Emin', 'contains_G,Amin,C', 'contains_G,Emin,C', 'contains_F,Amin,G', 'contains_C,D,C', 'contains_C,Amin,G', 'contains_G,C,Emin', 'contains_Amin,G,Amin', 'contains_C,Amin,C', 'contains_Emin,G,C', 'contains_G,F,Amin', 'contains_Amin,D,G', 'contains_G,D,Amin'] \n",
      "\n",
      "\n",
      "Evaluating Dummy Baseline...\n",
      "Cross-validation folds: 5\n",
      "\n",
      "============================================================\n",
      "Dummy Baseline - Multiclass Target\n",
      "Parameters: strategy=most_frequent\n",
      "============================================================\n",
      "\n",
      "Test Performance (Out-of-Sample):\n",
      "------------------------------------------------------------\n",
      "Accuracy                      :  0.2552 (+/- 0.0000)\n",
      "Precision Micro               :  0.2552 (+/- 0.0000)\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Target variable:\",target_variable)\n",
    "print(\"Predictors:\",predictor_columns,'\\n')\n",
    "results_dummy = evaluate_dummy_baseline(data_X, data_y, cv=cv, target_type=target_type, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7a193f5976fc655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:20.418289Z",
     "start_time": "2025-11-02T01:07:16.748062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: main_genre\n",
      "Predictors: ['contains_G,C,G', 'contains_C,G,C', 'contains_C,G,D', 'contains_C,G,Amin', 'contains_C,D,G', 'contains_D,G,C', 'contains_Emin,C,G', 'contains_D,C,G', 'contains_G,Amin,F', 'contains_G,D,C', 'contains_Amin,G,F', 'contains_G,C,D', 'contains_Amin,F,G', 'contains_F,G,Amin', 'contains_G,F,G', 'contains_Amin,C,G', 'contains_G,Amin,G', 'contains_G,C,Amin', 'contains_Amin,G,C', 'contains_C,G,Emin', 'contains_G,Amin,C', 'contains_G,Emin,C', 'contains_F,Amin,G', 'contains_C,D,C', 'contains_C,Amin,G', 'contains_G,C,Emin', 'contains_Amin,G,Amin', 'contains_C,Amin,C', 'contains_Emin,G,C', 'contains_G,F,Amin', 'contains_Amin,D,G', 'contains_G,D,Amin']\n",
      "\n",
      "Training Logistic Regression/Ridge...\n",
      "Cross-validation folds: 5\n",
      "\n",
      "============================================================\n",
      "Logistic Regression - Multiclass Target\n",
      "Parameters: C=1.0, penalty=l2, solver=lbfgs\n",
      "============================================================\n",
      "\n",
      "Test Performance (Out-of-Sample):\n",
      "------------------------------------------------------------\n",
      "Accuracy                      :  0.2743 (+/- 0.0005)\n",
      "F1 Micro                      :  0.2743 (+/- 0.0005)\n",
      "Precision Micro               :  0.2743 (+/- 0.0005)\n",
      "Recall Micro                  :  0.2743 (+/- 0.0005)\n",
      "\n",
      "Train Performance (In-Sample):\n",
      "------------------------------------------------------------\n",
      "Accuracy                      :  0.2748 (+/- 0.0002)\n",
      "F1 Micro                      :  0.2748 (+/- 0.0002)\n",
      "Precision Micro               :  0.2748 (+/- 0.0002)\n",
      "Recall Micro                  :  0.2748 (+/- 0.0002)\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and fit logistic regression model here (uses ridge regression for regression variables)\n",
    "print(\"Target variable:\",target_variable)\n",
    "print(\"Predictors:\",predictor_columns)\n",
    "results_lr = train_logistic_regression(\n",
    "    data_X,\n",
    "    data_y,\n",
    "    cv=cv,\n",
    "    target_type=target_type,\n",
    "    C=1.0,\n",
    "    penalty='l2',\n",
    "    solver='lbfgs',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8d147c7d098022c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:07:26.805948Z",
     "start_time": "2025-11-02T01:07:20.547209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: main_genre\n",
      "Predictors: ['contains_G,C,G', 'contains_C,G,C', 'contains_C,G,D', 'contains_C,G,Amin', 'contains_C,D,G', 'contains_D,G,C', 'contains_Emin,C,G', 'contains_D,C,G', 'contains_G,Amin,F', 'contains_G,D,C', 'contains_Amin,G,F', 'contains_G,C,D', 'contains_Amin,F,G', 'contains_F,G,Amin', 'contains_G,F,G', 'contains_Amin,C,G', 'contains_G,Amin,G', 'contains_G,C,Amin', 'contains_Amin,G,C', 'contains_C,G,Emin', 'contains_G,Amin,C', 'contains_G,Emin,C', 'contains_F,Amin,G', 'contains_C,D,C', 'contains_C,Amin,G', 'contains_G,C,Emin', 'contains_Amin,G,Amin', 'contains_C,Amin,C', 'contains_Emin,G,C', 'contains_G,F,Amin', 'contains_Amin,D,G', 'contains_G,D,Amin'] \n",
      "\n",
      "\n",
      "üìê Training Lasso...\n",
      "Cross-validation folds: 5\n",
      "\n",
      "============================================================\n",
      "Lasso - Multiclass Target\n",
      "Parameters: alpha=0.1, max_iter=5000\n",
      "============================================================\n",
      "\n",
      "Test Performance (Out-of-Sample):\n",
      "------------------------------------------------------------\n",
      "Accuracy                      :  0.2743 (+/- 0.0005)\n",
      "F1 Micro                      :  0.2743 (+/- 0.0005)\n",
      "Precision Micro               :  0.2743 (+/- 0.0005)\n",
      "Recall Micro                  :  0.2743 (+/- 0.0005)\n",
      "\n",
      "Train Performance (In-Sample):\n",
      "------------------------------------------------------------\n",
      "Accuracy                      :  0.2748 (+/- 0.0002)\n",
      "F1 Micro                      :  0.2748 (+/- 0.0002)\n",
      "Precision Micro               :  0.2748 (+/- 0.0002)\n",
      "Recall Micro                  :  0.2748 (+/- 0.0002)\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and fit Lasso model here\n",
    "print(\"Target variable:\",target_variable)\n",
    "print(\"Predictors:\",predictor_columns,'\\n')\n",
    "results_lasso = train_lasso(\n",
    "    data_X,\n",
    "    data_y,\n",
    "    cv=cv,\n",
    "    target_type=target_type,\n",
    "    alpha=0.1,\n",
    "    max_iter=5000,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d110fbb4e9794f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T01:08:08.349295Z",
     "start_time": "2025-11-02T01:07:26.832276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: main_genre\n",
      "Predictors: ['contains_G,C,G', 'contains_C,G,C', 'contains_C,G,D', 'contains_C,G,Amin', 'contains_C,D,G', 'contains_D,G,C', 'contains_Emin,C,G', 'contains_D,C,G', 'contains_G,Amin,F', 'contains_G,D,C', 'contains_Amin,G,F', 'contains_G,C,D', 'contains_Amin,F,G', 'contains_F,G,Amin', 'contains_G,F,G', 'contains_Amin,C,G', 'contains_G,Amin,G', 'contains_G,C,Amin', 'contains_Amin,G,C', 'contains_C,G,Emin', 'contains_G,Amin,C', 'contains_G,Emin,C', 'contains_F,Amin,G', 'contains_C,D,C', 'contains_C,Amin,G', 'contains_G,C,Emin', 'contains_Amin,G,Amin', 'contains_C,Amin,C', 'contains_Emin,G,C', 'contains_G,F,Amin', 'contains_Amin,D,G', 'contains_G,D,Amin'] \n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Cross-validation folds: 5\n",
      "\n",
      "============================================================\n",
      "Random Forest - Multiclass Target\n",
      "Parameters: n_estimators=100, max_depth=5, min_samples_leaf=1\n",
      "============================================================\n",
      "\n",
      "Test Performance (Out-of-Sample):\n",
      "------------------------------------------------------------\n",
      "Accuracy                      :  0.2723 (+/- 0.0006)\n",
      "F1 Micro                      :  0.2723 (+/- 0.0006)\n",
      "Precision Micro               :  0.2723 (+/- 0.0006)\n",
      "Recall Micro                  :  0.2723 (+/- 0.0006)\n",
      "\n",
      "Train Performance (In-Sample):\n",
      "------------------------------------------------------------\n",
      "Accuracy                      :  0.2727 (+/- 0.0002)\n",
      "F1 Micro                      :  0.2727 (+/- 0.0002)\n",
      "Precision Micro               :  0.2727 (+/- 0.0002)\n",
      "Recall Micro                  :  0.2727 (+/- 0.0002)\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and fit Random Forests model here\n",
    "print(\"Target variable:\",target_variable)\n",
    "print(\"Predictors:\",predictor_columns,'\\n')\n",
    "results_rf = train_random_forest(\n",
    "    data_X,\n",
    "    data_y,\n",
    "    cv=cv,\n",
    "    target_type=target_type,\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
