{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9e89b9-eaf9-4e8e-99d4-724fd7d971c9",
   "metadata": {},
   "source": [
    "This notebook is about determining which $n$-grams we should make into features. More specifically, for which $x$ should we add a feature of the form \"contains a harmonically equivalent $n$-gram to $x$\"?\n",
    "In theory, we could do this for any harmonically unique n-gram for $n=1,2,3,4,...$ but that would be infinitely many different features, which is obviously impossible.\n",
    "\n",
    "So how to pick which ones are good? \n",
    "\n",
    "* Based on domain knowledge, sequences longer than, say, $10$ are definitely not going to be useful for distinguishing genre. First of all, I can't imagine there are any $10$-grams which actually occur in more than $1\\%$ of the songs, but also musically speaking, a chord progression of length $10$ is usually longer than an entire \"musical idea\" or \"phrase.\" Even $10$ is pushing it, really based on this idea we shouldn't expect anything longer than $6$ to be very useful.\n",
    "* Even if we wanted to look at all the harmonically unique $n$-grams for $1 \\le n \\le 6$, that would be far too many. There are $44$ harmonically unique $1$-grams in the training set, $5903$ unqiue $2$-grams. To determine the list of unique $2$-grams takes a three minute computation, but I project to determine the counts for unique 3-grams, the computation would take around $24$ hours.\n",
    "* Because of the above, we need to heavily filter our choice of n-grams. The first easy criterion is to only consider $n$-grams which appear in some sample size threshold of the data set, maybe $1-10\\%$. The table below gives concrete numbers for the number of unique $1$-grams and $2$-grams after restricting to higher and higher relative sample size requirements. Based on the table, I think a threshold cutoff of around $1\\%$ is a good sweet spot.\n",
    "\n",
    "| $n$      | $n$-grams | $1\\%$ | $2\\%$ | $5\\%$ |$10\\%$ |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| 1 | 44 | 22 | 20 | 15 | 10\n",
    "| 2 | 5903 | 237 | 173 | 105 | 62 |\n",
    "\n",
    "* Because compiling a full list of unique $3$-grams seems to be computationally taxing (and for $4, 5, 6$ definitely infeasible), we are probably going to need to simplify something. Even though it takes really long to compile the list of unique $3$-grams, it is very fast to compile the complete list of raw $3$-grams (less than $30$ seconds). This computation doesn't scale up much with $n$, in fact even up to $n=9$ it is still well under a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8ea9c5-c04d-4ce5-9e90-6f3304acd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "data_folder_path = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c032917b-bddd-4151-9d50-eecd1b0acf83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in the database\n",
    "df = pd.read_csv(data_folder_path + 'clean_test.csv', low_memory=False)\n",
    "num_songs = len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4a0fa3-81ff-4269-979b-c6ec5a0ad1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs: 255606\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chords</th>\n",
       "      <th>simplified_chords</th>\n",
       "      <th>decade</th>\n",
       "      <th>main_genre</th>\n",
       "      <th>spotify_song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;intro_1&gt; G A Fsmin Bmin G A Fsmin Bmin &lt;verse...</td>\n",
       "      <td>G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>7vpGKEUPrA4UEsS4o4W1tP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C F G C F G F Dmin G C F Dmin G C F G C F G F ...</td>\n",
       "      <td>C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>7MTpNQUBKyyymbS3gPuqwQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C F C G Amin G F C F C G Amin G F C G C F C G ...</td>\n",
       "      <td>C,F,C,G,Amin,G,F,C,F,C,G,Amin,G,F,C,G,C,F,C,G,...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>alternative</td>\n",
       "      <td>6jIIMhcBPRTrkTWh3PXIc7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amin G Gmin B Amin G Gmin B Amin G Gmin B Amin...</td>\n",
       "      <td>Amin,G,Gmin,B,Amin,G,Gmin,B,Amin,G,Gmin,B,Amin...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>2zAfQdoOeYujy7QIgDUq9p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;verse_1&gt; D Dmaj7 G/D A/D D Dmaj7 G/D A/D &lt;cho...</td>\n",
       "      <td>D,Dmaj7,G,A,D,Dmaj7,G,A,G,D,Emin,D,A,G,D,Emin,...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>metal</td>\n",
       "      <td>40rChMoUd1VXb4TKgTuTSP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chords  \\\n",
       "0  <intro_1> G A Fsmin Bmin G A Fsmin Bmin <verse...   \n",
       "1  C F G C F G F Dmin G C F Dmin G C F G C F G F ...   \n",
       "2  C F C G Amin G F C F C G Amin G F C G C F C G ...   \n",
       "3  Amin G Gmin B Amin G Gmin B Amin G Gmin B Amin...   \n",
       "4  <verse_1> D Dmaj7 G/D A/D D Dmaj7 G/D A/D <cho...   \n",
       "\n",
       "                                   simplified_chords  decade   main_genre  \\\n",
       "0  G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G,A,Fsmin,Bmin,G...  2010.0          pop   \n",
       "1  C,F,G,C,F,G,F,Dmin,G,C,F,Dmin,G,C,F,G,C,F,G,F,...  2000.0  alternative   \n",
       "2  C,F,C,G,Amin,G,F,C,F,C,G,Amin,G,F,C,G,C,F,C,G,...  2000.0  alternative   \n",
       "3  Amin,G,Gmin,B,Amin,G,Gmin,B,Amin,G,Gmin,B,Amin...  2010.0          pop   \n",
       "4  D,Dmaj7,G,A,D,Dmaj7,G,A,G,D,Emin,D,A,G,D,Emin,...  2010.0        metal   \n",
       "\n",
       "          spotify_song_id  \n",
       "0  7vpGKEUPrA4UEsS4o4W1tP  \n",
       "1  7MTpNQUBKyyymbS3gPuqwQ  \n",
       "2  6jIIMhcBPRTrkTWh3PXIc7  \n",
       "3  2zAfQdoOeYujy7QIgDUq9p  \n",
       "4  40rChMoUd1VXb4TKgTuTSP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Number of songs:\",num_songs)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e1c9d6-378d-4212-ad03-1fc40eeaafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify limitations on n, and sample size threshold\n",
    "n_max = 10\n",
    "n_range = list(range(1, n_max+1))\n",
    "relative_sample_size_threshold = 0.01\n",
    "sample_size_threshold = relative_sample_size_threshold * num_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a882886-505a-45b1-ad9c-8d0ca9b1e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size threshold: 2556\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample size threshold:\",int(sample_size_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80a575ac-328c-4090-adf6-de74ab95b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the counter json files\n",
    "with open(data_folder_path + 'harmonically_unique_1_gram_counts.json') as file:\n",
    "    unique_1_gram_counter = Counter(json.load(file))\n",
    "with open(data_folder_path + 'harmonically_unique_2_gram_counts.json') as file:\n",
    "    unique_2_gram_counter = Counter(json.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15cc0bf1-714a-46ac-8bf2-5ddf98a242c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('G', 12777669),\n",
       " ('Fsmin', 4627067),\n",
       " ('Gs7', 594128),\n",
       " ('Emin7', 548196),\n",
       " ('Cno3d', 353019),\n",
       " ('Dmaj7', 277398),\n",
       " ('Dsus4', 222221),\n",
       " ('Cadd9', 109279),\n",
       " ('A9', 34895),\n",
       " ('Eminadd13', 31283)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_1_gram_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ee8b10-daf4-41d0-abb4-3117c2860d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F,C', 2945027),\n",
       " ('C,F', 2359941),\n",
       " ('G,A', 1230986),\n",
       " ('G,F', 1063415),\n",
       " ('G,Amin', 995946),\n",
       " ('Bmin,G', 861782),\n",
       " ('Amin,G', 852222),\n",
       " ('A,Fsmin', 822318),\n",
       " ('Amin,C', 700118),\n",
       " ('Eb,Gmin', 597621)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_2_gram_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "991ff25a-46c0-41d9-ae31-4b0c68e4526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_counter(my_counter, threshold):\n",
    "    return Counter({ key : value for key, value in my_counter.items() if value >= threshold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b8a054-007a-4337-98d7-83eafe3f857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate any entries which don't meet the sample size threshold\n",
    "filtered_1_gram_counter = get_filtered_counter(unique_1_gram_counter, sample_size_threshold)\n",
    "filtered_2_gram_counter = get_filtered_counter(unique_2_gram_counter, sample_size_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3748302-7bc6-496a-aecf-b6e4c5c9a0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_1_gram_counter))\n",
    "print(len(filtered_2_gram_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bbd263a-ae3c-48cf-bd1f-4fa66b1a9111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_n_gram_counts(chord_column, n):\n",
    "    # compile a dictionary of counts\n",
    "    results = Counter()\n",
    "    for song in chord_column:\n",
    "        song_as_list = song.split(',')\n",
    "        song_n_grams = [','.join(song_as_list[i:i+n]) for i in range(len(song_as_list) - n + 1)]\n",
    "        for ng in song_n_grams:\n",
    "            results[ng] += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65bef5d7-4e08-4af3-b382-baab72177097",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_counters = [get_raw_n_gram_counts(df['simplified_chords'], n) for n in n_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44064b65-29c3-4e0f-a94d-a920c822e43b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n= 1\n",
      "Number of raw n-grams: 690\n",
      "[('G', 2625626), ('C', 2191805), ('D', 2003664), ('A', 1533155), ('F', 1294437), ('Amin', 1107254), ('E', 1052746), ('Emin', 996675), ('Bmin', 575690), ('B', 548336)]\n",
      "\n",
      "n= 2\n",
      "Number of raw n-grams: 42574\n",
      "[('C,G', 706503), ('G,D', 591016), ('G,C', 554507), ('D,G', 480181), ('F,C', 445031), ('D,A', 396728), ('A,D', 337546), ('C,F', 315429), ('A,E', 309189), ('G,Amin', 275016)]\n",
      "\n",
      "n= 3\n",
      "Number of raw n-grams: 298213\n",
      "[('G,C,G', 200871), ('C,G,C', 171186), ('C,G,D', 170030), ('D,G,D', 157471), ('F,C,G', 155828), ('G,D,G', 142521), ('C,F,C', 133546), ('G,D,A', 121522), ('C,G,Amin', 117324), ('A,D,A', 115067)]\n",
      "\n",
      "n= 4\n",
      "Number of raw n-grams: 888910\n",
      "[('C,G,C,G', 95210), ('G,C,G,C', 90135), ('G,D,G,D', 71195), ('D,G,D,G', 69352), ('F,C,F,C', 64615), ('C,F,C,F', 61359), ('D,A,D,A', 53756), ('F,C,G,Amin', 53013), ('C,G,Amin,F', 52877), ('A,E,A,E', 52701)]\n",
      "\n",
      "n= 5\n",
      "Number of raw n-grams: 1752485\n",
      "[('G,C,G,C,G', 63053), ('C,G,C,G,C', 58360), ('D,G,D,G,D', 46406), ('C,F,C,F,C', 45349), ('G,D,G,D,G', 45079), ('C,G,Amin,F,C', 42609), ('F,C,G,Amin,F', 41854), ('G,Amin,F,C,G', 41457), ('G,D,Emin,C,G', 40513), ('F,C,F,C,F', 40218)]\n",
      "\n",
      "n= 6\n",
      "Number of raw n-grams: 2764461\n",
      "[('C,G,C,G,C,G', 43439), ('G,C,G,C,G,C', 43079), ('C,G,Amin,F,C,G', 38337), ('F,C,G,Amin,F,C', 36879), ('G,D,Emin,C,G,D', 36067), ('C,G,D,Emin,C,G', 35005), ('Amin,F,C,G,Amin,F', 34781), ('Emin,C,G,D,Emin,C', 33208), ('D,G,D,G,D,G', 33023), ('G,Amin,F,C,G,Amin', 32858)]\n",
      "\n",
      "n= 7\n",
      "Number of raw n-grams: 3817027\n",
      "[('G,C,G,C,G,C,G', 33455), ('F,C,G,Amin,F,C,G', 33442), ('C,G,C,G,C,G,C', 32030), ('C,G,D,Emin,C,G,D', 31540), ('Amin,F,C,G,Amin,F,C', 31153), ('C,G,Amin,F,C,G,Amin', 30614), ('G,Amin,F,C,G,Amin,F', 30306), ('Emin,C,G,D,Emin,C,G', 29524), ('G,D,Emin,C,G,D,Emin', 28581), ('D,Emin,C,G,D,Emin,C', 28570)]\n",
      "\n",
      "n= 8\n",
      "Number of raw n-grams: 4824402\n",
      "[('Amin,F,C,G,Amin,F,C,G', 28633), ('C,G,Amin,F,C,G,Amin,F', 28329), ('F,C,G,Amin,F,C,G,Amin', 27223), ('G,Amin,F,C,G,Amin,F,C', 27202), ('Emin,C,G,D,Emin,C,G,D', 27053), ('G,D,Emin,C,G,D,Emin,C', 26650), ('G,C,G,C,G,C,G,C', 26299), ('C,G,C,G,C,G,C,G', 25658), ('C,G,D,Emin,C,G,D,Emin', 25575), ('D,Emin,C,G,D,Emin,C,G', 25524)]\n",
      "\n",
      "n= 9\n",
      "Number of raw n-grams: 5735351\n",
      "[('C,G,Amin,F,C,G,Amin,F,C', 25675), ('G,Amin,F,C,G,Amin,F,C,G', 25542), ('F,C,G,Amin,F,C,G,Amin,F', 25464), ('Amin,F,C,G,Amin,F,C,G,Amin', 24651), ('G,D,Emin,C,G,D,Emin,C,G', 24078), ('C,G,D,Emin,C,G,D,Emin,C', 23986), ('D,Emin,C,G,D,Emin,C,G,D', 23926), ('Emin,C,G,D,Emin,C,G,D,Emin', 23261), ('G,C,G,C,G,C,G,C,G', 21622), ('C,G,C,G,C,G,C,G,C', 21055)]\n",
      "\n",
      "n= 10\n",
      "Number of raw n-grams: 6537957\n",
      "[('C,G,Amin,F,C,G,Amin,F,C,G', 24141), ('F,C,G,Amin,F,C,G,Amin,F,C', 23512), ('Amin,F,C,G,Amin,F,C,G,Amin,F', 23304), ('G,D,Emin,C,G,D,Emin,C,G,D', 22617), ('G,Amin,F,C,G,Amin,F,C,G,Amin', 22331), ('C,G,D,Emin,C,G,D,Emin,C,G', 22031), ('Emin,C,G,D,Emin,C,G,D,Emin,C', 21990), ('D,Emin,C,G,D,Emin,C,G,D,Emin', 20888), ('G,C,G,C,G,C,G,C,G,C', 18338), ('C,G,C,G,C,G,C,G,C,G', 17818)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in n_range:\n",
    "    index = n-1\n",
    "    print(\"n=\",n)\n",
    "    print(\"Number of raw n-grams:\",len(raw_counters[index]))\n",
    "    print(raw_counters[index].most_common(10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cba146b4-b905-4839-9bfa-043596bc7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a generic method for iterating through a counter of n-grams and aggregating equivalent n-grams\n",
    "def uniquify_n_grams(n_gram_counter, n, progress_updates = False):\n",
    "    results = Counter()\n",
    "    processed = set()\n",
    "    if progress_updates:\n",
    "        t0 = time.time()\n",
    "        i = 0\n",
    "        percent_complete = 0\n",
    "        num_raw = len(n_gram_counter)\n",
    "        print(\"Finding counts of \" + str(n) + \"-grams up to harmonic equivalence.\")\n",
    "        print(\"There are \" + str(num_raw) + \" raw \" + str(n) + \"-grams to process.\")\n",
    "        progress_interval = int(num_raw /100)\n",
    "    for ng1 in n_gram_counter:\n",
    "        if progress_updates:\n",
    "            i += 1\n",
    "            if i % progress_interval == 0 and i !=0:\n",
    "                percent_complete += 1\n",
    "                print(\"Processing \" + str(n) + \"-gram number \" + str(i) + \".\")\n",
    "                print(\"\\tTime spent so far:\",time.time() - t0)\n",
    "                print(\"\\tComputation is \" + str(percent_complete) + \"% complete.\")\n",
    "        if ng1 in processed:\n",
    "            continue\n",
    "        total = n_gram_counter[ng1]\n",
    "        for ng2 in n_gram_counter:\n",
    "            if (ng2 not in processed) and ng1 != ng2:\n",
    "                if compare_n_grams(ng1, ng2)[0]:\n",
    "                    total += n_gram_counter[ng2]\n",
    "                    processed.add(ng2)\n",
    "        results[ng1] = total\n",
    "        processed.add(ng1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7feb7-7c01-4861-8343-985a6ce4b629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
