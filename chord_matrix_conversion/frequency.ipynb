{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e604b290-a0bf-46bc-acd0-e66e4adb45e8",
   "metadata": {},
   "source": [
    "The goal of this notebook is to compile a list of chords by frequency in the entire database.\n",
    "My main goal is to do this counting chords as harmonically equivalent, but I will also do it more literally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc98f8-c078-4a63-8abe-f259789e8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import copy\n",
    "from collections import Counter, deque\n",
    "\n",
    "# read in the data set\n",
    "df = pd.read_csv('../data/chordonomicon.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aed508-0c99-46bc-9b17-ea87c399c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the mapping CSV file\n",
    "chord_relations = pd.read_csv('../data/chords_mapping.csv')\n",
    "\n",
    "# Create a dictionary with keys the \"chords\" and values the \"degrees\"\n",
    "chord_degrees = dict(zip(chord_relations['Chords'], chord_relations['Degrees']))\n",
    "for key, value in chord_degrees.items():\n",
    "    chord_degrees[key] = ast.literal_eval(value)\n",
    "    \n",
    "# full list of chords from the chords_mapping csv\n",
    "known_chords = list(chord_degrees.keys())\n",
    "assert(len(known_chords) == len(set(known_chords))) # Validating no duplicates\n",
    "\n",
    "# some examples of what the string labels for known chords look like\n",
    "print(known_chords[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513db183-3aef-4d67-a2ed-c237cf4accca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns except for chords and genres\n",
    "chord_data = df[['chords','genres']]\n",
    "chord_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40977578-d572-40a0-822c-1b16d71f52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing spaces with commas\n",
    "def replace_space_with_comma(my_string):\n",
    "    return my_string.replace(\" \",\",\")\n",
    "\n",
    "# Remove section markers\n",
    "def remove_section_markers(my_string):\n",
    "    result = []\n",
    "    i = 0\n",
    "    n = len(my_string)\n",
    "    while i < n:\n",
    "        if my_string[i] == '<':\n",
    "            # Skip until after the following \", \"\n",
    "            j = my_string.find('>', i)\n",
    "            if j == -1:\n",
    "                break  # no closing '>', stop\n",
    "            i = j + 2  # skip '>,' and the space\n",
    "        else:\n",
    "            result.append(my_string[i])\n",
    "            i += 1\n",
    "    assert('<' not in result)\n",
    "    assert('>' not in result)\n",
    "    return ''.join(result)\n",
    "\n",
    "# Remove inversions\n",
    "def remove_inversions(my_string):\n",
    "    result = []\n",
    "    i = 0\n",
    "    n = len(my_string)\n",
    "    while i < n:\n",
    "        if my_string[i] == '/':\n",
    "            # Skip until after the following \", \"\n",
    "            j = my_string.find(',', i)\n",
    "            if j == -1:\n",
    "                break  # no closing comma, stop\n",
    "            i = j  # skip comma\n",
    "        else:\n",
    "            result.append(my_string[i])\n",
    "            i += 1\n",
    "    return ''.join(result)\n",
    "\n",
    "def clean_up_chord_string(my_string):\n",
    "    return remove_inversions(\n",
    "        remove_section_markers(\n",
    "            replace_space_with_comma(my_string)))\n",
    "\n",
    "# replacing spaces with commons in all chords in all rows of the data\n",
    "chord_data.loc[:,'chords'] = chord_data['chords'].apply(clean_up_chord_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5c1f9-366b-49ae-9a75-6abcd8cde91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f8c91-d747-4b01-9fba-51cce6d1fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile a list of all chords in the data set\n",
    "list_of_chord_lists = list(chord_data.chords)\n",
    "giant_chord_string = ','.join(list_of_chord_lists)\n",
    "data_set_chords_with_duplicates = list(giant_chord_string.split(',')) # converting to a set as an intermediate step will get rid of duplicates\n",
    "data_set_chords_with_duplicates.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf8c951-e27e-4557-9af7-4cf0786e9443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile a dictionary of chords by count, where the key is the chord name, and the value is the number of times it appears in the database\n",
    "data_set_chord_counts = Counter(data_set_chords_with_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c3e6b-0316-4747-81bc-d935548f904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart of all chords, just by string name\n",
    "plt.pie(data_set_chord_counts.values(), \n",
    "        labels = data_set_chord_counts.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2cbf98-c2d3-4df3-a0bf-753bb5b43b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the log of frequency numbers\n",
    "plt.scatter(x = np.arange(len(data_set_chord_counts.values())),\n",
    "            y = np.log(np.sort(list(data_set_chord_counts.values()))),\n",
    "           marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad9e5e-31cb-4644-a7b9-e33125c7a81a",
   "metadata": {},
   "source": [
    "Next goal: compile a list of chord counts by harmonic equivalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1b641-59b8-40b9-b61b-bb74ac28e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to transpose a chord in vector format\n",
    "def transpose_chord_up(chord_vector, num_semitones):\n",
    "    d = deque(chord_vector)\n",
    "    d.rotate(num_semitones)\n",
    "    return(list(d))\n",
    "    \n",
    "# method to return true if chord_1 and chord_2 are just tranposed versions of each other\n",
    "def is_harmonic_equivalent(chord_1, chord_2):\n",
    "    # if they have different numbers of notes, then we don't have to check if \n",
    "    # any of the transpositions are equal\n",
    "    if sum(chord_1) != sum(chord_2):\n",
    "        return False\n",
    "\n",
    "    # if they have the same number of notes, just rotate through the 12 possible transpositions to check\n",
    "    for i in range(12):\n",
    "        if np.array_equal(chord_1, transpose_chord_up(chord_2, i)):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "C = chord_degrees['C']\n",
    "D = chord_degrees['D']\n",
    "E = chord_degrees['E']\n",
    "assert(is_harmonic_equivalent(C,D))\n",
    "assert(is_harmonic_equivalent(C,E))\n",
    "assert(is_harmonic_equivalent(D,E))\n",
    "\n",
    "Cmaj7 = chord_degrees['Cmaj7']\n",
    "Dmaj7 = chord_degrees['Dmaj7']\n",
    "assert(is_harmonic_equivalent(Cmaj7,Dmaj7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1875cae6-8e89-4da9-bc05-d2199ae86e1b",
   "metadata": {},
   "source": [
    "The next code block compiles a counter of harmonically unique chords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b3fad5-c5cf-4b7f-96bd-635fc1c06f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_counts_copy = copy.deepcopy(data_set_chord_counts)\n",
    "harmonically_unique_chord_counts = Counter()\n",
    "\n",
    "while len(chord_counts_copy) > 0:\n",
    "    # pick the most common chord, and retrieve a vector version of it\n",
    "    chord_1 = chord_counts_copy.most_common(1)[0][0]\n",
    "    chord_1_vec = chord_degrees[chord_1]\n",
    "\n",
    "    # start compiling a list of equivalent chords, and a running total of those chords\n",
    "    equivalent_chords = [chord_1]\n",
    "    running_total = chord_counts_copy[chord_1]\n",
    "\n",
    "    # remove the chord from the list so we don't double count it\n",
    "    del chord_counts_copy[chord_1]\n",
    "    \n",
    "    # go through and find all harmonically equivalent chords to the most common chord left\n",
    "    for chord_2 in chord_counts_copy:\n",
    "        chord_2_vec = chord_degrees[chord_2]\n",
    "        if is_harmonic_equivalent(chord_1_vec, chord_2_vec):\n",
    "            equivalent_chords.append(chord_2)\n",
    "            running_total = running_total + data_set_chord_counts[chord_2]\n",
    "\n",
    "    # set the value in the new counter to be the accumulated sum\n",
    "    harmonically_unique_chord_counts[chord_1] = running_total\n",
    "\n",
    "    # go through chord_counts_copy and delete all the chords that were just added to the unique chord counter\n",
    "    for ec in equivalent_chords:\n",
    "        del chord_counts_copy[ec]\n",
    "\n",
    "print(\"Number of harmonically unique chords:\",len(harmonically_unique_chord_counts))\n",
    "print(harmonically_unique_chord_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3348d9cd-b05c-4ae3-b11e-71b8bd4cdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart of harmonically unique chords\n",
    "plt.pie(harmonically_unique_chord_counts.values(), \n",
    "        labels = harmonically_unique_chord_counts.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f6b29-5994-4d14-baca-1e94c7f47a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the log of frequency numbers\n",
    "plt.scatter(x = np.arange(len(harmonically_unique_chord_counts.values())),\n",
    "            y = np.log(np.sort(list(harmonically_unique_chord_counts.values()))),\n",
    "           marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65506d05-f097-4460-a6fd-5c989c253ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a some charts for the \"other\" category, i.e. the chords other than major and minor\n",
    "harmonically_unique_chord_counts_rare = copy.deepcopy(harmonically_unique_chord_counts)\n",
    "del harmonically_unique_chord_counts_rare['G']\n",
    "del harmonically_unique_chord_counts_rare['Amin']\n",
    "print(harmonically_unique_chord_counts_rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19aa6e-1945-4ce9-a2b3-1c83aded1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart of rare unique chords\n",
    "plt.pie(harmonically_unique_chord_counts_rare.values(), \n",
    "        labels = harmonically_unique_chord_counts_rare.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c91c5ab-44d9-4008-be74-63d3c2897934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the log of rare unique chord frequencies\n",
    "plt.scatter(x = np.arange(len(harmonically_unique_chord_counts_rare.values())),\n",
    "            y = np.log(np.sort(list(harmonically_unique_chord_counts_rare.values()))),\n",
    "           marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9bbdd-0955-4c8d-9dab-eccc3235f7b8",
   "metadata": {},
   "source": [
    "Next goal: compile lists of n-gram frequencies, both in raw terms and using harmonic equivalence groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb18eba-9e98-4107-83e4-3a1d8fb23ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(n):\n",
    "    # return a counter object of n-grams, ignoring harmonic equivalence\n",
    "    chord_n_gram_counter = Counter()\n",
    "    for song in list_of_chord_lists:\n",
    "        song_as_list = song.split(',')\n",
    "        for i in range(len(song_as_list)-n+1):\n",
    "            pair = ','.join(song_as_list[i:i+n])\n",
    "            chord_n_gram_counter[pair] += 1\n",
    "    return chord_n_gram_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390fc260-b09e-473e-8957-3a7715269d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_2_gram_counter = n_grams(2)\n",
    "print(\"Number of 2-grams (ignoring harmonic equivalence):\",len(chord_2_gram_counter))\n",
    "print(\"Top 2 most common 2-grams:\",chord_2_gram_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fa7fb-ceba-4d56-a6eb-4300e5490be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart of the top 50 most common 2-grams (without harmonic equivalence)\n",
    "pie_slices = 50\n",
    "most_common = Counter(dict(chord_2_gram_counter.most_common(pie_slices)))\n",
    "plt.pie(most_common.values(), \n",
    "        labels = most_common.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260e21c-2c55-475d-9f39-6c666095fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the log of chord 2-gram frequencies (without harmonic equivalence)\n",
    "plt.scatter(x = np.arange(len(chord_2_gram_counter.values())),\n",
    "            y = np.log(np.sort(list(chord_2_gram_counter.values()))),\n",
    "           marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee265b5-cdd4-40f3-b6c5-9e5b4d5a731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_3_gram_counter = n_grams(3)\n",
    "print(chord_3_gram_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95c826-3556-4d3e-9731-4935c02860d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart of the top 50 most common 3-grams (without harmonic equivalence)\n",
    "pie_slices = 50\n",
    "most_common = Counter(dict(chord_3_gram_counter.most_common(pie_slices)))\n",
    "plt.pie(most_common.values(), \n",
    "        labels = most_common.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f6d4b-18d8-4672-ae7b-c6d44ea2c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the log of chord 3-gram frequencies (without enharmonic equivalence)\n",
    "chord_3_gram_counter = n_grams(3)\n",
    "plt.scatter(x = np.arange(len(chord_3_gram_counter.values())),\n",
    "            y = np.log(np.sort(list(chord_3_gram_counter.values()))),\n",
    "           marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d6c323-fcb9-4503-be26-78ebe1a7319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert a string of comma-separated chords into a matrix, where each column denotes a chord\n",
    "def string_to_chord_matrix(chord_sequence):\n",
    "    # split sequence over commas, ignoring any \"empty string\" chords\n",
    "    chord_list = [c for c in chord_sequence.split(',') if c != '']\n",
    "    \n",
    "    # then look up each chord in chord_degrees dictionary by the key value\n",
    "    return np.array([chord_degrees[c][::-1] for c in chord_list])\n",
    "\n",
    "def transpose_matrix_up(chord_matrix, num_semitones):\n",
    "    # transpose the entire matrix up by a number of semitones\n",
    "    # this just means applying transpose_chord_up to each row\n",
    "    # we'll accomplish this by taking the matrix transpose, applying to each row, then taking the matrix transpose back\n",
    "    for row in chord_matrix:\n",
    "        new_matrix[i] = transpose_chord_up(row,num_semitones)\n",
    "    return new_matrix\n",
    "\n",
    "def is_harmonic_equivalent_matrix(chord_matrix_1, chord_matrix_2):\n",
    "    # return true if chord_matrix_1 and chord_matrix_2 are just tranposed versions of each other\n",
    "\n",
    "    # some basic checks to skip some looping when we can rule that out already\n",
    "    if (chord_matrix_1.sum() != chord_matrix_2.sum()) or (chord_matrix_1.shape != chord_matrix_2.shape):\n",
    "        return False\n",
    "\n",
    "    # loop to check if they're the same\n",
    "    for i in range(12):\n",
    "        if np.array_equal(chord_matrix_1, transpose_chord_up(chord_matrix_2, i)):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9448c84-0b35-4abc-aafd-1a6507855119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_n_grams(chord_n_gram_counter, output_messages=False, countdown=False):\n",
    "    # return a counter object of harmonically unique n-grams\n",
    "    # this will be a dictionary where keys are (harmonically unique) n-grams, and values are numbers of occurences in the database\n",
    "\n",
    "    # make a deep copy of the input so we don't modify the original\n",
    "    chord_n_gram_counter_copy = copy.deepcopy(chord_n_gram_counter)\n",
    "\n",
    "    if output_messages:\n",
    "        print(\"Initial length of numbers of n-grams with duplicates:\",len(chord_n_gram_counter_copy))\n",
    "        print()\n",
    "    \n",
    "    # we'll build up a counter of uniques\n",
    "    unique_n_gram_counter = Counter()\n",
    "\n",
    "    while len(chord_n_gram_counter_copy) > 0:\n",
    "        n_gram_1 = chord_n_gram_counter_copy.most_common(1)[0][0]\n",
    "        matrix_1 = string_to_chord_matrix(n_gram_1)\n",
    "        \n",
    "        # initialize a list of equivalent n-grams\n",
    "        equivalent_n_grams = [n_gram_1]\n",
    "        running_total = chord_n_gram_counter_copy[n_gram_1]\n",
    "\n",
    "        # delete the current n-gram under consideration so that we don't count it as an equivalent to itself a second time\n",
    "        del chord_n_gram_counter_copy[n_gram_1]\n",
    "        \n",
    "        # go through and find all harmonically equivalent chords to the most common chord left\n",
    "        for n_gram_2 in chord_n_gram_counter_copy:\n",
    "            matrix_2 = string_to_chord_matrix(n_gram_2)\n",
    "            if is_harmonic_equivalent_matrix(matrix_1, matrix_2):\n",
    "                equivalent_n_grams.append(n_gram_2)\n",
    "                running_total = running_total + data_set_chord_counts[chord_2]\n",
    "                #print(n_gram_2) ###\n",
    "    \n",
    "        # set the value in the new counter to be the accumulated sum\n",
    "        unique_n_gram_counter[n_gram_1] = running_total\n",
    "\n",
    "        # go through chord_counts_copy and delete all the chords that were just added to the unique chord counter\n",
    "        for e in equivalent_n_grams:\n",
    "            del chord_n_gram_counter_copy[e]\n",
    "\n",
    "        if output_messages:\n",
    "            print(\"n-gram under consideration:\",n_gram_1)\n",
    "            print(\"Equivalent n-grams:\",equivalent_n_grams)\n",
    "            print(\"Number of equivalent n-grams:\",len(equivalent_n_grams))\n",
    "            print(\"New length of non-unique n-grams to check:\",len(chord_n_gram_counter_copy))\n",
    "            print(\"Updated list of unique n-grams:\",unique_n_gram_counter)\n",
    "            print()\n",
    "\n",
    "        if countdown:\n",
    "            print(\"Remaining n-grams:\",len(chord_n_gram_counter_copy))\n",
    "\n",
    "    return unique_n_gram_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4ce11-b3d6-475e-8ea3-411a46549d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_2_gram_counter = n_grams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dfe0bf-573b-4c40-9699-02cff548a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_2_gram_counter = unique_n_grams(chord_2_gram_counter, output_messages=True)\n",
    "print(unique_2_gram_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1773540-f8c1-4080-8b37-47a516ef7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the log of chord 2-gram frequencies (with enharmonic equivalence)\n",
    "plt.scatter(x = np.arange(len(unique_2_gram_counter.values())),\n",
    "            y = np.log(np.sort(list(unique_2_gram_counter.values()))),\n",
    "           marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69476d48-c46d-4dd1-9a55-56defa719883",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_3_gram_counter = unique_n_grams(chord_3_gram_counter)\n",
    "print(unique_3_gram_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b4338-7707-4abc-85ff-1ef5738c0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the log of chord 3-gram frequencies (with enharmonic equivalence)\n",
    "plt.scatter(x = np.arange(len(unique_3_gram_counter.values())),\n",
    "            y = np.log(np.sort(list(unique_3_gram_counter.values()))),\n",
    "           marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa15189a-5686-486c-b8b8-73b7996ee58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_4_gram_counter = n_grams(4)\n",
    "unique_4_gram_counter = unique_n_grams(chord_4_gram_counter)\n",
    "print(unique_4_gram_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c983ef4-3926-43f1-b9ad-cce3f73ad625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the log of chord 4-gram frequencies (with enharmonic equivalence)\n",
    "plt.scatter(x = np.arange(len(unique_4_gram_counter.values())),\n",
    "            y = np.log(np.sort(list(unique_4_gram_counter.values()))),\n",
    "           marker='.')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
