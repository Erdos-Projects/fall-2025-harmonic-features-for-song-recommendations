{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab509b08-5ba5-4ff2-ba08-73bec8e33487",
   "metadata": {},
   "source": [
    "The goal of this notebook is convert the chordonomicon data set to make each song a matrix where each column records a single chord. \n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Import the chordonomicon data set, drop all columns except for 'id' and 'chords'\n",
    "2. Remove section marker info from chords i.e. remove \\<intro_1\\>\n",
    "3. For each song, convert each chord into a vector, then concatenate them into a matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602903d3-fc5e-4813-b4a0-9b7dcfff001e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/chordonomicon.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# read in the data set\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/chordonomicon.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/chordonomicon.csv'"
     ]
    }
   ],
   "source": [
    "# importing basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import ast\n",
    "\n",
    "# read in the data set\n",
    "df = pd.read_csv('../data/chordonomicon.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb30571-731a-4f38-bd98-708669a9c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the mapping CSV file\n",
    "chord_relations = pd.read_csv('../data/chords_mapping.csv')\n",
    "\n",
    "# Create a dictionary with keys the \"chords\" and values the \"degrees\"\n",
    "chord_degrees = dict(zip(chord_relations['Chords'], chord_relations['Degrees']))\n",
    "for key, value in chord_degrees.items():\n",
    "    chord_degrees[key] = ast.literal_eval(value)\n",
    "    \n",
    "# full list of chords from the chords_mapping csv\n",
    "known_chords = list(chord_degrees.keys())\n",
    "assert(len(known_chords) == len(set(known_chords))) # Validating no duplicates\n",
    "\n",
    "# some examples of what the string labels for known chords look like\n",
    "print(known_chords[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0881bdbe-f6f6-4244-89d7-174eaf5e90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some examples of what chords look like in this data file\n",
    "print(\"Number of known chords: \",len(chord_degrees))\n",
    "print(\"C major: \\t\",chord_degrees['C'])\n",
    "print(\"C major 7: \\t\",chord_degrees['Cmaj7'])\n",
    "print(\"C minor: \\t\",chord_degrees['Cmin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87db9a5-6145-44c6-b8ff-be71f05e535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns except for chords and genres\n",
    "chord_data = df[['chords','genres']]\n",
    "chord_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368f4b4-0da0-408f-93ee-10f0fcaab7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing spaces with commas\n",
    "def replace_space_with_comma(my_string):\n",
    "    return my_string.replace(\" \",\",\")\n",
    "\n",
    "# replacing spaces with commons in all chords in all rows of the data\n",
    "chord_data.loc[:,'chords'] = chord_data['chords'].apply(replace_space_with_comma)\n",
    "chord_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ae15b-21a7-4d0f-9c4b-aa06a60ec248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove section markers\n",
    "def remove_section_markers(my_string):\n",
    "    result = []\n",
    "    i = 0\n",
    "    n = len(my_string)\n",
    "    while i < n:\n",
    "        if my_string[i] == '<':\n",
    "            # Skip until after the following \", \"\n",
    "            j = my_string.find('>', i)\n",
    "            if j == -1:\n",
    "                break  # no closing '>', stop\n",
    "            i = j + 2  # skip '>,' and the space\n",
    "        else:\n",
    "            result.append(my_string[i])\n",
    "            i += 1\n",
    "    assert('<' not in result)\n",
    "    assert('>' not in result)\n",
    "    return ''.join(result)\n",
    "\n",
    "chord_data.loc[:,'chords'] = chord_data['chords'].apply(remove_section_markers)\n",
    "chord_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4025fb61-b0af-438f-9b8a-c8350cac8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing inversions\n",
    "def remove_inversions(my_string):\n",
    "    result = []\n",
    "    i = 0\n",
    "    n = len(my_string)\n",
    "    while i < n:\n",
    "        if my_string[i] == '/':\n",
    "            # Skip until after the following \", \"\n",
    "            j = my_string.find(',', i)\n",
    "            if j == -1:\n",
    "                break  # no closing comma, stop\n",
    "            i = j  # skip comma\n",
    "        else:\n",
    "            result.append(my_string[i])\n",
    "            i += 1\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce013b6-849b-418b-8230-a3e96c0e3866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some sample chords with inversions\n",
    "songs_with_inversions = chord_data.loc[['/' in ch for ch in chord_data.chords]]\n",
    "songs_with_inversions.sample(10)\n",
    "\n",
    "# just a basic test on a random chord sequence with some inversions\n",
    "n = 3\n",
    "my_sample = songs_with_inversions.sample(5)\n",
    "for i in range(n):\n",
    "    s = songs_with_inversions.iloc[i].chords\n",
    "    print(s)\n",
    "    print()\n",
    "    print(remove_inversions(s))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12383e-7cdd-45d7-9e50-44edf8516cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove inversions from the whole data set\n",
    "chord_data.loc[:,'chords'] = chord_data['chords'].apply(remove_inversions)\n",
    "chord_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173b954-e058-43ed-b351-8583ec85601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile a list of all chords in the data set\n",
    "list_of_chord_lists = list(chord_data.chords)\n",
    "giant_chord_string = ','.join(list_of_chord_lists)\n",
    "data_set_chords = list(set(giant_chord_string.split(','))) # converting to a set as an intermediate step will get rid of duplicates\n",
    "assert(len(data_set_chords) == len(set(data_set_chords))) # validating no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4faa98e-7bb5-40ea-b1f8-95dadfdd2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_chords.remove('') # I still don't understand why the empty string ends up in here after what I'm doing above, but it does, so this gets rid of it. This is a very hacky solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be09cb-d121-44e4-9f8f-6123f7ecfcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_of_chord_lists[0:5])\n",
    "print()\n",
    "print(giant_chord_string[0:200])\n",
    "print()\n",
    "print(len(data_set_chords))\n",
    "print(data_set_chords[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a2138-5ddb-4e92-96a0-454ebeacce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all chords in the data set which are not in the chords_mapping csv file, should be basically zero\n",
    "mystery_chords = list(set(data_set_chords).difference(set(known_chords)))\n",
    "assert(len(mystery_chords) == len(set(mystery_chords))) # validating no duplicates\n",
    "print(len(mystery_chords))\n",
    "print(mystery_chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f65d4a-7660-43d2-9e40-99332a2e5e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert a string of comma-separated chords into a matrix, where each column denotes a chord\n",
    "def string_to_chord_matrix(chord_sequence):\n",
    "    # split sequence over commas, ignoring any \"empty string\" chords\n",
    "    chord_list = [c for c in chord_sequence.split(',') if c != '']\n",
    "    \n",
    "    # then look up each chord in chord_degrees dictionary by the key value\n",
    "    return np.array([chord_degrees[c][::-1] for c in chord_list]).transpose()\n",
    "\n",
    "# visualizing the output for a sample of a few songs\n",
    "n = 3\n",
    "my_sample = chord_data.sample(3)\n",
    "np.set_printoptions(linewidth=400)\n",
    "for i in range(n):\n",
    "    s = chord_data.iloc[i].chords\n",
    "    print(s)\n",
    "    print()\n",
    "    print(string_to_chord_matrix(s))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7678b8-694b-4ef5-a2ba-14d1a0a67a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove inversions from the whole data set\n",
    "chord_data.insert(loc = 2,\n",
    "                  column = 'chord_matrix',\n",
    "                  value = chord_data['chords'].apply(string_to_chord_matrix),\n",
    "                  allow_duplicates = False)\n",
    "chord_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d596821-6490-482b-973b-a575f9abf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration of how to transpose, in vector/matrix form\n",
    "# For a vector chord, transposing is just a matter of cyclically permuting the vector\n",
    "# It seems the easiest way to do this is using deque objects\n",
    "# deque = \"double-ended queue\"\n",
    "from collections import deque \n",
    "\n",
    "def transpose_chord_up(chord_vector, num_semitones):\n",
    "    # transpose the input chord_vector up by num_semitones\n",
    "    d = deque(chord_vector)\n",
    "    d.rotate(num_semitones)\n",
    "    return(list(d))\n",
    "\n",
    "Cmaj_vec = chord_degrees['C']\n",
    "Dmaj_vec = chord_degrees['D']\n",
    "print(\"C major:\\t\\t\",Cmaj_vec)\n",
    "print(\"D major:\\t\\t\",Dmaj_vec)\n",
    "print(\"C major transposed up 2:\",transpose_chord_up(Cmaj_vec,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4711c5ad-ee3c-4501-8aad-b5ac1d4c0563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
