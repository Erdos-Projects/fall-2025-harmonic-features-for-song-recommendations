{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffbbd26-b31b-4961-b1ab-ea17c8b89148",
   "metadata": {},
   "source": [
    "This notebook illustrates a very simple model for predicting genre based on whether the song contains something harmonically equivalent to a few key chords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd8d1cb-775c-4a5e-9cb6-8eb7523aa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53db6271-f2ac-46fe-b458-830649c259ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the chord and genre dataframe\n",
    "chord_data = pd.read_csv('chord_and_genre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad1516f-8dae-4ecd-a475-9fa486742ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the genre deviations dataframe\n",
    "n = 1\n",
    "filename = str(n) + '_gram_deviations.csv'\n",
    "deviation_df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26192852-4a82-457f-a3bb-bd748d854984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of n-grams before dropping based on sample size threshold: 45\n",
      "Number of n-grams after dropping based on sample size threshold: 45\n"
     ]
    }
   ],
   "source": [
    "# setting the sample size threshold\n",
    "###################################################################################################################\n",
    "sample_size_threshold = 0 # make this bigger to exclude rarer chords from the model\n",
    "###################################################################################################################\n",
    "baseline_total = deviation_df.loc[deviation_df['n_gram'] == 'baseline', 'total'].iloc[0]\n",
    "\n",
    "# drop the baseline row\n",
    "deviation_df = deviation_df[deviation_df['n_gram'] != 'baseline']\n",
    "\n",
    "# drop all rows not meeting a sample size threshold\n",
    "print(\"Number of n-grams before dropping based on sample size threshold:\", len(deviation_df.index))\n",
    "deviation_df = deviation_df[deviation_df['total'] >= baseline_total * sample_size_threshold]\n",
    "print(\"Number of n-grams after dropping based on sample size threshold:\", len(deviation_df.index))\n",
    "\n",
    "# sort by maximum absolute log deviation ration, so that the \"good feature\" chords are at the top\n",
    "deviation_df = deviation_df.sort_values(by = 'max_abs_log_dev_ratio', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2678090-4220-4bef-b035-a2a6e264dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the equivalence dictionary file\n",
    "# this is a dictionary of dictionaries\n",
    "#    the top-level keys are chord names (e.g. 'C','Amin')\n",
    "#    the top-level values are dictionaries, whose keys are equivalent chords, and whose values are the semitone distance between the top-level key and the low-level key\n",
    "with open('../data/harmonic_equivalence.json') as file:\n",
    "    equiv_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3050f7b4-d0e5-4b8e-a0d4-6f5f907ae827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the two input chords are harmonically equivalent, return (True, num_semitones) where num_semitones is the distance from n_gram_1 (up) to n_gram_2\n",
    "# otherwise, return (False, None)\n",
    "def compare_chords(chord_1, chord_2):\n",
    "    if chord_2 in equiv_dict[chord_1]:\n",
    "        return (True, equiv_dict[chord_1][chord_2])\n",
    "    else:\n",
    "        return (False, None)\n",
    "\n",
    "assert(compare_chords('C','D')[0])\n",
    "assert(compare_chords('C','E')[0])\n",
    "assert(not(compare_chords('C','Amin')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8948cbe5-3dc8-4a7b-ba28-73480c5b3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the two input n_grams are harmonically equivalent, return (True, num_semitones) where num_semitones is the distance from n_gram_1 (up) to n_gram_2\n",
    "# otherwise, return (False, None)\n",
    "def compare_n_grams(n_gram_1, n_gram_2):\n",
    "    list_1 = n_gram_1.split(',')\n",
    "    list_2 = n_gram_2.split(',')\n",
    "\n",
    "    # if they aren't the same length, we don't have to check anything\n",
    "    if len(list_1) != len(list_2):\n",
    "        return (False, None)\n",
    "\n",
    "    # now we can assume they have the same length\n",
    "    comparison = [compare_chords(list_1[i], list_2[i]) for i in range(len(list_1))]\n",
    "\n",
    "    # if any pairs are not the same, return False\n",
    "    for c in comparison:\n",
    "        if not c[0]:\n",
    "            return (False, None)\n",
    "\n",
    "    # now we can assume every respective pair is equivalent, but we still need all of the distances to match\n",
    "    dist_0 = comparison[0][1]\n",
    "    for c in comparison:\n",
    "        if c[1] != dist_0:\n",
    "            return (False, None)\n",
    "\n",
    "    return (True, dist_0)\n",
    "\n",
    "assert(compare_n_grams('C,D,E','F,G,A')[0])\n",
    "assert(not(compare_n_grams('C,D,E','F,G,B')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e051e0c8-0ed9-4b06-b597-f206407b97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return true/false depending on if a song contains a harmonically equivalent n_gram to the input n_gram\n",
    "# new version of this, making use of the equivalence dictionary for lookups rather than doing calculations every time\n",
    "def contains_n_gram(song, n_gram):\n",
    "    # assumption: input song is a comma-separated string of chord names\n",
    "    # assumption: input n_gram is a comma-separated string of chord names\n",
    "\n",
    "    # skip ahead and return true if the raw version is the song\n",
    "    if n_gram in song:\n",
    "        return True\n",
    "\n",
    "    # split up the song and n_gram into lists of strings of single chords\n",
    "    song_as_list = song.split(',')\n",
    "    song_length = len(song_as_list)\n",
    "    n_gram_as_list = n_gram.split(',')\n",
    "    n = len(n_gram_as_list)\n",
    "\n",
    "    for i in range(0,song_length - n):\n",
    "        song_n_gram = ','.join(song_as_list[i:i+n])\n",
    "        is_same, dist = compare_n_grams(n_gram, song_n_gram)\n",
    "        if is_same:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "assert(contains_n_gram('A,B,C,D,E,F,G','C,D'))\n",
    "assert(contains_n_gram('A,B,C,D,E,F','F,G'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04ef3e-4c24-4f0f-b66f-98f02eaf8076",
   "metadata": {},
   "source": [
    "With the above setup out of the way, now I want to make a classifier model which will output a genre prediction. The only features will be a series of binary columns of the form 'Contains a chord harmonically equivalent to C' or 'Contains a chord harmonically equivalent to Amin'. To decide which chords to use, I'm using the top sorted chords from the deviation dataframe loaded above.\n",
    "\n",
    "I will also make two different baslines to compare against:\n",
    "\n",
    "    1. Predict most common, i.e. just predict 'pop' for every song.\n",
    "    \n",
    "    2. An alternate classifier of similar type, whose inputs are also binary columns, but of the form 'Contains a (literal, raw) C chord'. In other words, the same kinds of features, but without considering harmonic equivalence. I'll have it use the same columns as the harmonic-equivalence-based classifier, unless I think of a better way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a87fdf06-a300-4748-84c0-ee49ce25eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392440b2-c21b-4906-8ff0-705f11eaf512",
   "metadata": {},
   "source": [
    "Run cells from here down and change num_feature_chords to make and test a mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f017ac2a-c2bf-41a9-8a12-2dd0b96f531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a one-hot column for a list of feature chords to the chord and genre data\n",
    "def add_one_hot(feature_chords):\n",
    "    df = pd.read_csv('chord_and_genre.csv')\n",
    "\n",
    "    new_feature_chords = [fc for fc in feature_chords if (('has_literal_'+fc) not in list(df.columns))]\n",
    "    num_new_features = len(new_feature_chords) \n",
    "    \n",
    "    print(\"Building \" + str(num_new_features) + \" one-hot encoded columns for chord containment.\\n\")\n",
    "    t0 = time.time()\n",
    "    for index, fc in enumerate(new_feature_chords):\n",
    "        df['has_literal_' + fc] = df['chords'].apply(lambda song : fc in song)\n",
    "        df['has_equivalent_' + fc] = df['chords'].apply(lambda song : contains_n_gram(song, fc))\n",
    "        \n",
    "        print(\"Finished tabulating columns for:\",fc)\n",
    "        print(\"\\tCompleted chords so far:\",index+1)\n",
    "        print(\"\\tChords remaining:\",num_new_features - (index+1))\n",
    "        print(\"\\tAverage time per chord so far:\",np.round((time.time()-t0)/(index+1), decimals=1))\n",
    "        print()\n",
    "\n",
    "    print(\"Finished all tabulations.\")\n",
    "\n",
    "    df.to_csv('chord_and_genre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c327b7ba-257a-4462-b4d3-114046b84516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 0 one-hot encoded columns for chord containment.\n",
      "\n",
      "Finished all tabulations.\n"
     ]
    }
   ],
   "source": [
    "# extract \"good\" feature chords from the top rows of the deviation dataframe\n",
    "features_to_try = 50\n",
    "features_to_try = min(features_to_try, len(deviation_df.index)) # causes an error if you try to do more than the number of rows in the dataframe\n",
    "top_rows = deviation_df.head(features_to_try)\n",
    "feature_chords = list(top_rows['n_gram'])\n",
    "\n",
    "# add one-hot columns to the chord and genre dataframe\n",
    "add_one_hot(feature_chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b02e2f8-3c5c-42da-a732-e8bf61931267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the feature dataframes\n",
    "model_df = pd.read_csv('chord_and_genre.csv')\n",
    "\n",
    "# make a numerically encoded genre column\n",
    "encoder = LabelEncoder()\n",
    "genre_encoded = encoder.fit_transform(model_df['genres'])\n",
    "\n",
    "# make some convenient handles\n",
    "literal_columns = ['has_literal_' + fc for fc in feature_chords]\n",
    "equivalent_columns = ['has_equivalent_' + fc for fc in feature_chords]\n",
    "feature_columns = literal_columns + equivalent_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75621c2b-4b95-4d8a-9da6-1b763b34126e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.5</th>\n",
       "      <th>Unnamed: 0.4</th>\n",
       "      <th>Unnamed: 0.3</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>chords</th>\n",
       "      <th>genres</th>\n",
       "      <th>has_literal_Dmin7</th>\n",
       "      <th>has_equivalent_Dmin7</th>\n",
       "      <th>...</th>\n",
       "      <th>has_literal_Eminmaj7</th>\n",
       "      <th>has_equivalent_Eminmaj7</th>\n",
       "      <th>has_literal_Fmaj7sus4</th>\n",
       "      <th>has_equivalent_Fmaj7sus4</th>\n",
       "      <th>has_literal_Gadd11</th>\n",
       "      <th>has_equivalent_Gadd11</th>\n",
       "      <th>has_literal_Adim13b9</th>\n",
       "      <th>has_equivalent_Adim13b9</th>\n",
       "      <th>has_literal_B11b9</th>\n",
       "      <th>has_equivalent_B11b9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C,F,C,E7,Amin,C,F,C,G7,C,F,C,E7,Amin,C,F,G7,C,...</td>\n",
       "      <td>pop</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E,D,A,E,D,A,E,D,A,E,D,A,E,D,A,E,D,A,C,E,G,D,A,...</td>\n",
       "      <td>pop</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>C,G,C,G,C,F,Dmin,G,Dmin,G,C,G,C,F,Dmin,G,Dmin,...</td>\n",
       "      <td>pop</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>C,G,C,G,C,G,C,G,C,Bmin,Emin,Amin,D,G,C,D,G,C,D...</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>G,Bmin,Amin,D,G,Bmin,Amin,D,G,Emin,Amin,D,G,Em...</td>\n",
       "      <td>pop</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.5  Unnamed: 0.4  Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  \\\n",
       "0             0             0             0             0             0   \n",
       "1             1             1             1             1             1   \n",
       "2             2             2             2             2             2   \n",
       "3             3             3             3             3             3   \n",
       "4             4             4             4             4             4   \n",
       "\n",
       "   Unnamed: 0                                             chords genres  \\\n",
       "0           0  C,F,C,E7,Amin,C,F,C,G7,C,F,C,E7,Amin,C,F,G7,C,...    pop   \n",
       "1           1  E,D,A,E,D,A,E,D,A,E,D,A,E,D,A,E,D,A,C,E,G,D,A,...    pop   \n",
       "2           3  C,G,C,G,C,F,Dmin,G,Dmin,G,C,G,C,F,Dmin,G,Dmin,...    pop   \n",
       "3           4  C,G,C,G,C,G,C,G,C,Bmin,Emin,Amin,D,G,C,D,G,C,D...  other   \n",
       "4           5  G,Bmin,Amin,D,G,Bmin,Amin,D,G,Emin,Amin,D,G,Em...    pop   \n",
       "\n",
       "   has_literal_Dmin7  has_equivalent_Dmin7  ...  has_literal_Eminmaj7  \\\n",
       "0              False                 False  ...                 False   \n",
       "1              False                 False  ...                 False   \n",
       "2               True                  True  ...                 False   \n",
       "3              False                 False  ...                 False   \n",
       "4              False                  True  ...                 False   \n",
       "\n",
       "   has_equivalent_Eminmaj7  has_literal_Fmaj7sus4  has_equivalent_Fmaj7sus4  \\\n",
       "0                    False                  False                     False   \n",
       "1                    False                  False                     False   \n",
       "2                    False                  False                     False   \n",
       "3                    False                  False                     False   \n",
       "4                    False                  False                     False   \n",
       "\n",
       "   has_literal_Gadd11  has_equivalent_Gadd11  has_literal_Adim13b9  \\\n",
       "0               False                  False                 False   \n",
       "1               False                  False                 False   \n",
       "2               False                  False                 False   \n",
       "3               False                  False                 False   \n",
       "4               False                  False                 False   \n",
       "\n",
       "   has_equivalent_Adim13b9  has_literal_B11b9  has_equivalent_B11b9  \n",
       "0                    False              False                 False  \n",
       "1                    False              False                 False  \n",
       "2                    False              False                 False  \n",
       "3                    False              False                 False  \n",
       "4                    False              False                 False  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac6476d9-1efc-4dd8-9128-a26b979fb277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a train test split on the harmonic equivalence dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_df[feature_columns], \n",
    "                                                    genre_encoded,\n",
    "                                                    random_state = 145,\n",
    "                                                    test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86d3d8e6-e5ea-44a3-8d74-0372e09b0b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of equivalence model:\t 0.3661166192886362\n",
      "Accuracy of literal model:\t 0.35783124176662273\n",
      "Accuracy of dummy model:\t 0.3540178880954032\n",
      "\n",
      "Precision of equivalence model:\t 0.3661166192886362\n",
      "Precision of literal model:\t 0.35783124176662273\n",
      "Precision of dummy model:\t 0.3540178880954032\n"
     ]
    }
   ],
   "source": [
    "# fit the models and make predictions\n",
    "equivalence_model = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', max_iter = 2000)\n",
    "equivalence_model.fit(X_train[equivalent_columns], y_train)\n",
    "y_pred_equiv = equivalence_model.predict(X_test[equivalent_columns])\n",
    "\n",
    "literal_model = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', max_iter = 2000)\n",
    "literal_model.fit(X_train[literal_columns], y_train)\n",
    "y_pred_lit = literal_model.predict(X_test[literal_columns])\n",
    "\n",
    "dummy_model = DummyClassifier(strategy = 'most_frequent')\n",
    "dummy_model.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_model.predict(X_test)\n",
    "\n",
    "# compute and output accuracy scores\n",
    "accuracy_equiv = accuracy_score(y_test, y_pred_equiv)\n",
    "print(\"Accuracy of equivalence model:\\t\", accuracy_equiv)\n",
    "accuracy_lit = accuracy_score(y_test, y_pred_lit)\n",
    "print(\"Accuracy of literal model:\\t\", accuracy_lit)\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "print(\"Accuracy of dummy model:\\t\", accuracy_dummy)\n",
    "print()\n",
    "\n",
    "# compute and output precision scores\n",
    "precision_equiv = precision_score(y_test, y_pred_equiv, average = 'micro')\n",
    "print(\"Precision of equivalence model:\\t\", precision_equiv)\n",
    "precision_lit = precision_score(y_test, y_pred_lit, average = 'micro')\n",
    "print(\"Precision of literal model:\\t\", precision_lit)\n",
    "precision_dummy = precision_score(y_test, y_pred_dummy, average = 'micro')\n",
    "print(\"Precision of dummy model:\\t\", precision_dummy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
