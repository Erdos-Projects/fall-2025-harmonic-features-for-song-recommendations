{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7658af-055e-4ea4-bfb3-ae44fa9e954a",
   "metadata": {},
   "source": [
    "This notebook is used to make some csv files which highlight top n-grams for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d685bf7-ecf6-43a5-bc66-57acbbb3421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "from collections import Counter, deque\n",
    "\n",
    "# read in the data set\n",
    "df = pd.read_csv('../data/chordonomicon.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9842b-cb0f-46e2-b4a5-76ef439c642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the mapping CSV file\n",
    "chord_relations = pd.read_csv('../data/chords_mapping.csv')\n",
    "\n",
    "# Create a dictionary with keys the \"chords\" and values the \"degrees\"\n",
    "chord_degrees = dict(zip(chord_relations['Chords'], chord_relations['Degrees']))\n",
    "for key, value in chord_degrees.items():\n",
    "    chord_degrees[key] = ast.literal_eval(value)\n",
    "    \n",
    "# full list of chords from the chords_mapping csv\n",
    "known_chords = list(chord_degrees.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f1cff-62c1-48ba-9a5c-6ce4ede3e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the equivalence dictionary file\n",
    "# this is a dictionary of dictionaries\n",
    "#    the top-level keys are chord names (e.g. 'C','Amin')\n",
    "#    the top-level values are dictionaries, whose keys are equivalent chords, and whose values are the semitone distance between the top-level key and the low-level key\n",
    "with open('../data/harmonic_equivalence.json') as file:\n",
    "    equiv_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb037ca-02dc-4770-8f69-5e4b2eda2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns except for chords and genres\n",
    "chord_data = df[['chords','genres']]\n",
    "\n",
    "# drop anything that lacks chord or genre data\n",
    "chord_data = chord_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63fa7b6-c266-458f-9e17-a20e731a05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing spaces with commas\n",
    "def replace_space_with_comma(my_string):\n",
    "    return my_string.replace(\" \",\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762e2cb-b58d-427d-b0ef-9fc3aa591c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove section markers\n",
    "def remove_section_markers(my_string):\n",
    "    result = []\n",
    "    i = 0\n",
    "    n = len(my_string)\n",
    "    while i < n:\n",
    "        if my_string[i] == '<':\n",
    "            # Skip until after the following \", \"\n",
    "            j = my_string.find('>', i)\n",
    "            if j == -1:\n",
    "                break  # no closing '>', stop\n",
    "            i = j + 2  # skip '>,' and the space\n",
    "        else:\n",
    "            result.append(my_string[i])\n",
    "            i += 1\n",
    "    assert('<' not in result)\n",
    "    assert('>' not in result)\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b28991-cd87-494f-843b-2e8dd78046ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove inversions\n",
    "def remove_inversions(my_string):\n",
    "    result = []\n",
    "    i = 0\n",
    "    n = len(my_string)\n",
    "    while i < n:\n",
    "        if my_string[i] == '/':\n",
    "            # Skip until after the following \", \"\n",
    "            j = my_string.find(',', i)\n",
    "            if j == -1:\n",
    "                break  # no closing comma, stop\n",
    "            i = j  # skip comma\n",
    "        else:\n",
    "            result.append(my_string[i])\n",
    "            i += 1\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56fc2dd-f82e-4811-a610-2526655e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_chord_string(my_string):\n",
    "    return remove_inversions(\n",
    "        remove_section_markers(\n",
    "            replace_space_with_comma(my_string)))\n",
    "    \n",
    "# cleaning up the data in a few ways\n",
    "chord_data.loc[:,'chords'] = chord_data['chords'].apply(clean_up_chord_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189567a6-4a52-4d60-8d94-789b226c3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify genre data\n",
    "major_genres = ['pop','rock','country','alternative','punk','metal','rap','soul','jazz','reggae','electronic']\n",
    "def simplify_genre(genre_string):\n",
    "    for g in major_genres:\n",
    "        if g in genre_string:\n",
    "            return g\n",
    "    return 'other'\n",
    "\n",
    "chord_data.loc[:,'genres'] = chord_data['genres'].apply(simplify_genre)\n",
    "major_genres = ['pop','rock','country','alternative','punk','metal','rap','soul','jazz','reggae','electronic','other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11362029-11f0-4dba-a858-57bb5e5dcb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_genre_counter = Counter(chord_data.genres)\n",
    "print(full_data_genre_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c97667-df2b-44db-aa5b-7b5d71903597",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(x = list(full_data_genre_counter.values()), \n",
    "        labels = list(full_data_genre_counter.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19baee2a-8c66-41ac-adb9-8716a15097ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "labels, values = zip(*full_data_genre_counter.most_common())\n",
    "plt.bar(x = labels, \n",
    "        height = values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8dd88d-a4c4-4fbf-b173-e306eab55b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the two input chords are harmonically equivalent, return (True, num_semitones) where num_semitones is the distance from n_gram_1 (up) to n_gram_2\n",
    "# otherwise, return (False, None)\n",
    "def compare_chords(chord_1, chord_2):\n",
    "    if chord_2 in equiv_dict[chord_1]:\n",
    "        return (True, equiv_dict[chord_1][chord_2])\n",
    "    else:\n",
    "        return (False, None)\n",
    "\n",
    "print(compare_chords('C','D'))\n",
    "print(compare_chords('C','E'))\n",
    "print(compare_chords('C','Amin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92111206-48cc-4640-89ce-bea615bca65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the two input n_grams are harmonically equivalent, return (True, num_semitones) where num_semitones is the distance from n_gram_1 (up) to n_gram_2\n",
    "# otherwise, return (False, None)\n",
    "def compare_n_grams(n_gram_1, n_gram_2):\n",
    "    list_1 = n_gram_1.split(',')\n",
    "    list_2 = n_gram_2.split(',')\n",
    "\n",
    "    # if they aren't the same length, we don't have to check anything\n",
    "    if len(list_1) != len(list_2):\n",
    "        return (False, None)\n",
    "\n",
    "    # now we can assume they have the same length\n",
    "    comparison = [compare_chords(list_1[i], list_2[i]) for i in range(len(list_1))]\n",
    "\n",
    "    # if any pairs are not the same, return False\n",
    "    for c in comparison:\n",
    "        if not c[0]:\n",
    "            return (False, None)\n",
    "\n",
    "    # now we can assume every respective pair is equivalent, but we still need all of the distances to match\n",
    "    dist_0 = comparison[0][1]\n",
    "    for c in comparison:\n",
    "        if c[1] != dist_0:\n",
    "            return (False, None)\n",
    "\n",
    "    return (True, dist_0)\n",
    "\n",
    "print(compare_n_grams('C,D,E','F,G,A'))\n",
    "print(compare_n_grams('C,D,E','F,G,B'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0ee28-b967-47b4-8264-6981a9c22553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return true/false depending on if a song contains a harmonically equivalent n_gram to the input n_gram\n",
    "# new version of this, making use of the equivalence dictionary for lookups rather than doing calculations every time\n",
    "def contains_n_gram(song, n_gram):\n",
    "    # assumption: input song is a comma-separated string of chord names\n",
    "    # assumption: input n_gram is a comma-separated string of chord names\n",
    "\n",
    "    # skip ahead and return true if the raw version is the song\n",
    "    if n_gram in song:\n",
    "        return True\n",
    "\n",
    "    # split up the song and n_gram into lists of strings of single chords\n",
    "    song_as_list = song.split(',')\n",
    "    song_length = len(song_as_list)\n",
    "    n_gram_as_list = n_gram.split(',')\n",
    "    n = len(n_gram_as_list)\n",
    "\n",
    "    for i in range(0,song_length - n):\n",
    "        song_n_gram = ','.join(song_as_list[i:i+n])\n",
    "        is_same, dist = compare_n_grams(n_gram, song_n_gram)\n",
    "        if is_same:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "assert(contains_n_gram('A,B,C,D,E,F,G','C,D'))\n",
    "assert(contains_n_gram('A,B,C,D,E,F','F,G'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3201411-c07f-4e76-931b-2fc78f703da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_n_grams_list(data, n):\n",
    "    # return a list of all raw n-grams, ignoring harmonic equivalence\n",
    "    results = []\n",
    "    for song in list(data.chords):\n",
    "        song_as_list = song.split(',')\n",
    "        for i in range(len(song_as_list)-n+1):\n",
    "            n_gram = ','.join(song_as_list[i:i+n])\n",
    "            if not n_gram in results:\n",
    "                results.append(n_gram)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f53afe-4a99-4747-b6c8-b5e18dac850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = chord_data.sample(5)\n",
    "get_raw_n_grams_list(sample_data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38077c17-a923-4448-b009-552060adfaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return true if n_gram belongs to the list\n",
    "# false otherwise\n",
    "def n_gram_belongs_to_list(list_of_n_grams, n_gram):\n",
    "    for ng in list_of_n_grams:\n",
    "        if compare_n_grams(ng,n_gram)[0]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "my_list = ['C','D','E','C,D','C,G']\n",
    "assert(n_gram_belongs_to_list(my_list,'C'))\n",
    "assert(n_gram_belongs_to_list(my_list,'D'))\n",
    "assert(n_gram_belongs_to_list(my_list,'E'))\n",
    "assert(n_gram_belongs_to_list(my_list,'C,D'))\n",
    "assert(n_gram_belongs_to_list(my_list,'C,G'))\n",
    "\n",
    "assert(n_gram_belongs_to_list(my_list,'A'))\n",
    "assert(n_gram_belongs_to_list(my_list,'G'))\n",
    "assert(n_gram_belongs_to_list(my_list,'F'))\n",
    "assert(n_gram_belongs_to_list(my_list,'D,E'))\n",
    "assert(n_gram_belongs_to_list(my_list,'A,B'))\n",
    "assert(n_gram_belongs_to_list(my_list,'A,E'))\n",
    "\n",
    "assert(not(n_gram_belongs_to_list(my_list,'Cmin')))\n",
    "assert(not(n_gram_belongs_to_list(my_list,'C,F')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4656876-054d-48a1-a84e-2060bb58ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a list of harmonically unique n-grams\n",
    "def get_unique_n_grams_list(data, n, progress_updates = False, progress_spacing = 10):\n",
    "    results = []\n",
    "\n",
    "    if progress_updates:\n",
    "        t0 = time.time()\n",
    "        num_songs = len(list(data.chords))\n",
    "        print(\"Computing all unique n-grams from given data.\")\n",
    "        print(\"Number of songs to analyze:\",num_songs)\n",
    "    \n",
    "    for index, song in enumerate(list(data.chords)):\n",
    "        if progress_updates and (index % progress_spacing == 0) and index != 0:\n",
    "            t1 = time.time()\n",
    "            time_so_far = t1-t0\n",
    "            average_time_per_song = (t1-t0)/index\n",
    "            remaining_songs = num_songs - index\n",
    "            estimated_remaining_time = average_time_per_song*remaining_songs\n",
    "            print(\"Analyzing song index number:\",index)\n",
    "            print(\"\\tTotal time spent so far: \" + str(time_so_far) + \" seconds\")            \n",
    "            print(\"\\tAverage time per song so far: \" + str(average_time_per_song) + \" seconds\")\n",
    "            print(\"\\tEstimated remaining time: \" + str(estimated_remaining_time) + \" seconds\")\n",
    "            \n",
    "        song_as_list = song.split(',')\n",
    "        for i in range(len(song_as_list)-n+1):\n",
    "            n_gram = ','.join(song_as_list[i:i+n])\n",
    "            if not(n_gram_belongs_to_list(results,n_gram)):\n",
    "                results.append(n_gram)\n",
    "\n",
    "    if progress_updates:\n",
    "        print(\"Done analyzing all songs.\")\n",
    "        print()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b6623-48c9-42d4-8412-23a2e2e41c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = chord_data.sample(30)\n",
    "get_unique_n_grams_list(sample_data, n=1, progress_updates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5cd287-fe7c-466b-86ae-cea4340271ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a list of harmonically unique n-grams\n",
    "def get_unique_n_grams_list(data, n, progress_updates = False, progress_spacing = 10):\n",
    "    results = []\n",
    "\n",
    "    if progress_updates:\n",
    "        t0 = time.time()\n",
    "        num_songs = len(list(data.chords))\n",
    "        print(\"Computing all unique n-grams from given data.\")\n",
    "        print(\"Number of songs to analyze:\",num_songs)\n",
    "    \n",
    "    for index, song in enumerate(list(data.chords)):\n",
    "        if progress_updates and (index % progress_spacing == 0) and index != 0:\n",
    "            t1 = time.time()\n",
    "            time_so_far = t1-t0\n",
    "            average_time_per_song = (t1-t0)/index\n",
    "            remaining_songs = num_songs - index\n",
    "            estimated_remaining_time = average_time_per_song*remaining_songs\n",
    "            print(\"Analyzing song index number:\",index)\n",
    "            print(\"\\tTotal time spent so far: \" + str(time_so_far) + \" seconds\")            \n",
    "            print(\"\\tAverage time per song so far: \" + str(average_time_per_song) + \" seconds\")\n",
    "            print(\"\\tEstimated remaining time: \" + str(estimated_remaining_time) + \" seconds\")\n",
    "            \n",
    "        song_as_list = song.split(',')\n",
    "        for i in range(len(song_as_list)-n+1):\n",
    "            n_gram = ','.join(song_as_list[i:i+n])\n",
    "            if not(n_gram_belongs_to_list(results,n_gram)):\n",
    "                results.append(n_gram)\n",
    "\n",
    "    if progress_updates:\n",
    "        print(\"Done analyzing all songs.\")\n",
    "        print()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02890da9-f1ce-4052-9391-98d7481bbcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_empty_df(data, n, progress_updates = False, progress_spacing = 10):\n",
    "    # construct a list of all unique n_grams that are present in the data, and n ranges over a specified list\n",
    "    # these will be the rows of the dataframe\n",
    "    n_grams = ['baseline'] + get_unique_n_grams_list(data, n, progress_updates, progress_spacing)\n",
    "    num_rows = len(n_grams)\n",
    "    results_dict = {'n_gram' : n_grams}\n",
    "\n",
    "    # initialize a bunch of columns of zeros, one for each major genre\n",
    "    for g in major_genres:\n",
    "        results_dict[g + '_raw'] = np.zeros(shape = num_rows, dtype = int)\n",
    "\n",
    "    # compute the baseline row by just counting all genres\n",
    "    for song, genre in zip(data.chords, data.genres):\n",
    "        results_dict[genre + '_raw'][0] += 1\n",
    "\n",
    "    # add a \"counts_completed\" column for tracking partial work/computations\n",
    "    results_dict['counts_completed'] = [True] + [False]*(num_rows - 1) # the first true is for the baseline row, which should be ignored mostly\n",
    "        \n",
    "    return pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49153003-9a97-4e54-b97b-b22298e74c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = chord_data.sample(30)\n",
    "empty_df = build_empty_df(sample_data, n=2, progress_updates = True, progress_spacing = 10)\n",
    "display(empty_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8454b58-cb20-4af6-b0ec-bc209be70fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_raw_counts(data, df, rows_to_compute = -1, output_messages = False):\n",
    "    # input: a dataframe with a column of n-grams a GENRE_raw counts column for each major genre, and a counts_completed column indicating whether that rows has been done\n",
    "    #        (the other columns\n",
    "    # output: a copy of the same dataframe, except that some of the rows have had the counting work done\n",
    "    \n",
    "    results_df = copy.deepcopy(df) # make a deep copy of the dataframe  \n",
    "    incomplete_rows = results_df[results_df['counts_completed'] == False] # extract the rows which are incomplete\n",
    "\n",
    "    if output_messages:\n",
    "        print(\"Remaining rows to tabulate raw counts for:\", len(incomplete_rows.index))\n",
    "\n",
    "    if rows_to_compute > 0:\n",
    "        incomplete_rows = incomplete_rows.head(rows_to_compute) # extract the top few rows\n",
    "    # if rows_to_compute is the default value of -1, then this will just try to do all of the incomplete rows\n",
    "    \n",
    "    # iterate through a few n_grams/rows, checking all songs to get raw genre counts for each of those n_grams/rows\n",
    "    for i, row in incomplete_rows.iterrows():\n",
    "        ng = row['n_gram']\n",
    "        for song, genre in zip(data.chords, data.genres):\n",
    "            if contains_n_gram(song, ng):\n",
    "                results_df.at[i, genre + '_raw'] += 1\n",
    "        results_df.at[i, 'counts_completed'] = True\n",
    "\n",
    "    if output_messages:\n",
    "        if rows_to_compute > 0:\n",
    "            print(\"Tabulated raw counts for \" + str(rows_to_compute) + \" rows\")\n",
    "        else:\n",
    "            print(\"Tabulated raw counts for all remaining rows\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9752a8-a6be-4cc1-88da-e4d7d6df7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = chord_data.sample(300)\n",
    "empty_df = build_empty_df(sample_data, n=2)\n",
    "raw_counts_df = compute_raw_counts(data = sample_data, df = empty_df, rows_to_compute = 5)\n",
    "display(raw_counts_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04afcc-171d-4e3b-96fe-ff75f9cd51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_relative_columns(raw_count_df):\n",
    "    # input: a dataframe that has one row for each n-gram, with raw counts of genres it appears in\n",
    "    # output: a new dataframe which is the same, but has added columns with relative counts\n",
    "    results_df = copy.deepcopy(raw_count_df)\n",
    "\n",
    "    # make a total counts column\n",
    "    raw_columns = [g + '_raw' for g in major_genres]\n",
    "    results_df['total'] = results_df[raw_columns].sum(axis=1)\n",
    "    \n",
    "    for g in major_genres:\n",
    "        results_df[g + '_rel'] = results_df[g + '_raw'] / results_df['total']\n",
    "    return results_df\n",
    "\n",
    "sample_data = chord_data.sample(20)\n",
    "empty_df = build_empty_df(sample_data, n=2)\n",
    "raw_counts_df = compute_raw_counts(data = sample_data, df = empty_df, rows_to_compute = -1)\n",
    "relative_df = add_relative_columns(raw_counts_df)\n",
    "\n",
    "pop_columns = ['n_gram', 'pop_raw', 'pop_rel', 'total', 'counts_completed']\n",
    "display(relative_df[pop_columns].head(10))\n",
    "\n",
    "display(relative_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9fcb77-c947-425e-91f5-855b7b71966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_deviation_columns(relative_df):\n",
    "    # input: a dataframe that has one row for each n-gram, and two columns for each genre: a raw count, and relative count\n",
    "    #          there should also be a first row for \"baseline\"\n",
    "    #          there should also be a column for \"total\" which is the sume of the raw count columns in that row\n",
    "    # output: a new dataframe which has added columns with some interesting metrics for deviation from baseline\n",
    "    results_df = copy.deepcopy(relative_df)\n",
    "\n",
    "    # metrics: \n",
    "    #     GENRE_dev_ratio - the ratio between the relative frequency of a genre among songs containing a given n-gram, and relative frequency of a genre as a baseline (among all songs in the sample)\n",
    "    #                     - if this is 1, then the n-gram is not deviating from baseline relative frequencies\n",
    "    #                     - farther from 1, it is more deviated\n",
    "    #     GENRE_log_dev_ratio - the log of the previous metric, so that now zero represents being the same as baseline relative frequency, and \n",
    "    #                         - positive numbers indicate higher than baseline frequency, and negative numbers indicate lower than baseline frequency\n",
    "    #     GENRE_abs_log_dev_ratio - the absolute value of the previous metric, so now bigger numbers represent higher deviation from baseline frequency\n",
    "    \n",
    "    for g in major_genres:\n",
    "        dev_ratio = results_df[g + '_rel'] / results_df[g + '_rel'].iloc[0]\n",
    "        \n",
    "        results_df[g + '_dev_ratio'] = dev_ratio\n",
    "        results_df[g + '_log_dev_ratio'] = np.log(dev_ratio.replace(0,np.nan))\n",
    "        results_df[g + '_abs_log_dev_ratio'] = results_df[g + '_log_dev_ratio'].abs()\n",
    "\n",
    "    # make a max_abs_log_dev_ratio column\n",
    "    # and a mean_abs_log_dev_ratio column\n",
    "    abs_log_dev_columns = [g + '_abs_log_dev_ratio' for g in major_genres]\n",
    "    results_df['max_abs_log_dev_ratio'] = results_df[abs_log_dev_columns].max(axis=1)\n",
    "    results_df['mean_abs_log_dev_ratio'] = results_df[abs_log_dev_columns].mean(axis=1)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "sample_data = chord_data.sample(20)\n",
    "empty_df = build_empty_df(sample_data, n=2)\n",
    "raw_counts_df = compute_raw_counts(data = sample_data, df = empty_df, rows_to_compute = -1)\n",
    "relative_df = add_relative_columns(raw_counts_df)\n",
    "deviation_df = add_deviation_columns(relative_df)\n",
    "pop_columns = ['n_gram', 'pop_raw', 'pop_rel', 'pop_dev_ratio', 'pop_log_dev_ratio', 'pop_abs_log_dev_ratio', 'total', 'counts_completed', 'max_abs_log_dev_ratio', 'mean_abs_log_dev_ratio']\n",
    "display(deviation_df[pop_columns].head(10))\n",
    "display(deviation_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8280e5-8358-4c26-864b-e39e2421cc75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_high_deviation_n_grams(deviation_df, sample_size_threshold = 0.1, how_many_to_plot = 10):\n",
    "    # input: a dataframe with one row for a baseline, and one row per n_gram\n",
    "    #        columns include n_gram, GENRE_abs_log_dev_ratio (for each major genre)\n",
    "    # output: bar plots of the top n_grams, ranked by abs_log_dev_ratio\n",
    "    df = copy.deepcopy(deviation_df)\n",
    "\n",
    "    # drop all rows where the 'total' column doesn't meet the sample size threshold, which is sample_size_threshold times the baseline total value\n",
    "    baseline_row_index = df.index[df['n_gram'] == 'baseline'][0]\n",
    "    baseline_total = df.loc[baseline_row_index,'total']\n",
    "    df = df[df.total >= baseline_total * sample_size_threshold]\n",
    "\n",
    "    # drop the baseline row\n",
    "    df = df[df.n_gram != 'baseline']\n",
    "      \n",
    "    # sort by max_abs_log_dev_ratio, descending so the big ones are at the top. Get those top rows.\n",
    "    df = df.sort_values(by = 'max_abs_log_dev_ratio', ascending = False)\n",
    "    how_many_to_plot = min(how_many_to_plot, len(df.index)) # don't try to plot more than all the rows\n",
    "    top_rows = df.head(how_many_to_plot)\n",
    "    \n",
    "    for i in range(how_many_to_plot):\n",
    "        row_i = df.iloc[i]\n",
    "        height_data = [row_i[g + '_log_dev_ratio'] for g in major_genres]\n",
    "        my_x = np.arange(len(major_genres))\n",
    "        plt.figure(figsize = (20, 4))\n",
    "        plt.bar(x = my_x,\n",
    "                height = height_data)\n",
    "        plt.xticks(my_x, major_genres, rotation = 45, ha = 'right')\n",
    "        plt.title('Deviations from baseline genre distribution for songs containing \"' + row_i['n_gram'] + '\" based on a filtered set of ' + str(row_i['total']) + ' out of ' + str(baseline_total) + ' songs')\n",
    "        plt.show()\n",
    "\n",
    "sample_data = chord_data.sample(100)\n",
    "empty_df = build_empty_df(sample_data, n=2)\n",
    "raw_counts_df = compute_raw_counts(data = sample_data, df = empty_df, rows_to_compute = -1)\n",
    "relative_df = add_relative_columns(raw_counts_df)\n",
    "deviation_df = add_deviation_columns(relative_df)\n",
    "pop_columns = ['n_gram', 'pop_raw', 'pop_rel', 'pop_dev_ratio', 'pop_log_dev_ratio', 'pop_abs_log_dev_ratio', 'total', 'counts_completed', 'max_abs_log_dev_ratio', 'mean_abs_log_dev_ratio']\n",
    "display(deviation_df[pop_columns].head(10))\n",
    "plot_high_deviation_n_grams(deviation_df, sample_size_threshold = 0.15, how_many_to_plot = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c1b99-286a-4f06-a702-dc216c601455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code snippet to partially complete the counts in the database\n",
    "def run_tabulations(n, iterations, rows_per_iteration):\n",
    "    filename = str(n) + '_gram_deviations.csv'\n",
    "    print(\"Running tabulations on \" + str(n) + \"-gram dataframe.\")\n",
    "    print(\"Will run \" + str(iterations) + \" iterations, doing calculations on \" + str(rows_per_iteration) + \" rows per iteration.\")\n",
    "    print()\n",
    "    \n",
    "    time_vector = [0]*iterations\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        print(\"Iteration i =\",i+1)\n",
    "        t0 = time.time()\n",
    "        \n",
    "        print(\"Loading dataframe from csv.\")\n",
    "        df_loaded = pd.read_csv(filename)\n",
    "\n",
    "        print(\"Current dataframe contains: \")\n",
    "        #print(\"\\t\" + str(len(df_loaded.index)) + \" total rows\")\n",
    "        print(\"\\t\" + str(df_loaded['counts_completed'].sum()) + \" completed rows\")\n",
    "        remaining_rows = (len(df_loaded.index)) - df_loaded['counts_completed'].sum()\n",
    "        print(\"\\t\" + str(remaining_rows) + \" remaining rows\")\n",
    "    \n",
    "        df_updated = compute_raw_counts(data = chord_data, df = df_loaded, rows_to_compute = rows_per_iteration)\n",
    "        print('Completed tabulation for ' + str(rows_per_iteration) + ' rows.')\n",
    "        \n",
    "        print('Saving dataframe to csv.')\n",
    "        df_updated.to_csv(filename,sep=',',index=False)\n",
    "        \n",
    "        t1 = time.time()\n",
    "        time_vector[i] = t1-t0\n",
    "        print(\"Time spent this iteration:\",t1-t0,\"seconds\")\n",
    "        print(\"Time per row this iteration:\",(t1-t0)/rows_per_iteration,\"seconds\")\n",
    "        print()\n",
    "\n",
    "        # if there are less remaining rows than the next iteration would tabulate, \n",
    "        # just change the number of rows to do in the next iteration to be all of them\n",
    "        if df_loaded['counts_completed'].sum() == 0:\n",
    "            break\n",
    "            if (len(df_loaded.index)) - df_loaded['counts_completed'].sum() < rows_per_iteration:\n",
    "                rows_per_iteration = (len(df_loaded.index)) - df_loaded['counts_completed'].sum()\n",
    "    \n",
    "    print(\"Finished all iterations.\")\n",
    "    print(\"Total time:\",np.sum(time_vector))\n",
    "    print(\"Average time per iteration:\",np.mean(time_vector))\n",
    "    print(\"Average time per row:\",np.mean(time_vector)/rows_per_iteration)\n",
    "    \n",
    "    remaining_rows = (len(df_loaded.index)) - df_loaded['counts_completed'].sum()\n",
    "    print(\"Remaining rows:\",remaining_rows)\n",
    "    return remaining_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e0288d-29e5-4a78-a0d0-176ef8177318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#### populate a \"blank\" 1-grams csv data file \n",
    "#### DO NOT RUN THIS AGAIN, IT WILL OVERWRITE THE TABULATION WORK\n",
    "#######################################################################\n",
    "#n=1\n",
    "#blank_df = build_empty_df(chord_data, n, progress_updates = True, progress_spacing = 5000)\n",
    "#blank_df.to_csv(str(n) + '_gram_deviations.csv', sep=',', index=False)\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df37598-80f7-4b33-b21d-3bb5415891c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#### populate a \"blank\" 2-grams csv data file \n",
    "#### DO NOT RUN THIS AGAIN, IT WILL OVERWRITE THE TABULATION WORK\n",
    "#######################################################################\n",
    "#n=2\n",
    "#blank_df = build_empty_df(chord_data, n, progress_updates = True, progress_spacing = 5000)\n",
    "#blank_df.to_csv(str(n) + '_gram_deviations.csv', sep=',', index=False)\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeef411-3221-496e-8f01-11ae9541f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#### populate a \"blank\" 3-grams csv data file \n",
    "#### I have still not run this yet, I anticipate it will take a long time\n",
    "#######################################################################\n",
    "#n=3\n",
    "#blank_df = build_empty_df(chord_data, n, progress_updates = True, progress_spacing = 5000)\n",
    "#blank_df.to_csv(str(n) + '_gram_deviations.csv', sep=',', index=False)\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6a85a-c060-40a6-89e0-105adb8d9873",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_rows = run_tabulations(n=2, iterations=1, rows_per_iteration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5ffd8-41f2-4431-b231-833423daed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this after all rows are tabulated\n",
    "# this will add the columsn for relative counts, relative deviations, log relative deviations, and key summary statistic columsn (main one being the absolute relative log deviation)\n",
    "def process_tabulated_df(n):\n",
    "    filename = str(n) + '_gram_deviations.csv'\n",
    "    raw_counts_df = pd.read_csv(filename)\n",
    "    relative_df = add_relative_columns(raw_counts_df)\n",
    "    deviation_df = add_deviation_columns(relative_df)\n",
    "    deviation_df.to_csv(filename,sep=',',index=False)\n",
    "    return deviation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68d3dd8-546b-40f7-bcc7-4107bdff498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#### DO NOT RUN THIS AGAIN, IT WILL JUST DUPLICATE COLUMNS\n",
    "#process_tabulated_df(1)\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015ddb1-6f8c-4018-806c-f3c260cb0429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#### ONLY RUN THIS ONE TIME EVER, AND ONLY AFTER FINISHING TABULATION FOR 2-GRAMS\n",
    "#process_tabulated_df(2)\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de043b-5178-453a-b863-97b55df251d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#### ONLY RUN THIS ONE TIME EVER, AND ONLY AFTER FINISHING TABULATION FOR 3-GRAMS\n",
    "#process_tabulated_df(3)\n",
    "#################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
